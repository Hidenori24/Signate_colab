{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "mount_file_id": "https://github.com/Hidenori24/Signate_colab/blob/main/SMBC_GreenChallenge_2025.ipynb",
      "authorship_tag": "ABX9TyODZMU2K5thUGJNJ/Dt2cqm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hidenori24/Signate_colab/blob/main/SMBC_GreenChallenge_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## importとシードなどの設定"
      ],
      "metadata": {
        "id": "x-BsQNWyMS0G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "MK3beRd6Kjrh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.decomposition import PCA\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# 日本語フォントを簡単に使う\n",
        "!pip -q install japanize-matplotlib\n",
        "import japanize_matplotlib\n",
        "\n",
        "# シードの設定\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Driveへの接続、データの取得"
      ],
      "metadata": {
        "id": "AMwtDtYJO009"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/MyDrive/ML/Signate_1634/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCR43u2YO4_X",
        "outputId": "ef679073-d283-4432-cacd-4e7458e769d4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train/test/sample_submission の取り込み"
      ],
      "metadata": {
        "id": "ZUdy-QCLPKSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df  = pd.read_csv(data_path + 'train.csv', parse_dates=['time'], index_col='time')\n",
        "df = train_df\n",
        "test_df   = pd.read_csv(data_path + 'test.csv', parse_dates=['time'], index_col='time')\n",
        "sample_submission_df = pd.read_csv(data_path + 'sample_submit.csv', header=None)  # header 無し"
      ],
      "metadata": {
        "id": "gugrOPbtPIaz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 概要確認"
      ],
      "metadata": {
        "id": "FT0Jun66P6ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 概要を確認\n",
        "print(\"\\n--- 学習データ (train_df) ---\")\n",
        "display(train_df.head())\n",
        "print(f\"shape: {train_df.shape}\")\n",
        "\n",
        "print(\"\\n--- テストデータ (test_df) ---\")\n",
        "display(test_df.head())\n",
        "print(f\"shape: {test_df.shape}\")\n",
        "\n",
        "print(\"\\n--- サンプル提出 (sample_submission_df) ---\")\n",
        "display(sample_submission_df.head())\n",
        "print(f\"shape: {sample_submission_df.shape}\")"
      ],
      "metadata": {
        "id": "cSti76YKP44d",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5c0b9c9d-6f89-42d9-d4a8-6894d40343a2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 学習データ (train_df) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                           generation_biomass  \\\n",
              "time                                            \n",
              "2015-01-02 00:00:00+01:00               447.0   \n",
              "2015-01-02 01:00:00+01:00               449.0   \n",
              "2015-01-02 02:00:00+01:00               448.0   \n",
              "2015-01-02 03:00:00+01:00               438.0   \n",
              "2015-01-02 04:00:00+01:00               428.0   \n",
              "\n",
              "                           generation_fossil_brown_coal/lignite  \\\n",
              "time                                                              \n",
              "2015-01-02 00:00:00+01:00                                 329.0   \n",
              "2015-01-02 01:00:00+01:00                                 328.0   \n",
              "2015-01-02 02:00:00+01:00                                 323.0   \n",
              "2015-01-02 03:00:00+01:00                                 254.0   \n",
              "2015-01-02 04:00:00+01:00                                 187.0   \n",
              "\n",
              "                           generation_fossil_gas  generation_fossil_hard_coal  \\\n",
              "time                                                                            \n",
              "2015-01-02 00:00:00+01:00                 4844.0                       4821.0   \n",
              "2015-01-02 01:00:00+01:00                 5196.0                       4755.0   \n",
              "2015-01-02 02:00:00+01:00                 4857.0                       4581.0   \n",
              "2015-01-02 03:00:00+01:00                 4314.0                       4131.0   \n",
              "2015-01-02 04:00:00+01:00                 4130.0                       3840.0   \n",
              "\n",
              "                           generation_fossil_oil  \\\n",
              "time                                               \n",
              "2015-01-02 00:00:00+01:00                  162.0   \n",
              "2015-01-02 01:00:00+01:00                  158.0   \n",
              "2015-01-02 02:00:00+01:00                  157.0   \n",
              "2015-01-02 03:00:00+01:00                  160.0   \n",
              "2015-01-02 04:00:00+01:00                  156.0   \n",
              "\n",
              "                           generation_hydro_pumped_storage_consumption  \\\n",
              "time                                                                     \n",
              "2015-01-02 00:00:00+01:00                                        863.0   \n",
              "2015-01-02 01:00:00+01:00                                        920.0   \n",
              "2015-01-02 02:00:00+01:00                                       1164.0   \n",
              "2015-01-02 03:00:00+01:00                                       1503.0   \n",
              "2015-01-02 04:00:00+01:00                                       1826.0   \n",
              "\n",
              "                           generation_hydro_run_of_river_and_poundage  \\\n",
              "time                                                                    \n",
              "2015-01-02 00:00:00+01:00                                      1051.0   \n",
              "2015-01-02 01:00:00+01:00                                      1009.0   \n",
              "2015-01-02 02:00:00+01:00                                       973.0   \n",
              "2015-01-02 03:00:00+01:00                                       949.0   \n",
              "2015-01-02 04:00:00+01:00                                       953.0   \n",
              "\n",
              "                           generation_hydro_water_reservoir  \\\n",
              "time                                                          \n",
              "2015-01-02 00:00:00+01:00                            1899.0   \n",
              "2015-01-02 01:00:00+01:00                            1658.0   \n",
              "2015-01-02 02:00:00+01:00                            1371.0   \n",
              "2015-01-02 03:00:00+01:00                             779.0   \n",
              "2015-01-02 04:00:00+01:00                             720.0   \n",
              "\n",
              "                           generation_nuclear  generation_other  ...  \\\n",
              "time                                                             ...   \n",
              "2015-01-02 00:00:00+01:00              7096.0              43.0  ...   \n",
              "2015-01-02 01:00:00+01:00              7096.0              43.0  ...   \n",
              "2015-01-02 02:00:00+01:00              7099.0              43.0  ...   \n",
              "2015-01-02 03:00:00+01:00              7098.0              43.0  ...   \n",
              "2015-01-02 04:00:00+01:00              7097.0              43.0  ...   \n",
              "\n",
              "                           seville_rain_1h  seville_rain_3h  seville_snow_3h  \\\n",
              "time                                                                           \n",
              "2015-01-02 00:00:00+01:00              0.0              0.0                0   \n",
              "2015-01-02 01:00:00+01:00              0.0              0.0                0   \n",
              "2015-01-02 02:00:00+01:00              0.0              0.0                0   \n",
              "2015-01-02 03:00:00+01:00              0.0              0.0                0   \n",
              "2015-01-02 04:00:00+01:00              0.0              0.0                0   \n",
              "\n",
              "                           seville_clouds_all  seville_weather_id  \\\n",
              "time                                                                \n",
              "2015-01-02 00:00:00+01:00                   0                 800   \n",
              "2015-01-02 01:00:00+01:00                   0                 800   \n",
              "2015-01-02 02:00:00+01:00                   0                 800   \n",
              "2015-01-02 03:00:00+01:00                   0                 800   \n",
              "2015-01-02 04:00:00+01:00                   0                 800   \n",
              "\n",
              "                           seville_weather_main  seville_weather_description  \\\n",
              "time                                                                           \n",
              "2015-01-02 00:00:00+01:00                 clear                 sky is clear   \n",
              "2015-01-02 01:00:00+01:00                 clear                 sky is clear   \n",
              "2015-01-02 02:00:00+01:00                 clear                 sky is clear   \n",
              "2015-01-02 03:00:00+01:00                 clear                 sky is clear   \n",
              "2015-01-02 04:00:00+01:00                 clear                 sky is clear   \n",
              "\n",
              "                           seville_weather_icon  price_actual      item_ID  \n",
              "time                                                                        \n",
              "2015-01-02 00:00:00+01:00                   01n         64.02  spain_total  \n",
              "2015-01-02 01:00:00+01:00                   01n         58.46  spain_total  \n",
              "2015-01-02 02:00:00+01:00                   01n         54.70  spain_total  \n",
              "2015-01-02 03:00:00+01:00                   01n         54.91  spain_total  \n",
              "2015-01-02 04:00:00+01:00                   01n         53.07  spain_total  \n",
              "\n",
              "[5 rows x 92 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-402eb217-4e71-408a-93e0-f8e89504c468\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generation_biomass</th>\n",
              "      <th>generation_fossil_brown_coal/lignite</th>\n",
              "      <th>generation_fossil_gas</th>\n",
              "      <th>generation_fossil_hard_coal</th>\n",
              "      <th>generation_fossil_oil</th>\n",
              "      <th>generation_hydro_pumped_storage_consumption</th>\n",
              "      <th>generation_hydro_run_of_river_and_poundage</th>\n",
              "      <th>generation_hydro_water_reservoir</th>\n",
              "      <th>generation_nuclear</th>\n",
              "      <th>generation_other</th>\n",
              "      <th>...</th>\n",
              "      <th>seville_rain_1h</th>\n",
              "      <th>seville_rain_3h</th>\n",
              "      <th>seville_snow_3h</th>\n",
              "      <th>seville_clouds_all</th>\n",
              "      <th>seville_weather_id</th>\n",
              "      <th>seville_weather_main</th>\n",
              "      <th>seville_weather_description</th>\n",
              "      <th>seville_weather_icon</th>\n",
              "      <th>price_actual</th>\n",
              "      <th>item_ID</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-01-02 00:00:00+01:00</th>\n",
              "      <td>447.0</td>\n",
              "      <td>329.0</td>\n",
              "      <td>4844.0</td>\n",
              "      <td>4821.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>863.0</td>\n",
              "      <td>1051.0</td>\n",
              "      <td>1899.0</td>\n",
              "      <td>7096.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>64.02</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-02 01:00:00+01:00</th>\n",
              "      <td>449.0</td>\n",
              "      <td>328.0</td>\n",
              "      <td>5196.0</td>\n",
              "      <td>4755.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>920.0</td>\n",
              "      <td>1009.0</td>\n",
              "      <td>1658.0</td>\n",
              "      <td>7096.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>58.46</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-02 02:00:00+01:00</th>\n",
              "      <td>448.0</td>\n",
              "      <td>323.0</td>\n",
              "      <td>4857.0</td>\n",
              "      <td>4581.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>1164.0</td>\n",
              "      <td>973.0</td>\n",
              "      <td>1371.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>54.70</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-02 03:00:00+01:00</th>\n",
              "      <td>438.0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>4314.0</td>\n",
              "      <td>4131.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>1503.0</td>\n",
              "      <td>949.0</td>\n",
              "      <td>779.0</td>\n",
              "      <td>7098.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>54.91</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-02 04:00:00+01:00</th>\n",
              "      <td>428.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>4130.0</td>\n",
              "      <td>3840.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>1826.0</td>\n",
              "      <td>953.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>7097.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>53.07</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 92 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-402eb217-4e71-408a-93e0-f8e89504c468')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-402eb217-4e71-408a-93e0-f8e89504c468 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-402eb217-4e71-408a-93e0-f8e89504c468');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f256a0a4-37a8-4af0-a40d-b9c63fde18e6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f256a0a4-37a8-4af0-a40d-b9c63fde18e6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f256a0a4-37a8-4af0-a40d-b9c63fde18e6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (26280, 92)\n",
            "\n",
            "--- テストデータ (test_df) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                           generation_biomass  \\\n",
              "time                                            \n",
              "2018-01-01 00:00:00+01:00               279.0   \n",
              "2018-01-01 01:00:00+01:00               282.0   \n",
              "2018-01-01 02:00:00+01:00               283.0   \n",
              "2018-01-01 03:00:00+01:00               280.0   \n",
              "2018-01-01 04:00:00+01:00               286.0   \n",
              "\n",
              "                           generation_fossil_brown_coal/lignite  \\\n",
              "time                                                              \n",
              "2018-01-01 00:00:00+01:00                                   0.0   \n",
              "2018-01-01 01:00:00+01:00                                   0.0   \n",
              "2018-01-01 02:00:00+01:00                                   0.0   \n",
              "2018-01-01 03:00:00+01:00                                   0.0   \n",
              "2018-01-01 04:00:00+01:00                                   0.0   \n",
              "\n",
              "                           generation_fossil_gas  generation_fossil_hard_coal  \\\n",
              "time                                                                            \n",
              "2018-01-01 00:00:00+01:00                 3927.0                        895.0   \n",
              "2018-01-01 01:00:00+01:00                 3948.0                        878.0   \n",
              "2018-01-01 02:00:00+01:00                 3791.0                        890.0   \n",
              "2018-01-01 03:00:00+01:00                 3671.0                        881.0   \n",
              "2018-01-01 04:00:00+01:00                 3460.0                        861.0   \n",
              "\n",
              "                           generation_fossil_oil  \\\n",
              "time                                               \n",
              "2018-01-01 00:00:00+01:00                  189.0   \n",
              "2018-01-01 01:00:00+01:00                  177.0   \n",
              "2018-01-01 02:00:00+01:00                  175.0   \n",
              "2018-01-01 03:00:00+01:00                  175.0   \n",
              "2018-01-01 04:00:00+01:00                  173.0   \n",
              "\n",
              "                           generation_hydro_pumped_storage_consumption  \\\n",
              "time                                                                     \n",
              "2018-01-01 00:00:00+01:00                                        230.0   \n",
              "2018-01-01 01:00:00+01:00                                       1269.0   \n",
              "2018-01-01 02:00:00+01:00                                       2197.0   \n",
              "2018-01-01 03:00:00+01:00                                       2965.0   \n",
              "2018-01-01 04:00:00+01:00                                       2705.0   \n",
              "\n",
              "                           generation_hydro_run_of_river_and_poundage  \\\n",
              "time                                                                    \n",
              "2018-01-01 00:00:00+01:00                                      1069.0   \n",
              "2018-01-01 01:00:00+01:00                                      1058.0   \n",
              "2018-01-01 02:00:00+01:00                                      1052.0   \n",
              "2018-01-01 03:00:00+01:00                                      1032.0   \n",
              "2018-01-01 04:00:00+01:00                                      1001.0   \n",
              "\n",
              "                           generation_hydro_water_reservoir  \\\n",
              "time                                                          \n",
              "2018-01-01 00:00:00+01:00                            1893.0   \n",
              "2018-01-01 01:00:00+01:00                            1024.0   \n",
              "2018-01-01 02:00:00+01:00                             888.0   \n",
              "2018-01-01 03:00:00+01:00                             645.0   \n",
              "2018-01-01 04:00:00+01:00                             661.0   \n",
              "\n",
              "                           generation_nuclear  generation_other  ...  \\\n",
              "time                                                             ...   \n",
              "2018-01-01 00:00:00+01:00              7104.0              53.0  ...   \n",
              "2018-01-01 01:00:00+01:00              7101.0              52.0  ...   \n",
              "2018-01-01 02:00:00+01:00              7100.0              52.0  ...   \n",
              "2018-01-01 03:00:00+01:00              7101.0              53.0  ...   \n",
              "2018-01-01 04:00:00+01:00              7101.0              53.0  ...   \n",
              "\n",
              "                           seville_wind_deg  seville_rain_1h  seville_rain_3h  \\\n",
              "time                                                                            \n",
              "2018-01-01 00:00:00+01:00               343              0.0              0.0   \n",
              "2018-01-01 01:00:00+01:00               343              0.0              0.0   \n",
              "2018-01-01 02:00:00+01:00                 0              0.0              0.0   \n",
              "2018-01-01 03:00:00+01:00                40              0.0              0.0   \n",
              "2018-01-01 04:00:00+01:00                30              0.0              0.0   \n",
              "\n",
              "                           seville_snow_3h  seville_clouds_all  \\\n",
              "time                                                             \n",
              "2018-01-01 00:00:00+01:00                0                   0   \n",
              "2018-01-01 01:00:00+01:00                0                   0   \n",
              "2018-01-01 02:00:00+01:00                0                   0   \n",
              "2018-01-01 03:00:00+01:00                0                   0   \n",
              "2018-01-01 04:00:00+01:00                0                   0   \n",
              "\n",
              "                           seville_weather_id  seville_weather_main  \\\n",
              "time                                                                  \n",
              "2018-01-01 00:00:00+01:00                 800                 clear   \n",
              "2018-01-01 01:00:00+01:00                 800                 clear   \n",
              "2018-01-01 02:00:00+01:00                 800                 clear   \n",
              "2018-01-01 03:00:00+01:00                 800                 clear   \n",
              "2018-01-01 04:00:00+01:00                 800                 clear   \n",
              "\n",
              "                           seville_weather_description  seville_weather_icon  \\\n",
              "time                                                                           \n",
              "2018-01-01 00:00:00+01:00                 sky is clear                   01n   \n",
              "2018-01-01 01:00:00+01:00                 sky is clear                   01n   \n",
              "2018-01-01 02:00:00+01:00                 sky is clear                   01n   \n",
              "2018-01-01 03:00:00+01:00                 sky is clear                   01n   \n",
              "2018-01-01 04:00:00+01:00                 sky is clear                   01n   \n",
              "\n",
              "                               item_ID  \n",
              "time                                    \n",
              "2018-01-01 00:00:00+01:00  spain_total  \n",
              "2018-01-01 01:00:00+01:00  spain_total  \n",
              "2018-01-01 02:00:00+01:00  spain_total  \n",
              "2018-01-01 03:00:00+01:00  spain_total  \n",
              "2018-01-01 04:00:00+01:00  spain_total  \n",
              "\n",
              "[5 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5cae1c44-46f4-4b6f-9f1d-3fd7ec7f5eee\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generation_biomass</th>\n",
              "      <th>generation_fossil_brown_coal/lignite</th>\n",
              "      <th>generation_fossil_gas</th>\n",
              "      <th>generation_fossil_hard_coal</th>\n",
              "      <th>generation_fossil_oil</th>\n",
              "      <th>generation_hydro_pumped_storage_consumption</th>\n",
              "      <th>generation_hydro_run_of_river_and_poundage</th>\n",
              "      <th>generation_hydro_water_reservoir</th>\n",
              "      <th>generation_nuclear</th>\n",
              "      <th>generation_other</th>\n",
              "      <th>...</th>\n",
              "      <th>seville_wind_deg</th>\n",
              "      <th>seville_rain_1h</th>\n",
              "      <th>seville_rain_3h</th>\n",
              "      <th>seville_snow_3h</th>\n",
              "      <th>seville_clouds_all</th>\n",
              "      <th>seville_weather_id</th>\n",
              "      <th>seville_weather_main</th>\n",
              "      <th>seville_weather_description</th>\n",
              "      <th>seville_weather_icon</th>\n",
              "      <th>item_ID</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2018-01-01 00:00:00+01:00</th>\n",
              "      <td>279.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3927.0</td>\n",
              "      <td>895.0</td>\n",
              "      <td>189.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>1069.0</td>\n",
              "      <td>1893.0</td>\n",
              "      <td>7104.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>...</td>\n",
              "      <td>343</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 01:00:00+01:00</th>\n",
              "      <td>282.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3948.0</td>\n",
              "      <td>878.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>1269.0</td>\n",
              "      <td>1058.0</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>7101.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>...</td>\n",
              "      <td>343</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 02:00:00+01:00</th>\n",
              "      <td>283.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3791.0</td>\n",
              "      <td>890.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>2197.0</td>\n",
              "      <td>1052.0</td>\n",
              "      <td>888.0</td>\n",
              "      <td>7100.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 03:00:00+01:00</th>\n",
              "      <td>280.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3671.0</td>\n",
              "      <td>881.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>2965.0</td>\n",
              "      <td>1032.0</td>\n",
              "      <td>645.0</td>\n",
              "      <td>7101.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 04:00:00+01:00</th>\n",
              "      <td>286.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3460.0</td>\n",
              "      <td>861.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>2705.0</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>661.0</td>\n",
              "      <td>7101.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>...</td>\n",
              "      <td>30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 91 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5cae1c44-46f4-4b6f-9f1d-3fd7ec7f5eee')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5cae1c44-46f4-4b6f-9f1d-3fd7ec7f5eee button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5cae1c44-46f4-4b6f-9f1d-3fd7ec7f5eee');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1f919c9b-26a0-48b0-bb91-d6707a0bfeb2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1f919c9b-26a0-48b0-bb91-d6707a0bfeb2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1f919c9b-26a0-48b0-bb91-d6707a0bfeb2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (8760, 91)\n",
            "\n",
            "--- サンプル提出 (sample_submission_df) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                           0  1\n",
              "0  2018-01-01 00:00:00+01:00  0\n",
              "1  2018-01-01 01:00:00+01:00  0\n",
              "2  2018-01-01 02:00:00+01:00  0\n",
              "3  2018-01-01 03:00:00+01:00  0\n",
              "4  2018-01-01 04:00:00+01:00  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2dfcaeef-eb6d-4cc9-b16d-b442c051070e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-01 00:00:00+01:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-01 01:00:00+01:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-01 02:00:00+01:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-01 03:00:00+01:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-01 04:00:00+01:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2dfcaeef-eb6d-4cc9-b16d-b442c051070e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2dfcaeef-eb6d-4cc9-b16d-b442c051070e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2dfcaeef-eb6d-4cc9-b16d-b442c051070e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-34303529-7542-41e5-b14a-e89fe6dee253\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34303529-7542-41e5-b14a-e89fe6dee253')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-34303529-7542-41e5-b14a-e89fe6dee253 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(f\\\"shape: {sample_submission_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2018-01-01 01:00:00+01:00\",\n          \"2018-01-01 04:00:00+01:00\",\n          \"2018-01-01 02:00:00+01:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (8760, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データの前処理\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FOl1SGI5QnSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 基本情報を確認\n",
        "print(f\"データのサイズ: {df.shape}\")\n",
        "print(f\"期間: {df.index.min()} から {df.index.max()}\")\n",
        "print(f\"推論対象の期間: {test_df.index.min()} から {test_df.index.max()}\")\n",
        "print(f\"⽋損値の合計: {df.isna().sum().sum()}\")\n",
        "# ⽋損値を処理\n",
        "# 時系列データなので、前⽅補間が適切\n",
        "#df = df.fillna(method='ffill')\n",
        "df = df.ffill()\n",
        "# まだ⽋損がある場合は後⽅補間\n",
        "#df = df.fillna(method='bfill')\n",
        "df = df.bfill()\n",
        "# ⽬的変数の確認\n",
        "print(\"\\n⽬的変数 'price_actual' の統計:\")\n",
        "print(df['price_actual'].describe())\n",
        "# 価格の時系列プロット\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(df.index, df['price_actual'])\n",
        "plt.title('電⼒価格の推移')\n",
        "plt.ylabel('価格')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('price_time_series.png')\n",
        "plt.close()\n",
        "# 説明変数を準備\n",
        "# item_IDはスペインの合計データのみ使⽤\n",
        "df = df[df['item_ID'] == 'spain_total']\n",
        "# 不要な列を削除\n",
        "X = df.drop(['price_actual', 'item_ID'], axis=1)\n",
        "# ⽬的変数\n",
        "y = df['price_actual']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHKftlr8Qqib",
        "outputId": "6fbfb8b3-f304-4f82-cec2-b857dd2ce037"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "データのサイズ: (26280, 92)\n",
            "期間: 2015-01-02 00:00:00+01:00 から 2017-12-31 23:00:00+01:00\n",
            "推論対象の期間: 2018-01-01 00:00:00+01:00 から 2018-12-31 23:00:00+01:00\n",
            "⽋損値の合計: 321\n",
            "\n",
            "⽬的変数 'price_actual' の統計:\n",
            "count    26280.000000\n",
            "mean        56.028338\n",
            "std         14.340356\n",
            "min          9.330000\n",
            "25%         47.617500\n",
            "50%         55.930000\n",
            "75%         65.192500\n",
            "max        116.800000\n",
            "Name: price_actual, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 特徴量エンジニアリング"
      ],
      "metadata": {
        "id": "fK3TvhMbxZ24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_additional_features(df):\n",
        "    \"\"\"\n",
        "    時間ベースの特徴量とラグ特徴量を作成\n",
        "    \"\"\"\n",
        "    df_features = df.copy()\n",
        "\n",
        "    # インデックスがDatetimeIndexであることを確認し、必要なら変換\n",
        "    if not isinstance(df_features.index, pd.DatetimeIndex) or df_features.index.tz is not None:\n",
        "        df_features.index = pd.to_datetime(df_features.index, utc=True)\n",
        "\n",
        "    # ここから既存の時間ベースの特徴量作成コード\n",
        "    df_features['hour'] = df_features.index.hour\n",
        "    df_features['dayofweek'] = df_features.index.dayofweek\n",
        "    df_features['month'] = df_features.index.month\n",
        "    df_features['year'] = df_features.index.year\n",
        "    df_features['quarter'] = df_features.index.quarter\n",
        "    df_features['dayofyear'] = df_features.index.dayofyear\n",
        "    # ISO週番号の取得方法が古いバージョンのPandasで異なる場合があります。\n",
        "    # .weekofyear は非推奨になったため、.isocalendar().week を使用するのが推奨です。\n",
        "    # ただし、もし古いPandasバージョンでisocalendarが使えない場合は .weekofyear を試してください。\n",
        "    try:\n",
        "        df_features['weekofyear'] = df_features.index.isocalendar().week.astype(int) # ISO週番号\n",
        "    except AttributeError:\n",
        "        # もし isocalendar がない場合は、古い .weekofyear を試す\n",
        "        print(\"警告: .isocalendar() が見つかりません。代わりに .weekofyear を使用します。Pandasのバージョンを確認してください。\")\n",
        "        df_features['weekofyear'] = df_features.index.weekofyear.astype(int)\n",
        "\n",
        "    df_features['dayofmonth'] = df_features.index.day\n",
        "    df_features['is_weekend'] = (df_features.index.dayofweek >= 5).astype(int)\n",
        "\n",
        "    # ラグ特徴量（例: 1時間前、24時間前、48時間前、1週間前）\n",
        "    # ... (既存のラグ特徴量作成コード)\n",
        "    df_features['price_actual_lag_1'] = df_features['price_actual'].shift(1)\n",
        "    df_features['price_actual_lag_24'] = df_features['price_actual'].shift(24)\n",
        "    df_features['price_actual_lag_48'] = df_features['price_actual'].shift(48)\n",
        "    df_features['price_actual_lag_168'] = df_features['price_actual'].shift(168) # 1週間前\n",
        "\n",
        "    # 必要に応じて他の特徴量のラグも追加できます。\n",
        "    # 例: df_features['consumption_lag_24'] = df_features['consumption'].shift(24)\n",
        "\n",
        "    # 移動平均（例: 24時間の移動平均）\n",
        "    df_features['price_actual_rolling_mean_24'] = df_features['price_actual'].rolling(window=24).mean()\n",
        "\n",
        "    # 指数平滑化（例: span=24の指数平滑化）\n",
        "    #df_features['price_actual_ewm_24'] = df_features['price_actual'].ewm(span=24).mean()\n",
        "\n",
        "\n",
        "    # 新たに生成された特徴量によって発生する可能性のある欠損値を処理\n",
        "    df_features = df_features.ffill()\n",
        "    df_features = df_features.bfill()\n",
        "\n",
        "    return df_features"
      ],
      "metadata": {
        "id": "ksJ_f75-xfMZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 特徴量選択と次元削減"
      ],
      "metadata": {
        "id": "76OSHBupRJ3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量選択（f_regressionを使って上位の特徴を選択）\n",
        "def select_features_and_scale(X, y, k=30):\n",
        "    \"\"\"\n",
        "    特徴量選択前に標準化を行い、選択された特徴量を返す\n",
        "    \"\"\"\n",
        "    # 数値型以外のカラムを削除\n",
        "    X_numeric = X.select_dtypes(include=np.number)\n",
        "\n",
        "    # 標準化\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_numeric)\n",
        "    X_scaled_df = pd.DataFrame(X_scaled, index=X_numeric.index, columns=X_numeric.columns) # DataFrameに戻す\n",
        "\n",
        "    # もし数値型カラムがkより少ない場合はkを調整\n",
        "    k = min(k, X_scaled_df.shape[1])\n",
        "\n",
        "    selector = SelectKBest(score_func=f_regression, k=k)\n",
        "    X_selected_scaled = selector.fit_transform(X_scaled_df, y)\n",
        "\n",
        "    # 選択された特徴のインデックスを取得\n",
        "    selected_indices = selector.get_support(indices=True)\n",
        "    selected_features = X_scaled_df.columns[selected_indices]\n",
        "    print(f\"標準化後、選択された特徴量 ({k}個): {selected_features.tolist()}\")\n",
        "\n",
        "    # 選択された特徴量を DataFrame として返す（スケール済み）\n",
        "    return pd.DataFrame(X_selected_scaled, index=X_numeric.index, columns=selected_features), scaler, selector\n",
        "\n",
        "# PCAで次元削減 (選択された特徴量に対して適用)\n",
        "def apply_pca_on_selected(X_selected_scaled, n_components=15):\n",
        "  # X_selected_scaled はすでに StandardScaler でスケール済みを想定\n",
        "  pca = PCA(n_components=n_components)\n",
        "  X_pca = pca.fit_transform(X_selected_scaled)\n",
        "\n",
        "  # 説明された分散の比率を確認\n",
        "  explained_variance = pca.explained_variance_ratio_.sum()\n",
        "  print(f\"PCAにより{n_components}成分で{explained_variance:.2%}の分散を説明 (選択特徴量から)\")\n",
        "  return X_pca, pca\n",
        "\n",
        "# 特徴量エンジニアリングを適用\n",
        "df_featured = create_additional_features(df.copy())\n",
        "\n",
        "# 特徴量エンジニアリング後のデータから説明変数と目的変数を作成\n",
        "X_featured = df_featured.drop(['price_actual', 'item_ID'], axis=1)\n",
        "y_featured = df_featured['price_actual']\n",
        "\n",
        "# 特徴量選択と標準化を適用\n",
        "X_selected_scaled, feature_scaler, feature_selector = select_features_and_scale(X_featured, y_featured, k=30)\n",
        "\n",
        "# 選択された特徴量にPCAを適用\n",
        "X_pca, pca = apply_pca_on_selected(X_selected_scaled, n_components=15)\n",
        "\n",
        "# ✅ ここで履歴長を定義\n",
        "seq_length = 24\n",
        "\n",
        "# 相関ヒートマップ（選択された特徴量 - スケール済み）\n",
        "# X_selected_scaled が DataFrame なのでそのまま corr() を使用\n",
        "plt.figure(figsize=(15, 12))\n",
        "correlation = X_selected_scaled.corr()\n",
        "mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
        "sns.heatmap(correlation, mask=mask, annot=False, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('標準化・選択された特徴量の相関ヒートマップ')\n",
        "plt.tight_layout()\n",
        "plt.savefig('selected_feature_correlation.png')\n",
        "plt.close()\n",
        "\n",
        "# PCA を外す場合のデータ準備 (スケール済み・選択済みだが PCA なし)\n",
        "X_no_pca = X_selected_scaled.values # numpy 配列として取得\n",
        "print(f\"PCA適用なしデータ形状: {X_no_pca.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ4me37_RKgH",
        "outputId": "e940c6f6-b014-491c-9fcc-485eebc315ae"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "標準化後、選択された特徴量 (30個): ['generation_biomass', 'generation_fossil_brown_coal/lignite', 'generation_fossil_gas', 'generation_fossil_hard_coal', 'generation_fossil_oil', 'generation_hydro_pumped_storage_consumption', 'generation_hydro_run_of_river_and_poundage', 'generation_other', 'total_load_actual', 'valencia_wind_speed', 'madrid_wind_speed', 'bilbao_pressure', 'bilbao_wind_speed', 'bilbao_wind_deg', 'bilbao_clouds_all', 'barcelona_wind_speed', 'seville_pressure', 'seville_wind_deg', 'hour', 'dayofweek', 'month', 'quarter', 'dayofyear', 'weekofyear', 'is_weekend', 'price_actual_lag_1', 'price_actual_lag_24', 'price_actual_lag_48', 'price_actual_lag_168', 'price_actual_rolling_mean_24']\n",
            "PCAにより15成分で88.59%の分散を説明 (選択特徴量から)\n",
            "PCA適用なしデータ形状: (26280, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 時系列データの準備"
      ],
      "metadata": {
        "id": "BXJU5TStRqwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(X, y, seq_length=24):\n",
        "    \"\"\"\n",
        "    時系列データのシーケンスを作成\n",
        "    seq_length: 何時間前までのデータを使うか（例：24時間）\n",
        "    \"\"\"\n",
        "    X_seq, y_seq = [], []\n",
        "\n",
        "    for i in range(len(X) - seq_length):\n",
        "        X_seq.append(X[i:i+seq_length])\n",
        "        y_seq.append(y[i+seq_length])\n",
        "\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# スケーリング\n",
        "y_scaler = MinMaxScaler()\n",
        "y_scaled = y_scaler.fit_transform(y_featured.values.reshape(-1, 1))\n",
        "\n",
        "# データセットの分割割合\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "\n",
        "train_size = int(len(X_featured) * train_ratio)\n",
        "val_size = int(len(X_featured) * val_ratio)\n",
        "test_size = len(X_featured) - train_size - val_size # 残りをテストサイズとする\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# PCA適用データでの分割とシーケンス作成\n",
        "# -------------------------------------------------------------\n",
        "print(\"--- PCA適用データ ---\")\n",
        "X_train_pca = X_pca[:train_size]\n",
        "X_val_pca = X_pca[train_size:train_size+val_size]\n",
        "X_test_pca = X_pca[train_size+val_size:train_size+val_size+test_size]\n",
        "\n",
        "y_train_scaled_pca = y_scaled[:train_size]\n",
        "y_val_scaled_pca = y_scaled[train_size:train_size+val_size]\n",
        "y_test_scaled_pca = y_scaled[train_size+val_size:train_size+val_size+test_size]\n",
        "\n",
        "\n",
        "X_train_seq_pca, y_train_seq_pca = create_sequences(X_train_pca, y_train_scaled_pca, seq_length)\n",
        "X_val_seq_pca, y_val_seq_pca = create_sequences(X_val_pca, y_val_scaled_pca, seq_length)\n",
        "X_test_seq_pca, y_test_seq_pca = create_sequences(X_test_pca, y_test_scaled_pca, seq_length)\n",
        "\n",
        "print(f\"PCA適用トレーニングデータ形状: {X_train_seq_pca.shape}, {y_train_seq_pca.shape}\")\n",
        "print(f\"PCA適用検証データ形状: {X_val_seq_pca.shape}, {y_val_seq_pca.shape}\")\n",
        "print(f\"PCA適用テストデータ形状: {X_test_seq_pca.shape}, {y_test_seq_pca.shape}\")\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# PCA適用なしデータでの分割とシーケンス作成\n",
        "# X_no_pca はすでに select_features_and_scale でスケール済み\n",
        "# -------------------------------------------------------------\n",
        "print(\"\\n--- PCA適用なしデータ ---\")\n",
        "X_train_no_pca = X_no_pca[:train_size]\n",
        "X_val_no_pca = X_no_pca[train_size:train_size+val_size]\n",
        "X_test_no_pca = X_no_pca[train_size+val_size:train_size+val_size+test_size]\n",
        "\n",
        "# 目的変数は共通のスケーリング済みデータを使用\n",
        "y_train_scaled_no_pca = y_scaled[:train_size]\n",
        "y_val_scaled_no_pca = y_scaled[train_size:train_size+val_size]\n",
        "y_test_scaled_no_pca = y_scaled[train_size+val_size:train_size+val_size+test_size]\n",
        "\n",
        "\n",
        "X_train_seq_no_pca, y_train_seq_no_pca = create_sequences(X_train_no_pca, y_train_scaled_no_pca, seq_length)\n",
        "X_val_seq_no_pca, y_val_seq_no_pca = create_sequences(X_val_no_pca, y_val_scaled_no_pca, seq_length)\n",
        "X_test_seq_no_pca, y_test_seq_no_pca = create_sequences(X_test_no_pca, y_test_scaled_no_pca, seq_length)\n",
        "\n",
        "\n",
        "print(f\"PCAなしトレーニングデータ形状: {X_train_seq_no_pca.shape}, {y_train_seq_no_pca.shape}\")\n",
        "print(f\"PCAなし検証データ形状: {X_val_seq_no_pca.shape}, {y_val_seq_no_pca.shape}\")\n",
        "print(f\"PCAなしテストデータ形状: {X_test_seq_no_pca.shape}, {y_test_seq_no_pca.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_DDT356RsTM",
        "outputId": "89f2d648-1add-4503-bbd3-3e368750b7fa"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- PCA適用データ ---\n",
            "PCA適用トレーニングデータ形状: (21000, 24, 15), (21000, 1)\n",
            "PCA適用検証データ形状: (2604, 24, 15), (2604, 1)\n",
            "PCA適用テストデータ形状: (2604, 24, 15), (2604, 1)\n",
            "\n",
            "--- PCA適用なしデータ ---\n",
            "PCAなしトレーニングデータ形状: (21000, 24, 30), (21000, 1)\n",
            "PCAなし検証データ形状: (2604, 24, 30), (2604, 1)\n",
            "PCAなしテストデータ形状: (2604, 24, 30), (2604, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデル構築と学習"
      ],
      "metadata": {
        "id": "D4bFBd9tR2Jk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTMモデル (PCA適用データ)"
      ],
      "metadata": {
        "id": "yVR_GONJSc-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm_model(seq_length, n_features):\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=(seq_length, n_features)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        LSTM(128, return_sequences=False),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "    return model\n",
        "\n",
        "# LSTMモデルの構築 (PCA適用データ)\n",
        "lstm_model_pca = build_lstm_model(seq_length, X_train_seq_pca.shape[2])\n",
        "print(\"\\n--- LSTMモデル (PCA適用) ---\")\n",
        "print(lstm_model_pca.summary())\n",
        "\n",
        "# コールバックの設定\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=15,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "checkpoint_pca = ModelCheckpoint(\n",
        "    data_path + 'lstm_model_pca.h5', # ファイル名を変更して区別\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=0.0001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# モデルの学習 (PCA適用データ)\n",
        "print(\"\\n--- LSTMモデル学習開始 (PCA適用) ---\")\n",
        "lstm_history_pca = lstm_model_pca.fit(\n",
        "    X_train_seq_pca, y_train_seq_pca,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val_seq_pca, y_val_seq_pca),\n",
        "    callbacks=[early_stopping, checkpoint_pca, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 学習履歴のプロット部分 (PCA適用)\n",
        "plt.figure(figsize=(7, 5))\n",
        "\n",
        "plt.plot(lstm_history_pca.history['loss'], label='Training Loss')\n",
        "plt.plot(lstm_history_pca.history['val_loss'], label='Validation Loss')\n",
        "plt.title('LSTM (PCA) - Loss (MSE)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('lstm_training_history_loss_pca.png') # ファイル名を変更\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "ut-_ZiltR3a_",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98433780-4c56-4fe8-b638-0c1f270db69f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- LSTMモデル (PCA適用) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m20,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m124,225\u001b[0m (485.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,225</span> (485.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m123,841\u001b[0m (483.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,841</span> (483.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\n",
            "--- LSTMモデル学習開始 (PCA適用) ---\n",
            "Epoch 1/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3725\n",
            "Epoch 1: val_loss improved from inf to 0.01439, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.3706 - val_loss: 0.0144 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0257\n",
            "Epoch 2: val_loss improved from 0.01439 to 0.00484, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0256 - val_loss: 0.0048 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0127\n",
            "Epoch 3: val_loss improved from 0.00484 to 0.00403, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0127 - val_loss: 0.0040 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0108\n",
            "Epoch 4: val_loss improved from 0.00403 to 0.00367, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0108 - val_loss: 0.0037 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0097\n",
            "Epoch 5: val_loss improved from 0.00367 to 0.00246, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0097 - val_loss: 0.0025 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0087\n",
            "Epoch 6: val_loss improved from 0.00246 to 0.00197, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0087 - val_loss: 0.0020 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0082\n",
            "Epoch 7: val_loss did not improve from 0.00197\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0082 - val_loss: 0.0023 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0084\n",
            "Epoch 8: val_loss did not improve from 0.00197\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0084 - val_loss: 0.0031 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0074\n",
            "Epoch 9: val_loss did not improve from 0.00197\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0074 - val_loss: 0.0031 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0074\n",
            "Epoch 10: val_loss improved from 0.00197 to 0.00133, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0074 - val_loss: 0.0013 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0064\n",
            "Epoch 11: val_loss did not improve from 0.00133\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0064 - val_loss: 0.0059 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0079\n",
            "Epoch 12: val_loss did not improve from 0.00133\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0079 - val_loss: 0.0024 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0063\n",
            "Epoch 13: val_loss did not improve from 0.00133\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0063 - val_loss: 0.0018 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0061\n",
            "Epoch 14: val_loss did not improve from 0.00133\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0061 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0060\n",
            "Epoch 15: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0059 - val_loss: 0.0026 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0049\n",
            "Epoch 16: val_loss did not improve from 0.00133\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0049 - val_loss: 0.0024 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0046\n",
            "Epoch 17: val_loss did not improve from 0.00133\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0046 - val_loss: 0.0021 - learning_rate: 2.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0045\n",
            "Epoch 18: val_loss did not improve from 0.00133\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0020 - learning_rate: 2.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043\n",
            "Epoch 19: val_loss did not improve from 0.00133\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0043 - val_loss: 0.0021 - learning_rate: 2.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0043\n",
            "Epoch 20: val_loss did not improve from 0.00133\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0043 - val_loss: 0.0020 - learning_rate: 2.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0041\n",
            "Epoch 21: val_loss did not improve from 0.00133\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0020 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040\n",
            "Epoch 22: val_loss did not improve from 0.00133\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0040 - val_loss: 0.0020 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0040\n",
            "Epoch 23: val_loss did not improve from 0.00133\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0040 - val_loss: 0.0020 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038\n",
            "Epoch 24: val_loss did not improve from 0.00133\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0038 - val_loss: 0.0019 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0038\n",
            "Epoch 25: val_loss did not improve from 0.00133\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0018 - learning_rate: 1.0000e-04\n",
            "Epoch 25: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTMモデル (PCA適用なし)"
      ],
      "metadata": {
        "id": "cC4Z9Tk6Y8N-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTMモデルの構築 (PCA適用なしデータ)\n",
        "# n_features が X_train_seq_no_pca の特徴量数になる\n",
        "lstm_model_no_pca = build_lstm_model(seq_length, X_train_seq_no_pca.shape[2])\n",
        "print(\"\\n--- LSTMモデル (PCA適用なし) ---\")\n",
        "print(lstm_model_no_pca.summary())\n",
        "\n",
        "checkpoint_no_pca = ModelCheckpoint(\n",
        "    data_path + 'lstm_model_no_pca.h5', # ファイル名を変更して区別\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "# モデルの学習 (PCA適用なしデータ)\n",
        "print(\"\\n--- LSTMモデル学習開始 (PCA適用なし) ---\")\n",
        "lstm_history_no_pca = lstm_model_no_pca.fit(\n",
        "    X_train_seq_no_pca, y_train_seq_no_pca,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val_seq_no_pca, y_val_seq_no_pca),\n",
        "    callbacks=[early_stopping, checkpoint_no_pca, reduce_lr], # 同じコールバックを使用\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 学習履歴のプロット部分 (PCA適用なし)\n",
        "plt.figure(figsize=(7, 5))\n",
        "\n",
        "plt.plot(lstm_history_no_pca.history['loss'], label='Training Loss')\n",
        "plt.plot(lstm_history_no_pca.history['val_loss'], label='Validation Loss')\n",
        "plt.title('LSTM (No PCA) - Loss (MSE)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('lstm_training_history_loss_no_pca.png') # ファイル名を変更\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "WR7zqgCrY_ZY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40ac893b-4e18-49e0-e47f-d55e3ea1a2a5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- LSTMモデル (PCA適用なし) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m24,320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_15 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m128,065\u001b[0m (500.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,065</span> (500.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m127,681\u001b[0m (498.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">127,681</span> (498.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\n",
            "--- LSTMモデル学習開始 (PCA適用なし) ---\n",
            "Epoch 1/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4335\n",
            "Epoch 1: val_loss improved from inf to 0.02653, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - loss: 0.4328 - val_loss: 0.0265 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0372\n",
            "Epoch 2: val_loss improved from 0.02653 to 0.00767, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0371 - val_loss: 0.0077 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0167\n",
            "Epoch 3: val_loss improved from 0.00767 to 0.00455, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0167 - val_loss: 0.0045 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0124\n",
            "Epoch 4: val_loss improved from 0.00455 to 0.00363, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0124 - val_loss: 0.0036 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0106\n",
            "Epoch 5: val_loss improved from 0.00363 to 0.00343, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0106 - val_loss: 0.0034 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0092\n",
            "Epoch 6: val_loss did not improve from 0.00343\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0092 - val_loss: 0.0042 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0078\n",
            "Epoch 7: val_loss improved from 0.00343 to 0.00264, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0078 - val_loss: 0.0026 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0075\n",
            "Epoch 8: val_loss did not improve from 0.00264\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0075 - val_loss: 0.0029 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0068\n",
            "Epoch 9: val_loss improved from 0.00264 to 0.00235, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0068 - val_loss: 0.0024 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0066\n",
            "Epoch 10: val_loss improved from 0.00235 to 0.00209, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0066 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0065\n",
            "Epoch 11: val_loss did not improve from 0.00209\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0065 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0064\n",
            "Epoch 12: val_loss did not improve from 0.00209\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0064 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0074\n",
            "Epoch 13: val_loss did not improve from 0.00209\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0074 - val_loss: 0.0025 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0066\n",
            "Epoch 14: val_loss improved from 0.00209 to 0.00183, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0066 - val_loss: 0.0018 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0059\n",
            "Epoch 15: val_loss did not improve from 0.00183\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0059 - val_loss: 0.0045 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0055\n",
            "Epoch 16: val_loss improved from 0.00183 to 0.00136, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0055 - val_loss: 0.0014 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0055\n",
            "Epoch 17: val_loss improved from 0.00136 to 0.00134, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0055 - val_loss: 0.0013 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0051\n",
            "Epoch 18: val_loss did not improve from 0.00134\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0051 - val_loss: 0.0016 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0052\n",
            "Epoch 19: val_loss did not improve from 0.00134\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0052 - val_loss: 0.0015 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0043\n",
            "Epoch 20: val_loss improved from 0.00134 to 0.00115, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0043 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0037\n",
            "Epoch 21: val_loss did not improve from 0.00115\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0037 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036\n",
            "Epoch 22: val_loss improved from 0.00115 to 0.00112, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0036 - val_loss: 0.0011 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0036\n",
            "Epoch 23: val_loss did not improve from 0.00112\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0036 - val_loss: 0.0011 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036\n",
            "Epoch 24: val_loss improved from 0.00112 to 0.00108, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0035 - val_loss: 0.0011 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032\n",
            "Epoch 25: val_loss did not improve from 0.00108\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027\n",
            "Epoch 26: val_loss improved from 0.00108 to 0.00095, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0027 - val_loss: 9.4596e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0026\n",
            "Epoch 27: val_loss improved from 0.00095 to 0.00091, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0026 - val_loss: 9.0814e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025\n",
            "Epoch 28: val_loss did not improve from 0.00091\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 9.3015e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0025\n",
            "Epoch 29: val_loss improved from 0.00091 to 0.00091, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0025 - val_loss: 9.0752e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0025\n",
            "Epoch 30: val_loss improved from 0.00091 to 0.00089, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0025 - val_loss: 8.8802e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024\n",
            "Epoch 31: val_loss did not improve from 0.00089\n",
            "\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0024 - val_loss: 8.9025e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0023\n",
            "Epoch 32: val_loss improved from 0.00089 to 0.00087, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0023 - val_loss: 8.7214e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0023\n",
            "Epoch 33: val_loss did not improve from 0.00087\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0023 - val_loss: 8.8416e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0022\n",
            "Epoch 34: val_loss did not improve from 0.00087\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0022 - val_loss: 9.1367e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022\n",
            "Epoch 35: val_loss did not improve from 0.00087\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - val_loss: 8.7930e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022\n",
            "Epoch 36: val_loss improved from 0.00087 to 0.00086, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0022 - val_loss: 8.6169e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0022\n",
            "Epoch 37: val_loss did not improve from 0.00086\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0022 - val_loss: 8.8649e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021\n",
            "Epoch 38: val_loss did not improve from 0.00086\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 9.1242e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022\n",
            "Epoch 39: val_loss did not improve from 0.00086\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - val_loss: 8.8602e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0021\n",
            "Epoch 40: val_loss did not improve from 0.00086\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 8.8496e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021\n",
            "Epoch 41: val_loss did not improve from 0.00086\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 8.6934e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021\n",
            "Epoch 42: val_loss did not improve from 0.00086\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 8.8117e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0021\n",
            "Epoch 43: val_loss did not improve from 0.00086\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0021 - val_loss: 8.6882e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020\n",
            "Epoch 44: val_loss did not improve from 0.00086\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 8.6306e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020\n",
            "Epoch 45: val_loss did not improve from 0.00086\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 8.6709e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020\n",
            "Epoch 46: val_loss did not improve from 0.00086\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 8.6217e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0020\n",
            "Epoch 47: val_loss did not improve from 0.00086\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0020 - val_loss: 8.6541e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019\n",
            "Epoch 48: val_loss improved from 0.00086 to 0.00084, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0019 - val_loss: 8.4320e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019\n",
            "Epoch 49: val_loss did not improve from 0.00084\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 8.6287e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020\n",
            "Epoch 50: val_loss improved from 0.00084 to 0.00082, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0020 - val_loss: 8.1875e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019\n",
            "Epoch 51: val_loss improved from 0.00082 to 0.00081, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 8.0938e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019\n",
            "Epoch 52: val_loss did not improve from 0.00081\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 8.4961e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018\n",
            "Epoch 53: val_loss did not improve from 0.00081\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0018 - val_loss: 8.1409e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019\n",
            "Epoch 54: val_loss improved from 0.00081 to 0.00079, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0019 - val_loss: 7.8840e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019\n",
            "Epoch 55: val_loss did not improve from 0.00079\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 8.1010e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0019\n",
            "Epoch 56: val_loss did not improve from 0.00079\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0019 - val_loss: 7.9255e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0018\n",
            "Epoch 57: val_loss did not improve from 0.00079\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0018 - val_loss: 8.2673e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018\n",
            "Epoch 58: val_loss did not improve from 0.00079\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 7.8960e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018\n",
            "Epoch 59: val_loss did not improve from 0.00079\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 8.0768e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0018\n",
            "Epoch 60: val_loss did not improve from 0.00079\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0018 - val_loss: 8.0354e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019\n",
            "Epoch 61: val_loss did not improve from 0.00079\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 8.2541e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018\n",
            "Epoch 62: val_loss did not improve from 0.00079\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 7.9500e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018\n",
            "Epoch 63: val_loss did not improve from 0.00079\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 8.0717e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018\n",
            "Epoch 64: val_loss did not improve from 0.00079\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 7.8901e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017\n",
            "Epoch 65: val_loss did not improve from 0.00079\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0017 - val_loss: 8.1881e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017\n",
            "Epoch 66: val_loss did not improve from 0.00079\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 8.0018e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017\n",
            "Epoch 67: val_loss did not improve from 0.00079\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 8.0325e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017\n",
            "Epoch 68: val_loss did not improve from 0.00079\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0017 - val_loss: 8.1223e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017\n",
            "Epoch 69: val_loss did not improve from 0.00079\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 8.1082e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 69: early stopping\n",
            "Restoring model weights from the end of the best epoch: 54.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU モデル（PCA適用）"
      ],
      "metadata": {
        "id": "PHNk3HR6R9K4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gru_model(seq_length, n_features):\n",
        "    model = Sequential([\n",
        "        GRU(64, return_sequences=True, input_shape=(seq_length, n_features)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        GRU(128, return_sequences=False),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "    return model\n",
        "\n",
        "# GRUモデルの構築と学習 (PCA適用データ)\n",
        "gru_model_pca = build_gru_model(seq_length, X_train_seq_pca.shape[2])\n",
        "print(\"\\n--- GRUモデル (PCA適用) ---\")\n",
        "print(gru_model_pca.summary())\n",
        "\n",
        "checkpoint_gru_pca = ModelCheckpoint(\n",
        "    data_path + 'gru_model_pca.h5', # ファイル名を変更して区別\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "print(\"\\n--- GRUモデル学習開始 (PCA適用) ---\")\n",
        "gru_history_pca = gru_model_pca.fit(\n",
        "    X_train_seq_pca, y_train_seq_pca,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val_seq_pca, y_val_seq_pca),\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor='val_loss', patience=15, verbose=1, restore_best_weights=True),\n",
        "        checkpoint_gru_pca,\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001, verbose=1)\n",
        "    ],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# GRU 学習履歴のプロット部分 (PCA適用)\n",
        "plt.figure(figsize=(7, 5))\n",
        "\n",
        "plt.plot(gru_history_pca.history['loss'], label='Training Loss')\n",
        "plt.plot(gru_history_pca.history['val_loss'], label='Validation Loss')\n",
        "plt.title('GRU (PCA) - Loss (MSE)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('gru_training_history_loss_pca.png') # ファイル名を変更\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "CahFKpwiR96t",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7041e2e-afc8-449b-a50a-34df9c51b661"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- GRUモデル (PCA適用) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m15,552\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_5 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m74,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_21          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,552</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_21          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m94,977\u001b[0m (371.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">94,977</span> (371.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m94,593\u001b[0m (369.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">94,593</span> (369.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\n",
            "--- GRUモデル学習開始 (PCA適用) ---\n",
            "Epoch 1/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.8563\n",
            "Epoch 1: val_loss improved from inf to 0.03860, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.8516 - val_loss: 0.0386 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0737\n",
            "Epoch 2: val_loss improved from 0.03860 to 0.01297, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0734 - val_loss: 0.0130 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0281\n",
            "Epoch 3: val_loss improved from 0.01297 to 0.00634, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0280 - val_loss: 0.0063 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0133\n",
            "Epoch 4: val_loss improved from 0.00634 to 0.00445, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - loss: 0.0132 - val_loss: 0.0044 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0101\n",
            "Epoch 5: val_loss improved from 0.00445 to 0.00367, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0101 - val_loss: 0.0037 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0085\n",
            "Epoch 6: val_loss did not improve from 0.00367\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0085 - val_loss: 0.0041 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0080\n",
            "Epoch 7: val_loss improved from 0.00367 to 0.00207, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0080 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0075\n",
            "Epoch 8: val_loss did not improve from 0.00207\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0075 - val_loss: 0.0032 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0072\n",
            "Epoch 9: val_loss did not improve from 0.00207\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0072 - val_loss: 0.0033 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0065\n",
            "Epoch 10: val_loss did not improve from 0.00207\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0065 - val_loss: 0.0037 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0065\n",
            "Epoch 11: val_loss improved from 0.00207 to 0.00186, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0065 - val_loss: 0.0019 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0071\n",
            "Epoch 12: val_loss did not improve from 0.00186\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0071 - val_loss: 0.0027 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0067\n",
            "Epoch 13: val_loss improved from 0.00186 to 0.00131, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0067 - val_loss: 0.0013 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0065\n",
            "Epoch 14: val_loss did not improve from 0.00131\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0065 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0060\n",
            "Epoch 15: val_loss did not improve from 0.00131\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0060 - val_loss: 0.0018 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0055\n",
            "Epoch 16: val_loss did not improve from 0.00131\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0055 - val_loss: 0.0018 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0051\n",
            "Epoch 17: val_loss did not improve from 0.00131\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0051 - val_loss: 0.0022 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0049\n",
            "Epoch 18: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0015 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0039\n",
            "Epoch 19: val_loss improved from 0.00131 to 0.00114, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0039 - val_loss: 0.0011 - learning_rate: 2.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0038\n",
            "Epoch 20: val_loss improved from 0.00114 to 0.00111, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0038 - val_loss: 0.0011 - learning_rate: 2.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037\n",
            "Epoch 21: val_loss did not improve from 0.00111\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0037 - val_loss: 0.0013 - learning_rate: 2.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0036\n",
            "Epoch 22: val_loss did not improve from 0.00111\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0036 - val_loss: 0.0011 - learning_rate: 2.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037\n",
            "Epoch 23: val_loss did not improve from 0.00111\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0037 - val_loss: 0.0016 - learning_rate: 2.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0037\n",
            "Epoch 24: val_loss did not improve from 0.00111\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0037 - val_loss: 0.0014 - learning_rate: 2.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0034\n",
            "Epoch 25: val_loss improved from 0.00111 to 0.00099, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0034 - val_loss: 9.9292e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0034\n",
            "Epoch 26: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0034 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0033\n",
            "Epoch 27: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0033 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032\n",
            "Epoch 28: val_loss improved from 0.00099 to 0.00099, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0032 - val_loss: 9.9079e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0033\n",
            "Epoch 29: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0033 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032\n",
            "Epoch 30: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0033\n",
            "Epoch 31: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0033 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0033\n",
            "Epoch 32: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0033 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032\n",
            "Epoch 33: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032\n",
            "Epoch 34: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032\n",
            "Epoch 35: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0032\n",
            "Epoch 36: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0032 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0031\n",
            "Epoch 37: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0031 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031\n",
            "Epoch 38: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031\n",
            "Epoch 39: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0031\n",
            "Epoch 40: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0031 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0031\n",
            "Epoch 41: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0031 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031\n",
            "Epoch 42: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031\n",
            "Epoch 43: val_loss did not improve from 0.00099\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 9.9905e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 43: early stopping\n",
            "Restoring model weights from the end of the best epoch: 28.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU モデル（PCA適用なし"
      ],
      "metadata": {
        "id": "bvC8ZZ8WZJua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRUモデルの構築と学習 (PCA適用なしデータ)\n",
        "gru_model_no_pca = build_gru_model(seq_length, X_train_seq_no_pca.shape[2])\n",
        "print(\"\\n--- GRUモデル (PCA適用なし) ---\")\n",
        "print(gru_model_no_pca.summary())\n",
        "\n",
        "checkpoint_gru_no_pca = ModelCheckpoint(\n",
        "    data_path + 'gru_model_no_pca.h5', # ファイル名を変更して区別\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\n--- GRUモデル学習開始 (PCA適用なし) ---\")\n",
        "gru_history_no_pca = gru_model_no_pca.fit(\n",
        "    X_train_seq_no_pca, y_train_seq_no_pca,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val_seq_no_pca, y_val_seq_no_pca),\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor='val_loss', patience=15, verbose=1, restore_best_weights=True),\n",
        "        checkpoint_gru_no_pca,\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001, verbose=1)\n",
        "    ],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# GRU 学習履歴のプロット部分 (PCA適用なし)\n",
        "plt.figure(figsize=(7, 5))\n",
        "\n",
        "plt.plot(gru_history_no_pca.history['loss'], label='Training Loss')\n",
        "plt.plot(gru_history_no_pca.history['val_loss'], label='Validation Loss')\n",
        "plt.title('GRU (No PCA) - Loss (MSE)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('gru_training_history_loss_no_pca.png') # ファイル名を変更\n",
        "plt.close()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bXJ5GbLdZLz8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "35b2ceea-91d9-435f-c1f8-6da136cb8d4e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- GRUモデル (PCA適用なし) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_6 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m18,432\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_22          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_7 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m74,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_23          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_22          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_23          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m97,857\u001b[0m (382.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,857</span> (382.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m97,473\u001b[0m (380.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,473</span> (380.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\n",
            "--- GRUモデル学習開始 (PCA適用なし) ---\n",
            "Epoch 1/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3335\n",
            "Epoch 1: val_loss improved from inf to 0.02338, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.3298 - val_loss: 0.0234 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0277\n",
            "Epoch 2: val_loss improved from 0.02338 to 0.00895, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0276 - val_loss: 0.0090 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0128\n",
            "Epoch 3: val_loss improved from 0.00895 to 0.00456, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0128 - val_loss: 0.0046 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0093\n",
            "Epoch 4: val_loss improved from 0.00456 to 0.00338, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0093 - val_loss: 0.0034 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0079\n",
            "Epoch 5: val_loss did not improve from 0.00338\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0079 - val_loss: 0.0037 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0071\n",
            "Epoch 6: val_loss improved from 0.00338 to 0.00226, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0071 - val_loss: 0.0023 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0062\n",
            "Epoch 7: val_loss improved from 0.00226 to 0.00211, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0062 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0057\n",
            "Epoch 8: val_loss improved from 0.00211 to 0.00186, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0019 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0054\n",
            "Epoch 9: val_loss did not improve from 0.00186\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0054 - val_loss: 0.0020 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0047\n",
            "Epoch 10: val_loss did not improve from 0.00186\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0047 - val_loss: 0.0025 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0045\n",
            "Epoch 11: val_loss improved from 0.00186 to 0.00160, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0045 - val_loss: 0.0016 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0044\n",
            "Epoch 12: val_loss improved from 0.00160 to 0.00150, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0044 - val_loss: 0.0015 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0042\n",
            "Epoch 13: val_loss did not improve from 0.00150\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0042 - val_loss: 0.0018 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0045\n",
            "Epoch 14: val_loss did not improve from 0.00150\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0045 - val_loss: 0.0016 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0041\n",
            "Epoch 15: val_loss did not improve from 0.00150\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0041 - val_loss: 0.0020 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0045\n",
            "Epoch 16: val_loss improved from 0.00150 to 0.00144, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0045 - val_loss: 0.0014 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0039\n",
            "Epoch 17: val_loss improved from 0.00144 to 0.00136, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0039 - val_loss: 0.0014 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0038\n",
            "Epoch 18: val_loss improved from 0.00136 to 0.00115, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0038 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0033\n",
            "Epoch 19: val_loss improved from 0.00115 to 0.00088, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0033 - val_loss: 8.7821e-04 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0031\n",
            "Epoch 20: val_loss did not improve from 0.00088\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0031 - val_loss: 8.9981e-04 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030\n",
            "Epoch 21: val_loss did not improve from 0.00088\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0030 - val_loss: 9.4913e-04 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0028\n",
            "Epoch 22: val_loss improved from 0.00088 to 0.00081, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0028 - val_loss: 8.1437e-04 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0026\n",
            "Epoch 23: val_loss did not improve from 0.00081\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0026 - val_loss: 0.0013 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0026\n",
            "Epoch 24: val_loss did not improve from 0.00081\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0026 - val_loss: 0.0010 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0022\n",
            "Epoch 25: val_loss improved from 0.00081 to 0.00069, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0022 - val_loss: 6.8946e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021\n",
            "Epoch 26: val_loss improved from 0.00069 to 0.00066, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 6.5673e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020\n",
            "Epoch 27: val_loss improved from 0.00066 to 0.00063, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 0.0020 - val_loss: 6.3001e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0021\n",
            "Epoch 28: val_loss improved from 0.00063 to 0.00063, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0021 - val_loss: 6.2842e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020\n",
            "Epoch 29: val_loss did not improve from 0.00063\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 6.4790e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0020\n",
            "Epoch 30: val_loss did not improve from 0.00063\n",
            "\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0020 - val_loss: 6.3078e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0019\n",
            "Epoch 31: val_loss did not improve from 0.00063\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0019 - val_loss: 6.4105e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019\n",
            "Epoch 32: val_loss did not improve from 0.00063\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0019 - val_loss: 6.5618e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019\n",
            "Epoch 33: val_loss improved from 0.00063 to 0.00061, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0019 - val_loss: 6.1004e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018\n",
            "Epoch 34: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 6.7124e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018\n",
            "Epoch 35: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 6.7897e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m325/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018\n",
            "Epoch 36: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 6.6013e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018\n",
            "Epoch 37: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 6.6638e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018\n",
            "Epoch 38: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 6.6574e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018\n",
            "Epoch 39: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 6.4465e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0018\n",
            "Epoch 40: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0018 - val_loss: 6.3837e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017\n",
            "Epoch 41: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 6.5065e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018\n",
            "Epoch 42: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 6.1738e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m327/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017\n",
            "Epoch 43: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 6.4247e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018\n",
            "Epoch 44: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 6.8768e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017\n",
            "Epoch 45: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 6.3008e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m323/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017\n",
            "Epoch 46: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 6.3667e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m326/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017\n",
            "Epoch 47: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0017 - val_loss: 6.6000e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m324/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017\n",
            "Epoch 48: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 6.8112e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 48: early stopping\n",
            "Restoring model weights from the end of the best epoch: 33.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデル評価と結果比較"
      ],
      "metadata": {
        "id": "coqyhCKXZW6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test_seq, y_test_seq_scaled, y_scaler, title): # y_test_scaledをy_test_seq_scaledに変更\n",
        "    \"\"\"\n",
        "    モデルを評価し、MAEとRMSEを計算、結果をプロットする\n",
        "    \"\"\"\n",
        "    # 予測\n",
        "    scaled_predictions = model.predict(X_test_seq)\n",
        "\n",
        "    # スケーリングを元に戻す\n",
        "    # MAE/RMSE計算とプロットのために、y_test_seq_scaledを使用する\n",
        "    y_test_orig = y_scaler.inverse_transform(y_test_seq_scaled.reshape(-1, 1)).flatten() # y_test_scaledをy_test_seq_scaledに変更\n",
        "    y_pred_orig = y_scaler.inverse_transform(scaled_predictions).flatten()\n",
        "\n",
        "    # 評価指標\n",
        "    mae = mean_absolute_error(y_test_orig, y_pred_orig)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
        "\n",
        "    print(f\"\\n--- {title} 評価結果 ---\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "    # 予測結果と実測値の比較プロット\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    # プロットの実測値もy_test_seq_scaledから計算する\n",
        "    plt.plot(y_scaler.inverse_transform(y_test_seq_scaled.reshape(-1, 1)).flatten(), label='Actual Price') # y_test_scaledをy_test_seq_scaledに変更\n",
        "    plt.plot(y_pred_orig, label='Predicted Price')\n",
        "    plt.title(f'{title} - 実測値 vs 予測値')\n",
        "    plt.xlabel('Time Step')\n",
        "    plt.ylabel('Price')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{title.replace(\" \", \"_\")}_prediction_vs_actual.png')\n",
        "    plt.close()\n",
        "\n",
        "    return mae, rmse\n",
        "\n",
        "# LSTM (PCA適用) の評価\n",
        "# y_test_scaled_pca を y_test_seq_pca に変更して evaluate_model を呼び出す\n",
        "lstm_pca_mae, lstm_pca_rmse = evaluate_model(lstm_model_pca, X_test_seq_pca, y_test_seq_pca, y_scaler, \"LSTM (PCA)\")\n",
        "\n",
        "# LSTM (PCA適用なし) の評価\n",
        "# y_test_scaled_no_pca を y_test_seq_no_pca に変更して evaluate_model を呼び出す\n",
        "lstm_no_pca_mae, lstm_no_pca_rmse = evaluate_model(lstm_model_no_pca, X_test_seq_no_pca, y_test_seq_no_pca, y_scaler, \"LSTM (No PCA)\")\n",
        "\n",
        "# GRU (PCA適用) の評価\n",
        "# y_test_scaled_pca を y_test_seq_pca に変更して evaluate_model を呼び出す\n",
        "gru_pca_mae, gru_pca_rmse = evaluate_model(gru_model_pca, X_test_seq_pca, y_test_seq_pca, y_scaler, \"GRU (PCA)\")\n",
        "\n",
        "# GRU (PCA適用なし) の評価\n",
        "# y_test_scaled_no_pca を y_test_seq_no_pca に変更して evaluate_model を呼び出す\n",
        "gru_no_pca_mae, gru_no_pca_rmse = evaluate_model(gru_model_no_pca, X_test_seq_no_pca, y_test_seq_no_pca, y_scaler, \"GRU (No PCA)\")\n",
        "\n",
        "# 結果の比較\n",
        "print(\"\\n--- モデル比較結果 ---\")\n",
        "print(f\"LSTM (PCA):     MAE={lstm_pca_mae:.4f}, RMSE={lstm_pca_rmse:.4f}\")\n",
        "print(f\"LSTM (No PCA):  MAE={lstm_no_pca_mae:.4f}, RMSE={lstm_no_pca_rmse:.4f}\")\n",
        "print(f\"GRU (PCA):      MAE={gru_pca_mae:.4f}, RMSE={gru_pca_rmse:.4f}\")\n",
        "print(f\"GRU (No PCA):   MAE={gru_no_pca_mae:.4f}, RMSE={gru_no_pca_rmse:.4f}\")"
      ],
      "metadata": {
        "id": "99xd15M7ZXeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "405c0601-80a6-4e2e-a066-2de8897e8427"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\n",
            "--- LSTM (PCA) 評価結果 ---\n",
            "MAE: 6.2338\n",
            "RMSE: 8.1579\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\n",
            "--- LSTM (No PCA) 評価結果 ---\n",
            "MAE: 3.6980\n",
            "RMSE: 5.2392\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\n",
            "--- GRU (PCA) 評価結果 ---\n",
            "MAE: 4.0530\n",
            "RMSE: 5.5660\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\n",
            "--- GRU (No PCA) 評価結果 ---\n",
            "MAE: 3.0711\n",
            "RMSE: 4.3489\n",
            "\n",
            "--- モデル比較結果 ---\n",
            "LSTM (PCA):     MAE=6.2338, RMSE=8.1579\n",
            "LSTM (No PCA):  MAE=3.6980, RMSE=5.2392\n",
            "GRU (PCA):      MAE=4.0530, RMSE=5.5660\n",
            "GRU (No PCA):   MAE=3.0711, RMSE=4.3489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 特徴量重要度の分析"
      ],
      "metadata": {
        "id": "Rh4RQNarSGbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量重要度の可視化（SelectKBestの結果）\n",
        "def plot_feature_importance(X, y, top_n=20):\n",
        "    # 数値型以外のカラムを削除\n",
        "    X_numeric = X.select_dtypes(include=np.number)\n",
        "\n",
        "    selector = SelectKBest(score_func=f_regression, k='all')\n",
        "    # 数値型カラムのみを使ってfitを行う\n",
        "    selector.fit(X_numeric, y)\n",
        "\n",
        "    # 特徴量のスコアを取得\n",
        "    feature_scores = pd.DataFrame({\n",
        "        'Feature': X_numeric.columns, # X_numericのカラム名を使用\n",
        "        'Score': selector.scores_\n",
        "    })\n",
        "\n",
        "    # スコア順にソート\n",
        "    feature_scores = feature_scores.sort_values(by='Score', ascending=False)\n",
        "\n",
        "    # 上位n個の特徴量をプロット\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x='Score', y='Feature', data=feature_scores.head(top_n))\n",
        "    plt.title(f'上位{top_n}個の重要な特徴量')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('feature_importance.png')\n",
        "    plt.close()\n",
        "\n",
        "    return feature_scores\n",
        "\n",
        "# 特徴量重要度のプロット\n",
        "# XがDataFrameであり、数値型以外のカラムを含んでいる可能性があるため、関数内で処理します\n",
        "importance = plot_feature_importance(X_featured, y_featured, top_n=20)\n",
        "print(\"\\n上位20の重要な特徴量:\")\n",
        "print(importance.head(20))"
      ],
      "metadata": {
        "id": "keF1FeENSIOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d93a2c-c5be-48a3-ea4e-462ff2c92efa"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "上位20の重要な特徴量:\n",
            "                                        Feature          Score\n",
            "84                           price_actual_lag_1  362397.475584\n",
            "85                          price_actual_lag_24   55455.839343\n",
            "88                 price_actual_rolling_mean_24   51125.358795\n",
            "87                         price_actual_lag_168   46096.371945\n",
            "86                          price_actual_lag_48   29553.563560\n",
            "3                   generation_fossil_hard_coal    7410.283193\n",
            "1          generation_fossil_brown_coal/lignite    4315.279936\n",
            "14                            total_load_actual    4191.590208\n",
            "2                         generation_fossil_gas    4151.326152\n",
            "5   generation_hydro_pumped_storage_consumption    2642.416186\n",
            "6    generation_hydro_run_of_river_and_poundage    1905.413869\n",
            "79                                      quarter    1801.790531\n",
            "4                         generation_fossil_oil    1735.021199\n",
            "75                                         hour    1639.636595\n",
            "81                                   weekofyear    1558.000176\n",
            "77                                        month    1550.580653\n",
            "80                                    dayofyear    1547.614404\n",
            "83                                   is_weekend    1542.839203\n",
            "32                            madrid_wind_speed    1515.924859\n",
            "0                            generation_biomass    1159.447579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 時系列交差検証"
      ],
      "metadata": {
        "id": "qWKVR5klSKZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 時系列交差検証\n",
        "def time_series_cv_evaluation(X, y, seq_length=24, n_splits=5):\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "    mae_scores = []\n",
        "    rmse_scores = []\n",
        "    fold = 1\n",
        "\n",
        "    for train_index, test_index in tscv.split(X):\n",
        "        print(f\"\\n評価 fold {fold}/{n_splits}\")\n",
        "\n",
        "        # データの分割\n",
        "        X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
        "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
        "\n",
        "        # スケーリング\n",
        "        y_scaler_fold = MinMaxScaler()\n",
        "        y_train_scaled = y_scaler_fold.fit_transform(y_train_fold.reshape(-1, 1))\n",
        "        y_test_scaled = y_scaler_fold.transform(y_test_fold.reshape(-1, 1))\n",
        "\n",
        "        # シーケンスデータの作成\n",
        "        X_train_seq_fold, y_train_seq_fold = create_sequences(X_train_fold, y_train_scaled, seq_length)\n",
        "        X_test_seq_fold, y_test_seq_fold = create_sequences(X_test_fold, y_test_scaled, seq_length)\n",
        "\n",
        "        if len(X_train_seq_fold) == 0 or len(X_test_seq_fold) == 0:\n",
        "            print(\"シーケンスデータが空です\")\n",
        "            continue\n",
        "\n",
        "        # モデル構築と学習\n",
        "        model = build_lstm_model(seq_length, X_train_seq_fold.shape[2])\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, restore_best_weights=True)\n",
        "\n",
        "        model.fit(\n",
        "            X_train_seq_fold, y_train_seq_fold,\n",
        "            epochs=50,\n",
        "            batch_size=64,\n",
        "            validation_split=0.2,\n",
        "            callbacks=[early_stopping],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # 評価\n",
        "        y_pred_fold = model.predict(X_test_seq_fold)\n",
        "\n",
        "        # スケーリングを元に戻す\n",
        "        y_test_orig_fold = y_scaler_fold.inverse_transform(y_test_seq_fold.reshape(-1, 1)).flatten()\n",
        "        y_pred_orig_fold = y_scaler_fold.inverse_transform(y_pred_fold).flatten()\n",
        "\n",
        "        # 評価指標の計算\n",
        "        mae = mean_absolute_error(y_test_orig_fold, y_pred_orig_fold)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test_orig_fold, y_pred_orig_fold))\n",
        "\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(rmse)\n",
        "\n",
        "        print(f\"Fold {fold} - MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n",
        "        fold += 1\n",
        "\n",
        "    # 結果をまとめる\n",
        "    print(\"\\n時系列交差検証の結果:\")\n",
        "    print(f\"平均 MAE: {np.mean(mae_scores):.2f} (±{np.std(mae_scores):.2f})\")\n",
        "    print(f\"平均 RMSE: {np.mean(rmse_scores):.2f} (±{np.std(rmse_scores):.2f})\")\n",
        "\n",
        "    return mae_scores, rmse_scores\n",
        "\n",
        "# 時系列交差検証の実行\n",
        "mae_cv, rmse_cv = time_series_cv_evaluation(X_pca, y_scaled, seq_length=24, n_splits=3)"
      ],
      "metadata": {
        "id": "w-aWTdEJSMJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f36f0549-9b88-4231-fcad-abe32fd32b7a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "評価 fold 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Fold 1 - MAE: 0.08, RMSE: 0.11\n",
            "\n",
            "評価 fold 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Fold 2 - MAE: 0.05, RMSE: 0.07\n",
            "\n",
            "評価 fold 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Fold 3 - MAE: 0.04, RMSE: 0.05\n",
            "\n",
            "時系列交差検証の結果:\n",
            "平均 MAE: 0.06 (±0.02)\n",
            "平均 RMSE: 0.07 (±0.02)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 追加特徴量の作成"
      ],
      "metadata": {
        "id": "LHo8vxY0KUc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_additional_features_combined(df, is_test=False, train_df=None):\n",
        "    \"\"\"\n",
        "    時系列データに対して時間系特徴量・ラグ特徴量・統計特徴量を追加\n",
        "\n",
        "    Parameters:\n",
        "    - df: 特徴量追加対象のDataFrame（DatetimeIndexを持つ）\n",
        "    - is_test: testデータでの呼び出しかどうか\n",
        "    - train_df: trainデータ（is_test=True のとき、ラグ計算用に参照）\n",
        "\n",
        "    Returns:\n",
        "    - df_features: 特徴量が追加されたDataFrame\n",
        "    \"\"\"\n",
        "    df_features = df.copy()\n",
        "\n",
        "    # インデックスの整備（UTC前提）\n",
        "    if not isinstance(df_features.index, pd.DatetimeIndex) or df_features.index.tz is not None:\n",
        "        df_features.index = pd.to_datetime(df_features.index, utc=True)\n",
        "\n",
        "    # 基本的な時間特徴量\n",
        "    df_features['hour'] = df_features.index.hour\n",
        "    df_features['dayofweek'] = df_features.index.dayofweek\n",
        "    df_features['month'] = df_features.index.month\n",
        "    df_features['year'] = df_features.index.year\n",
        "    df_features['quarter'] = df_features.index.quarter\n",
        "    df_features['dayofyear'] = df_features.index.dayofyear\n",
        "    df_features['weekofyear'] = df_features.index.isocalendar().week.astype(int)\n",
        "    df_features['dayofmonth'] = df_features.index.day\n",
        "    df_features['is_weekend'] = (df_features.index.dayofweek >= 5).astype(int)\n",
        "\n",
        "    # ラグ特徴量\n",
        "    if is_test and train_df is not None:\n",
        "        # train_dfの末尾と結合してラグを引き継ぐ\n",
        "        df_lag = pd.concat([train_df[['price_actual']].copy(), df_features], axis=0)\n",
        "    else:\n",
        "        df_lag = df_features.copy()\n",
        "\n",
        "    df_lag['price_actual_lag_1'] = df_lag['price_actual'].shift(1)\n",
        "    df_lag['price_actual_lag_24'] = df_lag['price_actual'].shift(24)\n",
        "    df_lag['price_actual_lag_48'] = df_lag['price_actual'].shift(48)\n",
        "    df_lag['price_actual_lag_168'] = df_lag['price_actual'].shift(168)\n",
        "\n",
        "    # 移動平均\n",
        "    df_lag['price_actual_rolling_mean_24'] = df_lag['price_actual'].rolling(window=24).mean()\n",
        "\n",
        "    # testの場合、trainを除いた test 部分だけを返す\n",
        "    if is_test and train_df is not None:\n",
        "        df_result = df_lag.loc[df_features.index]\n",
        "    else:\n",
        "        df_result = df_lag\n",
        "\n",
        "    # 欠損値処理（主にラグ・rolling平均による）\n",
        "    df_result = df_result.ffill().bfill()\n",
        "\n",
        "    return df_result\n"
      ],
      "metadata": {
        "id": "iqr749LQKZpi"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def recursive_forecast(model, test_df, train_df, pipeline):\n",
        "    \"\"\"\n",
        "    学習データの末尾を使って test を自己回帰的に予測\n",
        "    各ステップで特徴量生成 + 前処理 + 予測 + price_actual の更新 を行う\n",
        "    \"\"\"\n",
        "    seq_length = pipeline['seq_length']\n",
        "    selected_features = pipeline['selected_features']\n",
        "    scaler = pipeline['pca_scaler']\n",
        "    y_scaler = pipeline['y_scaler']\n",
        "    pca = pipeline['pca']\n",
        "\n",
        "    df_past = train_df.copy()\n",
        "    df_future = test_df.copy()\n",
        "\n",
        "    preds = []\n",
        "\n",
        "    for i in tqdm(range(len(df_future))):\n",
        "        # 今の時点の未来データ1ステップ\n",
        "        step_df = df_future.iloc[[i]].copy()\n",
        "\n",
        "        # 特徴量生成\n",
        "        df_with_feature = create_additional_features_combined(\n",
        "            step_df, is_test=True, train_df=df_past\n",
        "        )\n",
        "\n",
        "        # 特徴量選択\n",
        "        X_step = df_with_feature[selected_features]\n",
        "\n",
        "        # スケーリング\n",
        "        X_scaled = scaler.transform(X_step)\n",
        "\n",
        "        # PCA適用\n",
        "        if pca is not None:\n",
        "            X_scaled = pca.transform(X_scaled)\n",
        "\n",
        "        # シーケンス作成\n",
        "        if len(df_past) >= seq_length - 1:\n",
        "            recent = df_past.tail(seq_length - 1)[['price_actual']].copy()\n",
        "            recent_features = []\n",
        "\n",
        "            for j in range(seq_length - 1):\n",
        "                step = df_past.iloc[-(seq_length - 1 - j)]\n",
        "                step_feat = create_additional_features_combined(\n",
        "                    step.to_frame().T, is_test=True, train_df=df_past.iloc[:-(seq_length - 1 - j)]\n",
        "                )\n",
        "                feat = step_feat[selected_features]\n",
        "                feat_scaled = scaler.transform(feat)\n",
        "                feat_scaled = pca.transform(feat_scaled) if pca is not None else feat_scaled\n",
        "                recent_features.append(feat_scaled[0])\n",
        "\n",
        "            recent_features.append(X_scaled[0])\n",
        "            X_seq = np.array(recent_features).reshape(1, seq_length, -1)\n",
        "\n",
        "            # 予測\n",
        "            y_pred_scaled = model.predict(X_seq)\n",
        "            y_pred = y_scaler.inverse_transform(y_pred_scaled)[0, 0]\n",
        "        else:\n",
        "            y_pred = df_past['price_actual'].iloc[-1]  # fallback\n",
        "\n",
        "        preds.append(y_pred)\n",
        "\n",
        "        # 予測結果を df_future に反映\n",
        "        df_future.at[step_df.index[0], 'price_actual'] = y_pred\n",
        "        df_past = pd.concat([df_past, df_future.iloc[[i]]])\n",
        "\n",
        "    return preds\n"
      ],
      "metadata": {
        "id": "h0poyY_kih15"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデルとパイプラインの保存"
      ],
      "metadata": {
        "id": "ckd-tuS5SPPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# モデル保存のためのパイプラインを作成\n",
        "pipeline = {\n",
        "    'pca': pca,\n",
        "    'pca_scaler': feature_scaler ,\n",
        "    'y_scaler': y_scaler,\n",
        "    'selected_features': X_selected_scaled.columns.tolist(),\n",
        "    'seq_length': seq_length\n",
        "}\n",
        "\n",
        "# パイプラインを保存\n",
        "pipeline_save_path = data_path + 'price_prediction_pipeline.pkl'\n",
        "with open(pipeline_save_path, 'wb') as f:\n",
        "    pickle.dump(pipeline, f)\n",
        "\n",
        "# 予測パイプラインの使用例\n",
        "def predict_price(model, new_data, pipeline):\n",
        "    \"\"\"\n",
        "    新しいデータで価格を予測する\n",
        "\n",
        "    Parameters:\n",
        "    - model: 訓練済みモデル\n",
        "    - new_data: 予測したいデータ（必要な特徴量を含むDataFrame）\n",
        "    - pipeline: 前処理パイプライン\n",
        "\n",
        "    Returns:\n",
        "    - predicted_price: 予測された価格\n",
        "    \"\"\"\n",
        "    # パイプラインから必要な要素を取得\n",
        "    pca = pipeline['pca']\n",
        "    pca_scaler = pipeline['pca_scaler']\n",
        "    y_scaler = pipeline['y_scaler']\n",
        "    selected_features = pipeline['selected_features']\n",
        "    seq_length = pipeline['seq_length']\n",
        "\n",
        "    # 必要な特徴量のみを選択\n",
        "    selected_data = new_data[selected_features]\n",
        "\n",
        "    # スケーリングとPCA変換\n",
        "    scaled_data = pca_scaler.transform(selected_data)\n",
        "    pca_data = pca.transform(scaled_data)\n",
        "\n",
        "    # シーケンスデータの作成（最新のseq_length分のデータを使用）\n",
        "    if len(pca_data) >= seq_length:\n",
        "        sequence = pca_data[-seq_length:].reshape(1, seq_length, -1)\n",
        "\n",
        "        # 予測\n",
        "        scaled_prediction = model.predict(sequence)\n",
        "\n",
        "        # スケーリングを元に戻す\n",
        "        prediction = y_scaler.inverse_transform(scaled_prediction)[0, 0]\n",
        "\n",
        "        return prediction\n",
        "    else:\n",
        "        raise ValueError(f\"入力データが短すぎます。少なくとも{seq_length}点必要です。\")\n",
        "# 特徴量選択名を取得（再取得）\n",
        "selected_features_for_inference = feature_selector.get_support(indices=True)\n",
        "selected_feature_names = X_featured.select_dtypes(include=np.number).columns[selected_features_for_inference].tolist()\n",
        "\n",
        "print(\"\\nモデルと前処理パイプラインを保存しました。\")\n",
        "print(\"新しいデータに対する予測は 'predict_price' 関数を使用して行えます。\")"
      ],
      "metadata": {
        "id": "rnQKYSgsSREZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0104f73d-3ef9-4f7d-9929-54e29e9505a3"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "モデルと前処理パイプラインを保存しました。\n",
            "新しいデータに対する予測は 'predict_price' 関数を使用して行えます。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 最適モデルの決定と最終予測"
      ],
      "metadata": {
        "id": "hsIhTuL1Q9is"
      }
    },
    {
      "source": [
        "#------------------------------------------------------------\n",
        "# ★ 評価結果の取りまとめ 〜 最適モデル決定\n",
        "#------------------------------------------------------------\n",
        "evaluation_results = {\n",
        "    \"LSTM (PCA)\": {\"mae\": lstm_pca_mae, \"rmse\": lstm_pca_rmse,\n",
        "                   \"model\": lstm_model_pca, \"data_type\": \"pca\"},\n",
        "    \"LSTM (No PCA)\": {\"mae\": lstm_no_pca_mae, \"rmse\": lstm_no_pca_rmse,\n",
        "                      \"model\": lstm_model_no_pca, \"data_type\": \"no_pca\"},\n",
        "    \"GRU  (PCA)\": {\"mae\": gru_pca_mae, \"rmse\": gru_pca_rmse,\n",
        "                   \"model\": gru_model_pca, \"data_type\": \"pca\"},\n",
        "    \"GRU  (No PCA)\": {\"mae\": gru_no_pca_mae, \"rmse\": gru_no_pca_rmse,\n",
        "                      \"model\": gru_model_no_pca, \"data_type\": \"no_pca\"}\n",
        "}\n",
        "\n",
        "print(\"\\n--- モデル比較結果 ---\")\n",
        "for k, v in evaluation_results.items():\n",
        "    print(f\"{k}: MAE={v['mae']:.4f}, RMSE={v['rmse']:.4f}\")\n",
        "\n",
        "best_model_name = min(evaluation_results, key=lambda k: evaluation_results[k]['mae'])\n",
        "best_info       = evaluation_results[best_model_name]\n",
        "best_model      = best_info['model']\n",
        "best_data_type  = best_info['data_type']\n",
        "loaded_seq_len  = seq_length            # そのまま保持\n",
        "\n",
        "print(f\"\\n最適なモデルは: {best_model_name} (MAE={best_info['mae']:.4f})\")\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# ★ スケーラー & PCA\n",
        "#------------------------------------------------------------\n",
        "final_pca            = pca if best_data_type == \"pca\" else None\n",
        "final_feature_scaler = feature_scaler\n",
        "final_y_scaler       = y_scaler\n",
        "print(\"最終予測にPCAを使用します。\" if final_pca else \"最終予測にPCAは使用しません。\")\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# ★ テストデータ：特徴量生成\n",
        "#------------------------------------------------------------\n",
        "test_df_spain = (\n",
        "    test_df[test_df[\"item_ID\"] == \"spain_total\"]\n",
        "    .ffill().bfill()\n",
        "    .drop(columns=\"item_ID\")\n",
        ")\n",
        "\n",
        "test_feat = create_additional_features_combined(\n",
        "    test_df_spain.copy(), is_test=True, train_df=df.copy()\n",
        ").fillna(0)\n",
        "test_feat[\"price_actual\"] = np.nan   # 予測を書き込むダミー列\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# ★ train データも同じ関数で “フル特徴量” を作る\n",
        "#------------------------------------------------------------\n",
        "train_feat = create_additional_features_combined(df.copy(), is_test=False).fillna(0)\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# ★ 選択された特徴量リスト\n",
        "#------------------------------------------------------------\n",
        "selected_cols = pipeline[\"selected_features\"]\n",
        "\n",
        "missing_test  = set(selected_cols) - set(test_feat.columns)\n",
        "missing_train = set(selected_cols) - set(train_feat.columns)\n",
        "if missing_test or missing_train:\n",
        "    raise ValueError(f\"列が足りません\\n test → {missing_test}\\n train → {missing_train}\")\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# ★ ① 追加で保存するリスト\n",
        "#------------------------------------------------------------\n",
        "all_numeric_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "selected_cols    = pipeline[\"selected_features\"]               # 30 列\n",
        "sel_idx          = [all_numeric_cols.index(c) for c in selected_cols]\n",
        "\n",
        "# pipeline を上書き保存（あとで読み直す場合に備えて）\n",
        "pipeline.update({\n",
        "    \"all_numeric_cols\": all_numeric_cols,\n",
        "    \"selected_idx\"    : sel_idx\n",
        "})\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# ★ ② 逐次予測関数：139列でスケール → 30列だけ抽出\n",
        "#------------------------------------------------------------\n",
        "def recursive_forecast(model, test_df_full, train_df_full, pipe):\n",
        "\n",
        "    pca        = pipe[\"pca\"]\n",
        "    scaler     = pipe[\"pca_scaler\"]\n",
        "    y_scaler   = pipe[\"y_scaler\"]\n",
        "    feats      = pipe[\"selected_features\"]      # 30 列名\n",
        "    all_cols   = pipe[\"all_numeric_cols\"]       # 139 列名\n",
        "    sel_idx    = pipe[\"selected_idx\"]           # 30 → 139 中の位置\n",
        "    seq_len    = pipe[\"seq_length\"]\n",
        "\n",
        "    # index を tz なしに統一\n",
        "    train_df_full.index = pd.to_datetime(train_df_full.index).tz_localize(None)\n",
        "    test_df_full.index  = pd.to_datetime(test_df_full.index).tz_localize(None)\n",
        "\n",
        "    full  = train_df_full.copy()\n",
        "    preds = []\n",
        "\n",
        "    for ts, row in test_df_full.iterrows():\n",
        "\n",
        "        # ❶ 末尾に 1 行追加（列合わせ）\n",
        "        full = pd.concat(\n",
        "            [full, row.to_frame().T.reindex(columns=full.columns)],\n",
        "            copy=False\n",
        "        )\n",
        "\n",
        "        # ❷ 最新行 & 履歴を 139 列でそろえて取り出す ----------------\n",
        "        x_num   = full.loc[ts].reindex(all_cols).fillna(0)\n",
        "        hist_num= full[all_cols].iloc[-(seq_len-1):].fillna(0)\n",
        "\n",
        "        # ❸ スケール（139→139）------------------------------------\n",
        "        x_scaled_all    = scaler.transform(x_num.to_frame().T)      # (1,139)\n",
        "        hist_scaled_all = scaler.transform(hist_num)               # (seq-1,139)\n",
        "\n",
        "        # ❹ 30 列だけ切り出し -------------------------------------\n",
        "        x_scaled_sel    = x_scaled_all[:, sel_idx]                  # (1,30)\n",
        "        hist_scaled_sel = hist_scaled_all[:, sel_idx]               # (seq-1,30)\n",
        "\n",
        "        # ❺ PCA（必要なら）-----------------------------------------\n",
        "        if pca:\n",
        "            x_final    = pca.transform(x_scaled_sel)\n",
        "            hist_final = pca.transform(hist_scaled_sel)\n",
        "        else:\n",
        "            x_final, hist_final = x_scaled_sel, hist_scaled_sel\n",
        "\n",
        "        seq = np.vstack([hist_final, x_final]).reshape(1, seq_len, -1)\n",
        "\n",
        "        # ❻ 予測 ---------------------------------------------------\n",
        "        y_scaled = model.predict(seq, verbose=0)\n",
        "        y_pred   = y_scaler.inverse_transform(y_scaled)[0, 0]\n",
        "        preds.append(y_pred)\n",
        "\n",
        "        # ❼ 予測値 & ラグ -----------------------------------------\n",
        "        full.iat[-1, full.columns.get_loc(\"price_actual\")] = y_pred\n",
        "        idx_cur   = len(full) - 1\n",
        "        col_price = full.columns.get_loc(\"price_actual\")\n",
        "        for lag in (1, 24, 48, 168):\n",
        "            lag_col = f\"price_actual_lag_{lag}\"\n",
        "            if lag_col in full.columns and idx_cur >= lag:\n",
        "                col_pos = full.columns.get_loc(lag_col)\n",
        "                full.iat[idx_cur, col_pos] = full.iat[idx_cur - lag, col_price]\n",
        "\n",
        "    return preds\n",
        "\n",
        "\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# ★ 推論実行\n",
        "#------------------------------------------------------------\n",
        "preds = recursive_forecast(\n",
        "    best_model,\n",
        "    test_feat.copy(),\n",
        "    train_feat.copy(),\n",
        "    {\n",
        "        \"pca\"              : final_pca,\n",
        "        \"pca_scaler\"       : final_feature_scaler,\n",
        "        \"y_scaler\"         : final_y_scaler,\n",
        "        \"selected_features\": selected_cols,\n",
        "        \"seq_length\"       : loaded_seq_len,\n",
        "    }\n",
        ")\n",
        "\n",
        "#------------------------------------------------------------\n",
        "# ★ 提出ファイル作成\n",
        "#------------------------------------------------------------\n",
        "sub_df = pd.DataFrame({\n",
        "    \"id\"          : [ts.strftime(\"%Y-%m-%d %H:%M:%S\") + \"_spain_total\"\n",
        "                     for ts in test_df_spain.index],\n",
        "    \"price_actual\": preds\n",
        "})\n",
        "sub_path = data_path + \"submission.csv\"\n",
        "sub_df.to_csv(sub_path, header=False, index=False)\n",
        "\n",
        "print(f\"\\n最終推論結果を '{sub_path}' に保存しました。\")\n",
        "display(sub_df.head())\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "S1vik4ZSQ0gZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "83174cc1-5e87-452b-f5fe-cb6853184b10"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- モデル比較結果 ---\n",
            "LSTM (PCA): MAE=6.2338, RMSE=8.1579\n",
            "LSTM (No PCA): MAE=3.6980, RMSE=5.2392\n",
            "GRU  (PCA): MAE=4.0530, RMSE=5.5660\n",
            "GRU  (No PCA): MAE=3.0711, RMSE=4.3489\n",
            "\n",
            "最適なモデルは: GRU  (No PCA) (MAE=3.0711)\n",
            "最終予測にPCAは使用しません。\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "'hour' is not in list",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-2087319602>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mall_numeric_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mselected_cols\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"selected_features\"\u001b[0m\u001b[0;34m]\u001b[0m               \u001b[0;31m# 30 列\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0msel_idx\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mall_numeric_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# pipeline を上書き保存（あとで読み直す場合に備えて）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-2087319602>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mall_numeric_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mselected_cols\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"selected_features\"\u001b[0m\u001b[0;34m]\u001b[0m               \u001b[0;31m# 30 列\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0msel_idx\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mall_numeric_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# pipeline を上書き保存（あとで読み直す場合に備えて）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'hour' is not in list"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 最終提出データの作成"
      ],
      "metadata": {
        "id": "nFcXosEt0a62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "# test_dfに対する推論\n",
        "# test_IDが'spain_total'のデータのみを選択\n",
        "test_df_spain = test_df[test_df['item_ID'] == 'spain_total'].copy()\n",
        "\n",
        "# 欠損値処理 (trainと同じ処理を適用)\n",
        "test_df_spain = test_df_spain.ffill()\n",
        "test_df_spain = test_df_spain.bfill()\n",
        "\n",
        "# 'item_ID' 列を削除\n",
        "test_df_spain = test_df_spain.drop('item_ID', axis=1)\n",
        "\n",
        "# 保存したパイプラインを読み込み\n",
        "pipeline_load_path = data_path + 'price_prediction_pipeline.pkl'\n",
        "loaded_pipeline = None\n",
        "loaded_selected_features = None\n",
        "\n",
        "if os.path.exists(pipeline_load_path):\n",
        "    try:\n",
        "        with open(pipeline_load_path, 'rb') as f:\n",
        "            loaded_pipeline = pickle.load(f)\n",
        "\n",
        "        loaded_pca = loaded_pipeline['pca']\n",
        "        loaded_pca_scaler = loaded_pipeline['pca_scaler']\n",
        "        loaded_y_scaler = loaded_pipeline['y_scaler']\n",
        "        loaded_selected_features = loaded_pipeline['selected_features']\n",
        "        loaded_seq_length = loaded_pipeline['seq_length']\n",
        "\n",
        "        print(f\"\\nパイプラインをロードしました。学習時に選択された特徴量 ({len(loaded_selected_features)}個): {loaded_selected_features}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"パイプラインのロードに失敗しました: {e}\")\n",
        "        loaded_pipeline = None\n",
        "else:\n",
        "    print(f\"エラー: パイプラインファイル '{pipeline_load_path}' が見つかりません。\")\n",
        "\n",
        "if loaded_pipeline is not None and loaded_selected_features is not None:\n",
        "    # 学習データの特徴量エンジニアリング済みデータが必要\n",
        "    # dfに対して同じ特徴量エンジニアリングを適用\n",
        "    if 'df' in locals() or 'df' in globals():\n",
        "        # 学習データに特徴量エンジニアリングを適用（price_actualラグを含む）\n",
        "        df_featured_train = create_additional_features_combined(df.copy(), is_test=False)\n",
        "\n",
        "        # テストデータに特徴量エンジニアリングを適用（学習データを使ってラグを計算）\n",
        "        test_df_featured = create_additional_features_combined(\n",
        "            test_df_spain.copy(),\n",
        "            is_test=True,\n",
        "            train_df=df.copy()\n",
        "        )\n",
        "\n",
        "        print(f\"テストデータの特徴量エンジニアリング完了。形状: {test_df_featured.shape}\")\n",
        "\n",
        "        # NaN値の確認\n",
        "        nan_count = test_df_featured.isnull().sum().sum()\n",
        "        print(f\"テストデータのNaN値の総数: {nan_count}\")\n",
        "\n",
        "        if nan_count > 0:\n",
        "            print(\"NaN値が残っているカラム:\")\n",
        "            nan_columns = test_df_featured.isnull().sum()\n",
        "            print(nan_columns[nan_columns > 0])\n",
        "\n",
        "            # 残りのNaN値を0で埋める\n",
        "            test_df_featured = test_df_featured.fillna(0)\n",
        "            print(\"残りのNaN値を0で埋めました。\")\n",
        "\n",
        "        try:\n",
        "            # 学習時に選択された特徴量のみを抽出\n",
        "            test_data_aligned = test_df_featured[loaded_selected_features]\n",
        "            print(f\"テストデータ ({test_data_aligned.shape[1]}個の特徴量) のカラム順序を合わせました。\")\n",
        "\n",
        "            # 最終的なNaN確認\n",
        "            final_nan_count = test_data_aligned.isnull().sum().sum()\n",
        "            print(f\"最終的なNaN値の総数: {final_nan_count}\")\n",
        "\n",
        "            if final_nan_count > 0:\n",
        "                print(\"警告: まだNaN値が残っています。さらに処理します。\")\n",
        "                test_data_aligned = test_data_aligned.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
        "\n",
        "        except KeyError as e:\n",
        "            print(f\"エラー: 学習時に選択された特徴量 '{e}' がテストデータに見つかりません。\")\n",
        "            test_data_aligned = None\n",
        "\n",
        "        if test_data_aligned is not None:\n",
        "            # モデルをロード\n",
        "            lstm_model_path = data_path + 'lstm_model.h5'\n",
        "            try:\n",
        "                loaded_model = tf.keras.models.load_model(\n",
        "                    lstm_model_path,\n",
        "                    custom_objects={'mse': tf.keras.losses.MeanSquaredError()}\n",
        "                )\n",
        "                print(\"モデルを正常にロードしました。\")\n",
        "\n",
        "                # テストデータに前処理を適用\n",
        "                test_data_scaled = loaded_pca_scaler.transform(test_data_aligned)\n",
        "                test_data_pca = loaded_pca.transform(test_data_scaled)\n",
        "                print(f\"テストデータにスケーリングとPCAを適用しました。形状: {test_data_pca.shape}\")\n",
        "\n",
        "                # 学習データのPCA結果と結合\n",
        "                if 'X_pca' in locals() or 'X_pca' in globals():\n",
        "                    combined_data_pca = np.concatenate([X_pca, test_data_pca])\n",
        "                    print(f\"データを結合しました。形状: {combined_data_pca.shape}\")\n",
        "\n",
        "                    # 推論用シーケンスの作成\n",
        "                    X_inference = []\n",
        "                    start_index_test = len(X_pca)\n",
        "\n",
        "                    for i in range(len(test_data_pca)):\n",
        "                        seq_start = start_index_test + i - loaded_seq_length\n",
        "                        seq_end = start_index_test + i\n",
        "\n",
        "                        if seq_start >= 0:\n",
        "                            input_sequence = combined_data_pca[seq_start:seq_end]\n",
        "                            X_inference.append(input_sequence)\n",
        "\n",
        "                    if X_inference:\n",
        "                        X_inference = np.array(X_inference)\n",
        "                        print(f\"推論用シーケンスデータ形状: {X_inference.shape}\")\n",
        "\n",
        "                        # 予測実行\n",
        "                        scaled_predictions = loaded_model.predict(X_inference)\n",
        "                        predictions = loaded_y_scaler.inverse_transform(scaled_predictions).flatten()\n",
        "\n",
        "                        # 提出ファイル作成\n",
        "                        valid_test_indices = test_df_spain.index[len(test_df_spain) - len(predictions):]\n",
        "                        submission_df = pd.DataFrame({\n",
        "                            'id': [ts.strftime('%Y-%m-%d %H:%M:%S') for ts in valid_test_indices],\n",
        "                            'price_actual': predictions\n",
        "                        })\n",
        "\n",
        "                        submission_path = data_path + 'submission.csv'\n",
        "                        submission_df.to_csv(submission_path, header=False, index=False)\n",
        "\n",
        "                        print(f\"\\n推論結果を '{submission_path}' に保存しました。\")\n",
        "                        print(\"提出ファイルの先頭:\")\n",
        "                        display(pd.read_csv(submission_path, header=None).head())\n",
        "\n",
        "                    else:\n",
        "                        print(\"エラー: 予測のための入力シーケンスが作成できませんでした。\")\n",
        "                else:\n",
        "                    print(\"エラー: 学習データのPCA結果 (X_pca) が見つかりません。\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"モデルのロードまたは推論に失敗しました: {e}\")\n",
        "    else:\n",
        "        print(\"エラー: 学習データ (df) が見つかりません。\")\n",
        "else:\n",
        "    print(\"パイプラインがロードされなかったため、推論を実行できません。\")"
      ],
      "metadata": {
        "id": "dirpQrr1jDjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 最終メモ\n",
        "この修正により、PCAによる次元削減がモデル性能にどのような影響を与えるかを定量的に比較できるようになります。\n",
        "\n",
        "次に進めるべきステップとしては、ハイパーパラメータ検索の導入や、時系列交差検証のロジック一本化・ログ強化が考えられます。どちらに進みますか？ または、今回のコードについてさらに詳細な説明や修正が必要な点があればお知らせください。"
      ],
      "metadata": {
        "id": "-oFzFqAAI1qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 推論対象の特徴量と学習時特徴量の一致をチェック\n",
        "print(test_data_aligned.columns.tolist() == loaded_selected_features)\n",
        "\n",
        "# 2. テストデータの最初のラグ特徴量確認\n",
        "print(test_df_featured[['price_actual_lag_1', 'price_actual_lag_24']].head())\n",
        "\n",
        "# 3. シーケンスの中身確認（shapeと内容）\n",
        "print(X_inference.shape)\n",
        "print(X_inference[0][-1])  # 最後のタイムステップの値\n",
        "\n",
        "# 4. モデルの確認\n",
        "print(best_model_name)  # 'GRU (PCA)' になってるか\n"
      ],
      "metadata": {
        "id": "bEiZWYl-I20O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}