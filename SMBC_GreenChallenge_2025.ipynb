{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "mount_file_id": "1qJrYs6ebh932MmFEf4SGjwkUpA2BdVII",
      "authorship_tag": "ABX9TyOoV9dgvRTcAhLto0VP3taC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hidenori24/Signate_colab/blob/main/SMBC_GreenChallenge_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## importとシードなどの設定"
      ],
      "metadata": {
        "id": "x-BsQNWyMS0G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MK3beRd6Kjrh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.decomposition import PCA\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# 日本語フォントを簡単に使う\n",
        "!pip -q install japanize-matplotlib\n",
        "import japanize_matplotlib\n",
        "\n",
        "# シードの設定\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Driveへの接続、データの取得"
      ],
      "metadata": {
        "id": "AMwtDtYJO009"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/MyDrive/ML/Signate_1634/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCR43u2YO4_X",
        "outputId": "98280689-f180-45df-b2ac-9b4afa7789e4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train/test/sample_submission の取り込み"
      ],
      "metadata": {
        "id": "ZUdy-QCLPKSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df  = pd.read_csv(data_path + 'train.csv', parse_dates=['time'], index_col='time')\n",
        "df = train_df\n",
        "test_df   = pd.read_csv(data_path + 'test.csv', parse_dates=['time'], index_col='time')\n",
        "sample_submission_df = pd.read_csv(data_path + 'sample_submit.csv', header=None)  # header 無し"
      ],
      "metadata": {
        "id": "gugrOPbtPIaz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 概要確認"
      ],
      "metadata": {
        "id": "FT0Jun66P6ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 概要を確認\n",
        "print(\"\\n--- 学習データ (train_df) ---\")\n",
        "display(train_df.head())\n",
        "print(f\"shape: {train_df.shape}\")\n",
        "\n",
        "print(\"\\n--- テストデータ (test_df) ---\")\n",
        "display(test_df.head())\n",
        "print(f\"shape: {test_df.shape}\")\n",
        "\n",
        "print(\"\\n--- サンプル提出 (sample_submission_df) ---\")\n",
        "display(sample_submission_df.head())\n",
        "print(f\"shape: {sample_submission_df.shape}\")"
      ],
      "metadata": {
        "id": "cSti76YKP44d",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b17e8442-80a2-4434-c314-d6cea8cad927"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 学習データ (train_df) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                           generation_biomass  \\\n",
              "time                                            \n",
              "2015-01-02 00:00:00+01:00               447.0   \n",
              "2015-01-02 01:00:00+01:00               449.0   \n",
              "2015-01-02 02:00:00+01:00               448.0   \n",
              "2015-01-02 03:00:00+01:00               438.0   \n",
              "2015-01-02 04:00:00+01:00               428.0   \n",
              "\n",
              "                           generation_fossil_brown_coal/lignite  \\\n",
              "time                                                              \n",
              "2015-01-02 00:00:00+01:00                                 329.0   \n",
              "2015-01-02 01:00:00+01:00                                 328.0   \n",
              "2015-01-02 02:00:00+01:00                                 323.0   \n",
              "2015-01-02 03:00:00+01:00                                 254.0   \n",
              "2015-01-02 04:00:00+01:00                                 187.0   \n",
              "\n",
              "                           generation_fossil_gas  generation_fossil_hard_coal  \\\n",
              "time                                                                            \n",
              "2015-01-02 00:00:00+01:00                 4844.0                       4821.0   \n",
              "2015-01-02 01:00:00+01:00                 5196.0                       4755.0   \n",
              "2015-01-02 02:00:00+01:00                 4857.0                       4581.0   \n",
              "2015-01-02 03:00:00+01:00                 4314.0                       4131.0   \n",
              "2015-01-02 04:00:00+01:00                 4130.0                       3840.0   \n",
              "\n",
              "                           generation_fossil_oil  \\\n",
              "time                                               \n",
              "2015-01-02 00:00:00+01:00                  162.0   \n",
              "2015-01-02 01:00:00+01:00                  158.0   \n",
              "2015-01-02 02:00:00+01:00                  157.0   \n",
              "2015-01-02 03:00:00+01:00                  160.0   \n",
              "2015-01-02 04:00:00+01:00                  156.0   \n",
              "\n",
              "                           generation_hydro_pumped_storage_consumption  \\\n",
              "time                                                                     \n",
              "2015-01-02 00:00:00+01:00                                        863.0   \n",
              "2015-01-02 01:00:00+01:00                                        920.0   \n",
              "2015-01-02 02:00:00+01:00                                       1164.0   \n",
              "2015-01-02 03:00:00+01:00                                       1503.0   \n",
              "2015-01-02 04:00:00+01:00                                       1826.0   \n",
              "\n",
              "                           generation_hydro_run_of_river_and_poundage  \\\n",
              "time                                                                    \n",
              "2015-01-02 00:00:00+01:00                                      1051.0   \n",
              "2015-01-02 01:00:00+01:00                                      1009.0   \n",
              "2015-01-02 02:00:00+01:00                                       973.0   \n",
              "2015-01-02 03:00:00+01:00                                       949.0   \n",
              "2015-01-02 04:00:00+01:00                                       953.0   \n",
              "\n",
              "                           generation_hydro_water_reservoir  \\\n",
              "time                                                          \n",
              "2015-01-02 00:00:00+01:00                            1899.0   \n",
              "2015-01-02 01:00:00+01:00                            1658.0   \n",
              "2015-01-02 02:00:00+01:00                            1371.0   \n",
              "2015-01-02 03:00:00+01:00                             779.0   \n",
              "2015-01-02 04:00:00+01:00                             720.0   \n",
              "\n",
              "                           generation_nuclear  generation_other  ...  \\\n",
              "time                                                             ...   \n",
              "2015-01-02 00:00:00+01:00              7096.0              43.0  ...   \n",
              "2015-01-02 01:00:00+01:00              7096.0              43.0  ...   \n",
              "2015-01-02 02:00:00+01:00              7099.0              43.0  ...   \n",
              "2015-01-02 03:00:00+01:00              7098.0              43.0  ...   \n",
              "2015-01-02 04:00:00+01:00              7097.0              43.0  ...   \n",
              "\n",
              "                           seville_rain_1h  seville_rain_3h  seville_snow_3h  \\\n",
              "time                                                                           \n",
              "2015-01-02 00:00:00+01:00              0.0              0.0                0   \n",
              "2015-01-02 01:00:00+01:00              0.0              0.0                0   \n",
              "2015-01-02 02:00:00+01:00              0.0              0.0                0   \n",
              "2015-01-02 03:00:00+01:00              0.0              0.0                0   \n",
              "2015-01-02 04:00:00+01:00              0.0              0.0                0   \n",
              "\n",
              "                           seville_clouds_all  seville_weather_id  \\\n",
              "time                                                                \n",
              "2015-01-02 00:00:00+01:00                   0                 800   \n",
              "2015-01-02 01:00:00+01:00                   0                 800   \n",
              "2015-01-02 02:00:00+01:00                   0                 800   \n",
              "2015-01-02 03:00:00+01:00                   0                 800   \n",
              "2015-01-02 04:00:00+01:00                   0                 800   \n",
              "\n",
              "                           seville_weather_main  seville_weather_description  \\\n",
              "time                                                                           \n",
              "2015-01-02 00:00:00+01:00                 clear                 sky is clear   \n",
              "2015-01-02 01:00:00+01:00                 clear                 sky is clear   \n",
              "2015-01-02 02:00:00+01:00                 clear                 sky is clear   \n",
              "2015-01-02 03:00:00+01:00                 clear                 sky is clear   \n",
              "2015-01-02 04:00:00+01:00                 clear                 sky is clear   \n",
              "\n",
              "                           seville_weather_icon  price_actual      item_ID  \n",
              "time                                                                        \n",
              "2015-01-02 00:00:00+01:00                   01n         64.02  spain_total  \n",
              "2015-01-02 01:00:00+01:00                   01n         58.46  spain_total  \n",
              "2015-01-02 02:00:00+01:00                   01n         54.70  spain_total  \n",
              "2015-01-02 03:00:00+01:00                   01n         54.91  spain_total  \n",
              "2015-01-02 04:00:00+01:00                   01n         53.07  spain_total  \n",
              "\n",
              "[5 rows x 92 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e194adaa-659e-4ca3-8937-c7d60bd32f4e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generation_biomass</th>\n",
              "      <th>generation_fossil_brown_coal/lignite</th>\n",
              "      <th>generation_fossil_gas</th>\n",
              "      <th>generation_fossil_hard_coal</th>\n",
              "      <th>generation_fossil_oil</th>\n",
              "      <th>generation_hydro_pumped_storage_consumption</th>\n",
              "      <th>generation_hydro_run_of_river_and_poundage</th>\n",
              "      <th>generation_hydro_water_reservoir</th>\n",
              "      <th>generation_nuclear</th>\n",
              "      <th>generation_other</th>\n",
              "      <th>...</th>\n",
              "      <th>seville_rain_1h</th>\n",
              "      <th>seville_rain_3h</th>\n",
              "      <th>seville_snow_3h</th>\n",
              "      <th>seville_clouds_all</th>\n",
              "      <th>seville_weather_id</th>\n",
              "      <th>seville_weather_main</th>\n",
              "      <th>seville_weather_description</th>\n",
              "      <th>seville_weather_icon</th>\n",
              "      <th>price_actual</th>\n",
              "      <th>item_ID</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-01-02 00:00:00+01:00</th>\n",
              "      <td>447.0</td>\n",
              "      <td>329.0</td>\n",
              "      <td>4844.0</td>\n",
              "      <td>4821.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>863.0</td>\n",
              "      <td>1051.0</td>\n",
              "      <td>1899.0</td>\n",
              "      <td>7096.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>64.02</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-02 01:00:00+01:00</th>\n",
              "      <td>449.0</td>\n",
              "      <td>328.0</td>\n",
              "      <td>5196.0</td>\n",
              "      <td>4755.0</td>\n",
              "      <td>158.0</td>\n",
              "      <td>920.0</td>\n",
              "      <td>1009.0</td>\n",
              "      <td>1658.0</td>\n",
              "      <td>7096.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>58.46</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-02 02:00:00+01:00</th>\n",
              "      <td>448.0</td>\n",
              "      <td>323.0</td>\n",
              "      <td>4857.0</td>\n",
              "      <td>4581.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>1164.0</td>\n",
              "      <td>973.0</td>\n",
              "      <td>1371.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>54.70</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-02 03:00:00+01:00</th>\n",
              "      <td>438.0</td>\n",
              "      <td>254.0</td>\n",
              "      <td>4314.0</td>\n",
              "      <td>4131.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>1503.0</td>\n",
              "      <td>949.0</td>\n",
              "      <td>779.0</td>\n",
              "      <td>7098.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>54.91</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-01-02 04:00:00+01:00</th>\n",
              "      <td>428.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>4130.0</td>\n",
              "      <td>3840.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>1826.0</td>\n",
              "      <td>953.0</td>\n",
              "      <td>720.0</td>\n",
              "      <td>7097.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>53.07</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 92 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e194adaa-659e-4ca3-8937-c7d60bd32f4e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e194adaa-659e-4ca3-8937-c7d60bd32f4e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e194adaa-659e-4ca3-8937-c7d60bd32f4e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-622b5fa1-57a1-4964-a10b-0e6d9567ca00\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-622b5fa1-57a1-4964-a10b-0e6d9567ca00')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-622b5fa1-57a1-4964-a10b-0e6d9567ca00 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (26280, 92)\n",
            "\n",
            "--- テストデータ (test_df) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                           generation_biomass  \\\n",
              "time                                            \n",
              "2018-01-01 00:00:00+01:00               279.0   \n",
              "2018-01-01 01:00:00+01:00               282.0   \n",
              "2018-01-01 02:00:00+01:00               283.0   \n",
              "2018-01-01 03:00:00+01:00               280.0   \n",
              "2018-01-01 04:00:00+01:00               286.0   \n",
              "\n",
              "                           generation_fossil_brown_coal/lignite  \\\n",
              "time                                                              \n",
              "2018-01-01 00:00:00+01:00                                   0.0   \n",
              "2018-01-01 01:00:00+01:00                                   0.0   \n",
              "2018-01-01 02:00:00+01:00                                   0.0   \n",
              "2018-01-01 03:00:00+01:00                                   0.0   \n",
              "2018-01-01 04:00:00+01:00                                   0.0   \n",
              "\n",
              "                           generation_fossil_gas  generation_fossil_hard_coal  \\\n",
              "time                                                                            \n",
              "2018-01-01 00:00:00+01:00                 3927.0                        895.0   \n",
              "2018-01-01 01:00:00+01:00                 3948.0                        878.0   \n",
              "2018-01-01 02:00:00+01:00                 3791.0                        890.0   \n",
              "2018-01-01 03:00:00+01:00                 3671.0                        881.0   \n",
              "2018-01-01 04:00:00+01:00                 3460.0                        861.0   \n",
              "\n",
              "                           generation_fossil_oil  \\\n",
              "time                                               \n",
              "2018-01-01 00:00:00+01:00                  189.0   \n",
              "2018-01-01 01:00:00+01:00                  177.0   \n",
              "2018-01-01 02:00:00+01:00                  175.0   \n",
              "2018-01-01 03:00:00+01:00                  175.0   \n",
              "2018-01-01 04:00:00+01:00                  173.0   \n",
              "\n",
              "                           generation_hydro_pumped_storage_consumption  \\\n",
              "time                                                                     \n",
              "2018-01-01 00:00:00+01:00                                        230.0   \n",
              "2018-01-01 01:00:00+01:00                                       1269.0   \n",
              "2018-01-01 02:00:00+01:00                                       2197.0   \n",
              "2018-01-01 03:00:00+01:00                                       2965.0   \n",
              "2018-01-01 04:00:00+01:00                                       2705.0   \n",
              "\n",
              "                           generation_hydro_run_of_river_and_poundage  \\\n",
              "time                                                                    \n",
              "2018-01-01 00:00:00+01:00                                      1069.0   \n",
              "2018-01-01 01:00:00+01:00                                      1058.0   \n",
              "2018-01-01 02:00:00+01:00                                      1052.0   \n",
              "2018-01-01 03:00:00+01:00                                      1032.0   \n",
              "2018-01-01 04:00:00+01:00                                      1001.0   \n",
              "\n",
              "                           generation_hydro_water_reservoir  \\\n",
              "time                                                          \n",
              "2018-01-01 00:00:00+01:00                            1893.0   \n",
              "2018-01-01 01:00:00+01:00                            1024.0   \n",
              "2018-01-01 02:00:00+01:00                             888.0   \n",
              "2018-01-01 03:00:00+01:00                             645.0   \n",
              "2018-01-01 04:00:00+01:00                             661.0   \n",
              "\n",
              "                           generation_nuclear  generation_other  ...  \\\n",
              "time                                                             ...   \n",
              "2018-01-01 00:00:00+01:00              7104.0              53.0  ...   \n",
              "2018-01-01 01:00:00+01:00              7101.0              52.0  ...   \n",
              "2018-01-01 02:00:00+01:00              7100.0              52.0  ...   \n",
              "2018-01-01 03:00:00+01:00              7101.0              53.0  ...   \n",
              "2018-01-01 04:00:00+01:00              7101.0              53.0  ...   \n",
              "\n",
              "                           seville_wind_deg  seville_rain_1h  seville_rain_3h  \\\n",
              "time                                                                            \n",
              "2018-01-01 00:00:00+01:00               343              0.0              0.0   \n",
              "2018-01-01 01:00:00+01:00               343              0.0              0.0   \n",
              "2018-01-01 02:00:00+01:00                 0              0.0              0.0   \n",
              "2018-01-01 03:00:00+01:00                40              0.0              0.0   \n",
              "2018-01-01 04:00:00+01:00                30              0.0              0.0   \n",
              "\n",
              "                           seville_snow_3h  seville_clouds_all  \\\n",
              "time                                                             \n",
              "2018-01-01 00:00:00+01:00                0                   0   \n",
              "2018-01-01 01:00:00+01:00                0                   0   \n",
              "2018-01-01 02:00:00+01:00                0                   0   \n",
              "2018-01-01 03:00:00+01:00                0                   0   \n",
              "2018-01-01 04:00:00+01:00                0                   0   \n",
              "\n",
              "                           seville_weather_id  seville_weather_main  \\\n",
              "time                                                                  \n",
              "2018-01-01 00:00:00+01:00                 800                 clear   \n",
              "2018-01-01 01:00:00+01:00                 800                 clear   \n",
              "2018-01-01 02:00:00+01:00                 800                 clear   \n",
              "2018-01-01 03:00:00+01:00                 800                 clear   \n",
              "2018-01-01 04:00:00+01:00                 800                 clear   \n",
              "\n",
              "                           seville_weather_description  seville_weather_icon  \\\n",
              "time                                                                           \n",
              "2018-01-01 00:00:00+01:00                 sky is clear                   01n   \n",
              "2018-01-01 01:00:00+01:00                 sky is clear                   01n   \n",
              "2018-01-01 02:00:00+01:00                 sky is clear                   01n   \n",
              "2018-01-01 03:00:00+01:00                 sky is clear                   01n   \n",
              "2018-01-01 04:00:00+01:00                 sky is clear                   01n   \n",
              "\n",
              "                               item_ID  \n",
              "time                                    \n",
              "2018-01-01 00:00:00+01:00  spain_total  \n",
              "2018-01-01 01:00:00+01:00  spain_total  \n",
              "2018-01-01 02:00:00+01:00  spain_total  \n",
              "2018-01-01 03:00:00+01:00  spain_total  \n",
              "2018-01-01 04:00:00+01:00  spain_total  \n",
              "\n",
              "[5 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acc32273-d4ad-4d97-a94f-26bec8121566\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generation_biomass</th>\n",
              "      <th>generation_fossil_brown_coal/lignite</th>\n",
              "      <th>generation_fossil_gas</th>\n",
              "      <th>generation_fossil_hard_coal</th>\n",
              "      <th>generation_fossil_oil</th>\n",
              "      <th>generation_hydro_pumped_storage_consumption</th>\n",
              "      <th>generation_hydro_run_of_river_and_poundage</th>\n",
              "      <th>generation_hydro_water_reservoir</th>\n",
              "      <th>generation_nuclear</th>\n",
              "      <th>generation_other</th>\n",
              "      <th>...</th>\n",
              "      <th>seville_wind_deg</th>\n",
              "      <th>seville_rain_1h</th>\n",
              "      <th>seville_rain_3h</th>\n",
              "      <th>seville_snow_3h</th>\n",
              "      <th>seville_clouds_all</th>\n",
              "      <th>seville_weather_id</th>\n",
              "      <th>seville_weather_main</th>\n",
              "      <th>seville_weather_description</th>\n",
              "      <th>seville_weather_icon</th>\n",
              "      <th>item_ID</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2018-01-01 00:00:00+01:00</th>\n",
              "      <td>279.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3927.0</td>\n",
              "      <td>895.0</td>\n",
              "      <td>189.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>1069.0</td>\n",
              "      <td>1893.0</td>\n",
              "      <td>7104.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>...</td>\n",
              "      <td>343</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 01:00:00+01:00</th>\n",
              "      <td>282.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3948.0</td>\n",
              "      <td>878.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>1269.0</td>\n",
              "      <td>1058.0</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>7101.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>...</td>\n",
              "      <td>343</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 02:00:00+01:00</th>\n",
              "      <td>283.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3791.0</td>\n",
              "      <td>890.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>2197.0</td>\n",
              "      <td>1052.0</td>\n",
              "      <td>888.0</td>\n",
              "      <td>7100.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 03:00:00+01:00</th>\n",
              "      <td>280.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3671.0</td>\n",
              "      <td>881.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>2965.0</td>\n",
              "      <td>1032.0</td>\n",
              "      <td>645.0</td>\n",
              "      <td>7101.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>...</td>\n",
              "      <td>40</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 04:00:00+01:00</th>\n",
              "      <td>286.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3460.0</td>\n",
              "      <td>861.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>2705.0</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>661.0</td>\n",
              "      <td>7101.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>...</td>\n",
              "      <td>30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>800</td>\n",
              "      <td>clear</td>\n",
              "      <td>sky is clear</td>\n",
              "      <td>01n</td>\n",
              "      <td>spain_total</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 91 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acc32273-d4ad-4d97-a94f-26bec8121566')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-acc32273-d4ad-4d97-a94f-26bec8121566 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-acc32273-d4ad-4d97-a94f-26bec8121566');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7047efb5-e2e5-4379-aa69-ef11275deb55\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7047efb5-e2e5-4379-aa69-ef11275deb55')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7047efb5-e2e5-4379-aa69-ef11275deb55 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (8760, 91)\n",
            "\n",
            "--- サンプル提出 (sample_submission_df) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                           0  1\n",
              "0  2018-01-01 00:00:00+01:00  0\n",
              "1  2018-01-01 01:00:00+01:00  0\n",
              "2  2018-01-01 02:00:00+01:00  0\n",
              "3  2018-01-01 03:00:00+01:00  0\n",
              "4  2018-01-01 04:00:00+01:00  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f5019ab-ce1a-41ea-a81a-3fbf6e6c720f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-01 00:00:00+01:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-01 01:00:00+01:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-01 02:00:00+01:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-01 03:00:00+01:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-01 04:00:00+01:00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f5019ab-ce1a-41ea-a81a-3fbf6e6c720f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1f5019ab-ce1a-41ea-a81a-3fbf6e6c720f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1f5019ab-ce1a-41ea-a81a-3fbf6e6c720f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-491a9f27-370d-4512-8fcd-82fc1d8a3628\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-491a9f27-370d-4512-8fcd-82fc1d8a3628')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-491a9f27-370d-4512-8fcd-82fc1d8a3628 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(f\\\"shape: {sample_submission_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2018-01-01 01:00:00+01:00\",\n          \"2018-01-01 04:00:00+01:00\",\n          \"2018-01-01 02:00:00+01:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape: (8760, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データの前処理\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FOl1SGI5QnSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 基本情報を確認\n",
        "print(f\"データのサイズ: {df.shape}\")\n",
        "print(f\"期間: {df.index.min()} から {df.index.max()}\")\n",
        "print(f\"推論対象の期間: {test_df.index.min()} から {test_df.index.max()}\")\n",
        "print(f\"⽋損値の合計: {df.isna().sum().sum()}\")\n",
        "# ⽋損値を処理\n",
        "# 時系列データなので、前⽅補間が適切\n",
        "#df = df.fillna(method='ffill')\n",
        "df = df.ffill()\n",
        "# まだ⽋損がある場合は後⽅補間\n",
        "#df = df.fillna(method='bfill')\n",
        "df = df.bfill()\n",
        "# ⽬的変数の確認\n",
        "print(\"\\n⽬的変数 'price_actual' の統計:\")\n",
        "print(df['price_actual'].describe())\n",
        "# 価格の時系列プロット\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(df.index, df['price_actual'])\n",
        "plt.title('電⼒価格の推移')\n",
        "plt.ylabel('価格')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig('price_time_series.png')\n",
        "plt.close()\n",
        "# 説明変数を準備\n",
        "# item_IDはスペインの合計データのみ使⽤\n",
        "df = df[df['item_ID'] == 'spain_total']\n",
        "# 不要な列を削除\n",
        "X = df.drop(['price_actual', 'item_ID'], axis=1)\n",
        "# ⽬的変数\n",
        "y = df['price_actual']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHKftlr8Qqib",
        "outputId": "048a8c41-3894-430f-fa83-8d7681875b3f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "データのサイズ: (26280, 92)\n",
            "期間: 2015-01-02 00:00:00+01:00 から 2017-12-31 23:00:00+01:00\n",
            "推論対象の期間: 2018-01-01 00:00:00+01:00 から 2018-12-31 23:00:00+01:00\n",
            "⽋損値の合計: 321\n",
            "\n",
            "⽬的変数 'price_actual' の統計:\n",
            "count    26280.000000\n",
            "mean        56.028338\n",
            "std         14.340356\n",
            "min          9.330000\n",
            "25%         47.617500\n",
            "50%         55.930000\n",
            "75%         65.192500\n",
            "max        116.800000\n",
            "Name: price_actual, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 特徴量エンジニアリング"
      ],
      "metadata": {
        "id": "fK3TvhMbxZ24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_additional_features(df):\n",
        "    \"\"\"\n",
        "    時間ベースの特徴量とラグ特徴量を作成\n",
        "    \"\"\"\n",
        "    df_features = df.copy()\n",
        "\n",
        "    # インデックスがDatetimeIndexであることを確認し、必要なら変換\n",
        "    if not isinstance(df_features.index, pd.DatetimeIndex) or df_features.index.tz is not None:\n",
        "        df_features.index = pd.to_datetime(df_features.index, utc=True)\n",
        "\n",
        "    # ここから既存の時間ベースの特徴量作成コード\n",
        "    df_features['hour'] = df_features.index.hour\n",
        "    df_features['dayofweek'] = df_features.index.dayofweek\n",
        "    df_features['month'] = df_features.index.month\n",
        "    df_features['year'] = df_features.index.year\n",
        "    df_features['quarter'] = df_features.index.quarter\n",
        "    df_features['dayofyear'] = df_features.index.dayofyear\n",
        "    # ISO週番号の取得方法が古いバージョンのPandasで異なる場合があります。\n",
        "    # .weekofyear は非推奨になったため、.isocalendar().week を使用するのが推奨です。\n",
        "    # ただし、もし古いPandasバージョンでisocalendarが使えない場合は .weekofyear を試してください。\n",
        "    try:\n",
        "        df_features['weekofyear'] = df_features.index.isocalendar().week.astype(int) # ISO週番号\n",
        "    except AttributeError:\n",
        "        # もし isocalendar がない場合は、古い .weekofyear を試す\n",
        "        print(\"警告: .isocalendar() が見つかりません。代わりに .weekofyear を使用します。Pandasのバージョンを確認してください。\")\n",
        "        df_features['weekofyear'] = df_features.index.weekofyear.astype(int)\n",
        "\n",
        "    df_features['dayofmonth'] = df_features.index.day\n",
        "    df_features['is_weekend'] = (df_features.index.dayofweek >= 5).astype(int)\n",
        "\n",
        "    # ラグ特徴量（例: 1時間前、24時間前、48時間前、1週間前）\n",
        "    # ... (既存のラグ特徴量作成コード)\n",
        "    df_features['price_actual_lag_1'] = df_features['price_actual'].shift(1)\n",
        "    df_features['price_actual_lag_24'] = df_features['price_actual'].shift(24)\n",
        "    df_features['price_actual_lag_48'] = df_features['price_actual'].shift(48)\n",
        "    df_features['price_actual_lag_168'] = df_features['price_actual'].shift(168) # 1週間前\n",
        "\n",
        "    # 必要に応じて他の特徴量のラグも追加できます。\n",
        "    # 例: df_features['consumption_lag_24'] = df_features['consumption'].shift(24)\n",
        "\n",
        "    # 移動平均（例: 24時間の移動平均）\n",
        "    df_features['price_actual_rolling_mean_24'] = df_features['price_actual'].rolling(window=24).mean()\n",
        "\n",
        "    # 指数平滑化（例: span=24の指数平滑化）\n",
        "    #df_features['price_actual_ewm_24'] = df_features['price_actual'].ewm(span=24).mean()\n",
        "\n",
        "\n",
        "    # 新たに生成された特徴量によって発生する可能性のある欠損値を処理\n",
        "    df_features = df_features.ffill()\n",
        "    df_features = df_features.bfill()\n",
        "\n",
        "    return df_features"
      ],
      "metadata": {
        "id": "ksJ_f75-xfMZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 特徴量選択と次元削減"
      ],
      "metadata": {
        "id": "76OSHBupRJ3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量選択（f_regressionを使って上位の特徴を選択）\n",
        "def select_features_and_scale(X, y, k=30):\n",
        "    \"\"\"\n",
        "    特徴量選択前に標準化を行い、選択された特徴量を返す\n",
        "    \"\"\"\n",
        "    # 数値型以外のカラムを削除\n",
        "    X_numeric = X.select_dtypes(include=np.number)\n",
        "\n",
        "    # 標準化\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X_numeric)\n",
        "    X_scaled_df = pd.DataFrame(X_scaled, index=X_numeric.index, columns=X_numeric.columns) # DataFrameに戻す\n",
        "\n",
        "    # もし数値型カラムがkより少ない場合はkを調整\n",
        "    k = min(k, X_scaled_df.shape[1])\n",
        "\n",
        "    selector = SelectKBest(score_func=f_regression, k=k)\n",
        "    X_selected_scaled = selector.fit_transform(X_scaled_df, y)\n",
        "\n",
        "    # 選択された特徴のインデックスを取得\n",
        "    selected_indices = selector.get_support(indices=True)\n",
        "    selected_features = X_scaled_df.columns[selected_indices]\n",
        "    print(f\"標準化後、選択された特徴量 ({k}個): {selected_features.tolist()}\")\n",
        "\n",
        "    # 選択された特徴量を DataFrame として返す（スケール済み）\n",
        "    return pd.DataFrame(X_selected_scaled, index=X_numeric.index, columns=selected_features), scaler, selector\n",
        "\n",
        "# PCAで次元削減 (選択された特徴量に対して適用)\n",
        "def apply_pca_on_selected(X_selected_scaled, n_components=15):\n",
        "  # X_selected_scaled はすでに StandardScaler でスケール済みを想定\n",
        "  pca = PCA(n_components=n_components)\n",
        "  X_pca = pca.fit_transform(X_selected_scaled)\n",
        "\n",
        "  # 説明された分散の比率を確認\n",
        "  explained_variance = pca.explained_variance_ratio_.sum()\n",
        "  print(f\"PCAにより{n_components}成分で{explained_variance:.2%}の分散を説明 (選択特徴量から)\")\n",
        "  return X_pca, pca\n",
        "\n",
        "# 特徴量エンジニアリングを適用\n",
        "df_featured = create_additional_features(df.copy())\n",
        "\n",
        "# 特徴量エンジニアリング後のデータから説明変数と目的変数を作成\n",
        "X_featured = df_featured.drop(['price_actual', 'item_ID'], axis=1)\n",
        "y_featured = df_featured['price_actual']\n",
        "\n",
        "# 特徴量選択と標準化を適用\n",
        "X_selected_scaled, feature_scaler, feature_selector = select_features_and_scale(X_featured, y_featured, k=30)\n",
        "\n",
        "# 選択された特徴量にPCAを適用\n",
        "X_pca, pca = apply_pca_on_selected(X_selected_scaled, n_components=15)\n",
        "\n",
        "# 相関ヒートマップ（選択された特徴量 - スケール済み）\n",
        "# X_selected_scaled が DataFrame なのでそのまま corr() を使用\n",
        "plt.figure(figsize=(15, 12))\n",
        "correlation = X_selected_scaled.corr()\n",
        "mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
        "sns.heatmap(correlation, mask=mask, annot=False, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('標準化・選択された特徴量の相関ヒートマップ')\n",
        "plt.tight_layout()\n",
        "plt.savefig('selected_feature_correlation.png')\n",
        "plt.close()\n",
        "\n",
        "# PCA を外す場合のデータ準備 (スケール済み・選択済みだが PCA なし)\n",
        "X_no_pca = X_selected_scaled.values # numpy 配列として取得\n",
        "print(f\"PCA適用なしデータ形状: {X_no_pca.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ4me37_RKgH",
        "outputId": "c4c173df-c433-491a-8201-a641ac1c539d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "標準化後、選択された特徴量 (30個): ['generation_biomass', 'generation_fossil_brown_coal/lignite', 'generation_fossil_gas', 'generation_fossil_hard_coal', 'generation_fossil_oil', 'generation_hydro_pumped_storage_consumption', 'generation_hydro_run_of_river_and_poundage', 'generation_other', 'total_load_actual', 'valencia_wind_speed', 'madrid_wind_speed', 'bilbao_pressure', 'bilbao_wind_speed', 'bilbao_wind_deg', 'bilbao_clouds_all', 'barcelona_wind_speed', 'seville_pressure', 'seville_wind_deg', 'hour', 'dayofweek', 'month', 'quarter', 'dayofyear', 'weekofyear', 'is_weekend', 'price_actual_lag_1', 'price_actual_lag_24', 'price_actual_lag_48', 'price_actual_lag_168', 'price_actual_rolling_mean_24']\n",
            "PCAにより15成分で88.59%の分散を説明 (選択特徴量から)\n",
            "PCA適用なしデータ形状: (26280, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 時系列データの準備"
      ],
      "metadata": {
        "id": "BXJU5TStRqwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(X, y, seq_length=24):\n",
        "    \"\"\"\n",
        "    時系列データのシーケンスを作成\n",
        "    seq_length: 何時間前までのデータを使うか（例：24時間）\n",
        "    \"\"\"\n",
        "    X_seq, y_seq = [], []\n",
        "\n",
        "    for i in range(len(X) - seq_length):\n",
        "        X_seq.append(X[i:i+seq_length])\n",
        "        y_seq.append(y[i+seq_length])\n",
        "\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "# スケーリング\n",
        "y_scaler = MinMaxScaler()\n",
        "y_scaled = y_scaler.fit_transform(y_featured.values.reshape(-1, 1))\n",
        "\n",
        "# データセットの分割割合\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "\n",
        "train_size = int(len(X_featured) * train_ratio)\n",
        "val_size = int(len(X_featured) * val_ratio)\n",
        "test_size = len(X_featured) - train_size - val_size # 残りをテストサイズとする\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# PCA適用データでの分割とシーケンス作成\n",
        "# -------------------------------------------------------------\n",
        "print(\"--- PCA適用データ ---\")\n",
        "X_train_pca = X_pca[:train_size]\n",
        "X_val_pca = X_pca[train_size:train_size+val_size]\n",
        "X_test_pca = X_pca[train_size+val_size:train_size+val_size+test_size]\n",
        "\n",
        "y_train_scaled_pca = y_scaled[:train_size]\n",
        "y_val_scaled_pca = y_scaled[train_size:train_size+val_size]\n",
        "y_test_scaled_pca = y_scaled[train_size+val_size:train_size+val_size+test_size]\n",
        "\n",
        "\n",
        "X_train_seq_pca, y_train_seq_pca = create_sequences(X_train_pca, y_train_scaled_pca, seq_length)\n",
        "X_val_seq_pca, y_val_seq_pca = create_sequences(X_val_pca, y_val_scaled_pca, seq_length)\n",
        "X_test_seq_pca, y_test_seq_pca = create_sequences(X_test_pca, y_test_scaled_pca, seq_length)\n",
        "\n",
        "print(f\"PCA適用トレーニングデータ形状: {X_train_seq_pca.shape}, {y_train_seq_pca.shape}\")\n",
        "print(f\"PCA適用検証データ形状: {X_val_seq_pca.shape}, {y_val_seq_pca.shape}\")\n",
        "print(f\"PCA適用テストデータ形状: {X_test_seq_pca.shape}, {y_test_seq_pca.shape}\")\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------\n",
        "# PCA適用なしデータでの分割とシーケンス作成\n",
        "# X_no_pca はすでに select_features_and_scale でスケール済み\n",
        "# -------------------------------------------------------------\n",
        "print(\"\\n--- PCA適用なしデータ ---\")\n",
        "X_train_no_pca = X_no_pca[:train_size]\n",
        "X_val_no_pca = X_no_pca[train_size:train_size+val_size]\n",
        "X_test_no_pca = X_no_pca[train_size+val_size:train_size+val_size+test_size]\n",
        "\n",
        "# 目的変数は共通のスケーリング済みデータを使用\n",
        "y_train_scaled_no_pca = y_scaled[:train_size]\n",
        "y_val_scaled_no_pca = y_scaled[train_size:train_size+val_size]\n",
        "y_test_scaled_no_pca = y_scaled[train_size+val_size:train_size+val_size+test_size]\n",
        "\n",
        "\n",
        "X_train_seq_no_pca, y_train_seq_no_pca = create_sequences(X_train_no_pca, y_train_scaled_no_pca, seq_length)\n",
        "X_val_seq_no_pca, y_val_seq_no_pca = create_sequences(X_val_no_pca, y_val_scaled_no_pca, seq_length)\n",
        "X_test_seq_no_pca, y_test_seq_no_pca = create_sequences(X_test_no_pca, y_test_scaled_no_pca, seq_length)\n",
        "\n",
        "\n",
        "print(f\"PCAなしトレーニングデータ形状: {X_train_seq_no_pca.shape}, {y_train_seq_no_pca.shape}\")\n",
        "print(f\"PCAなし検証データ形状: {X_val_seq_no_pca.shape}, {y_val_seq_no_pca.shape}\")\n",
        "print(f\"PCAなしテストデータ形状: {X_test_seq_no_pca.shape}, {y_test_seq_no_pca.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_DDT356RsTM",
        "outputId": "6afe8a5a-b46d-495c-986a-b47f2ab40b1b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- PCA適用データ ---\n",
            "PCA適用トレーニングデータ形状: (21000, 24, 15), (21000, 1)\n",
            "PCA適用検証データ形状: (2604, 24, 15), (2604, 1)\n",
            "PCA適用テストデータ形状: (2604, 24, 15), (2604, 1)\n",
            "\n",
            "--- PCA適用なしデータ ---\n",
            "PCAなしトレーニングデータ形状: (21000, 24, 30), (21000, 1)\n",
            "PCAなし検証データ形状: (2604, 24, 30), (2604, 1)\n",
            "PCAなしテストデータ形状: (2604, 24, 30), (2604, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデル構築と学習"
      ],
      "metadata": {
        "id": "D4bFBd9tR2Jk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTMモデル (PCA適用データ)"
      ],
      "metadata": {
        "id": "yVR_GONJSc-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm_model(seq_length, n_features):\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=(seq_length, n_features)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        LSTM(128, return_sequences=False),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "    return model\n",
        "\n",
        "# LSTMモデルの構築 (PCA適用データ)\n",
        "lstm_model_pca = build_lstm_model(seq_length, X_train_seq_pca.shape[2])\n",
        "print(\"\\n--- LSTMモデル (PCA適用) ---\")\n",
        "print(lstm_model_pca.summary())\n",
        "\n",
        "# コールバックの設定\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=15,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "checkpoint_pca = ModelCheckpoint(\n",
        "    data_path + 'lstm_model_pca.h5', # ファイル名を変更して区別\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=0.0001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# モデルの学習 (PCA適用データ)\n",
        "print(\"\\n--- LSTMモデル学習開始 (PCA適用) ---\")\n",
        "lstm_history_pca = lstm_model_pca.fit(\n",
        "    X_train_seq_pca, y_train_seq_pca,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val_seq_pca, y_val_seq_pca),\n",
        "    callbacks=[early_stopping, checkpoint_pca, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 学習履歴のプロット部分 (PCA適用)\n",
        "plt.figure(figsize=(7, 5))\n",
        "\n",
        "plt.plot(lstm_history_pca.history['loss'], label='Training Loss')\n",
        "plt.plot(lstm_history_pca.history['val_loss'], label='Validation Loss')\n",
        "plt.title('LSTM (PCA) - Loss (MSE)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('lstm_training_history_loss_pca.png') # ファイル名を変更\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ut-_ZiltR3a_",
        "outputId": "a4202af6-04dc-4e52-c692-2751896dd352",
        "collapsed": true
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- LSTMモデル (PCA適用) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m20,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m124,225\u001b[0m (485.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,225</span> (485.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m123,841\u001b[0m (483.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">123,841</span> (483.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\n",
            "--- LSTMモデル学習開始 (PCA適用) ---\n",
            "Epoch 1/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.4937\n",
            "Epoch 1: val_loss improved from inf to 0.02008, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 88ms/step - loss: 0.4921 - val_loss: 0.0201 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0504\n",
            "Epoch 2: val_loss improved from 0.02008 to 0.01338, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.0503 - val_loss: 0.0134 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0228\n",
            "Epoch 3: val_loss improved from 0.01338 to 0.00678, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 91ms/step - loss: 0.0228 - val_loss: 0.0068 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0150\n",
            "Epoch 4: val_loss improved from 0.00678 to 0.00566, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - loss: 0.0150 - val_loss: 0.0057 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0116\n",
            "Epoch 5: val_loss improved from 0.00566 to 0.00433, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - loss: 0.0116 - val_loss: 0.0043 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0097\n",
            "Epoch 6: val_loss improved from 0.00433 to 0.00248, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 94ms/step - loss: 0.0097 - val_loss: 0.0025 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0093\n",
            "Epoch 7: val_loss did not improve from 0.00248\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 86ms/step - loss: 0.0093 - val_loss: 0.0034 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0088\n",
            "Epoch 8: val_loss did not improve from 0.00248\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - loss: 0.0088 - val_loss: 0.0027 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0087\n",
            "Epoch 9: val_loss did not improve from 0.00248\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 84ms/step - loss: 0.0087 - val_loss: 0.0026 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0076\n",
            "Epoch 10: val_loss improved from 0.00248 to 0.00160, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - loss: 0.0076 - val_loss: 0.0016 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0076\n",
            "Epoch 11: val_loss did not improve from 0.00160\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 0.0076 - val_loss: 0.0068 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0089\n",
            "Epoch 12: val_loss did not improve from 0.00160\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 91ms/step - loss: 0.0089 - val_loss: 0.0030 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0084\n",
            "Epoch 13: val_loss did not improve from 0.00160\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 86ms/step - loss: 0.0084 - val_loss: 0.0042 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0081\n",
            "Epoch 14: val_loss did not improve from 0.00160\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 84ms/step - loss: 0.0081 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0075\n",
            "Epoch 15: val_loss did not improve from 0.00160\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 0.0075 - val_loss: 0.0023 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0055\n",
            "Epoch 16: val_loss did not improve from 0.00160\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 84ms/step - loss: 0.0055 - val_loss: 0.0017 - learning_rate: 2.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0051\n",
            "Epoch 17: val_loss did not improve from 0.00160\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - loss: 0.0051 - val_loss: 0.0016 - learning_rate: 2.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0053\n",
            "Epoch 18: val_loss improved from 0.00160 to 0.00158, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - loss: 0.0053 - val_loss: 0.0016 - learning_rate: 2.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0052\n",
            "Epoch 19: val_loss improved from 0.00158 to 0.00147, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 86ms/step - loss: 0.0052 - val_loss: 0.0015 - learning_rate: 2.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0050\n",
            "Epoch 20: val_loss did not improve from 0.00147\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - loss: 0.0050 - val_loss: 0.0018 - learning_rate: 2.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0048\n",
            "Epoch 21: val_loss did not improve from 0.00147\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - loss: 0.0048 - val_loss: 0.0017 - learning_rate: 2.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0046\n",
            "Epoch 22: val_loss did not improve from 0.00147\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 84ms/step - loss: 0.0046 - val_loss: 0.0017 - learning_rate: 2.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0044\n",
            "Epoch 23: val_loss did not improve from 0.00147\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 0.0044 - val_loss: 0.0017 - learning_rate: 2.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0046\n",
            "Epoch 24: val_loss did not improve from 0.00147\n",
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 82ms/step - loss: 0.0046 - val_loss: 0.0017 - learning_rate: 2.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0042\n",
            "Epoch 25: val_loss did not improve from 0.00147\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.0042 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0042\n",
            "Epoch 26: val_loss did not improve from 0.00147\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - loss: 0.0042 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0041\n",
            "Epoch 27: val_loss improved from 0.00147 to 0.00146, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 0.0041 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0041\n",
            "Epoch 28: val_loss improved from 0.00146 to 0.00142, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - loss: 0.0041 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0040\n",
            "Epoch 29: val_loss improved from 0.00142 to 0.00135, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 0.0040 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0040\n",
            "Epoch 30: val_loss did not improve from 0.00135\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 89ms/step - loss: 0.0040 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0040\n",
            "Epoch 31: val_loss did not improve from 0.00135\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 80ms/step - loss: 0.0040 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0040\n",
            "Epoch 32: val_loss did not improve from 0.00135\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - loss: 0.0040 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0040\n",
            "Epoch 33: val_loss did not improve from 0.00135\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 84ms/step - loss: 0.0040 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0039\n",
            "Epoch 34: val_loss improved from 0.00135 to 0.00133, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 0.0039 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0039\n",
            "Epoch 35: val_loss did not improve from 0.00133\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - loss: 0.0039 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0038\n",
            "Epoch 36: val_loss did not improve from 0.00133\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 93ms/step - loss: 0.0038 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0038\n",
            "Epoch 37: val_loss improved from 0.00133 to 0.00131, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 83ms/step - loss: 0.0038 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0039\n",
            "Epoch 38: val_loss did not improve from 0.00131\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 82ms/step - loss: 0.0039 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0038\n",
            "Epoch 39: val_loss improved from 0.00131 to 0.00130, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 98ms/step - loss: 0.0038 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0039\n",
            "Epoch 40: val_loss did not improve from 0.00130\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 83ms/step - loss: 0.0039 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0038\n",
            "Epoch 41: val_loss did not improve from 0.00130\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 88ms/step - loss: 0.0038 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0037\n",
            "Epoch 42: val_loss did not improve from 0.00130\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 92ms/step - loss: 0.0037 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0037\n",
            "Epoch 43: val_loss did not improve from 0.00130\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - loss: 0.0037 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0038\n",
            "Epoch 44: val_loss did not improve from 0.00130\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 82ms/step - loss: 0.0038 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0037\n",
            "Epoch 45: val_loss did not improve from 0.00130\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - loss: 0.0037 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0037\n",
            "Epoch 46: val_loss did not improve from 0.00130\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - loss: 0.0037 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0036\n",
            "Epoch 47: val_loss did not improve from 0.00130\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 83ms/step - loss: 0.0036 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0036\n",
            "Epoch 48: val_loss did not improve from 0.00130\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - loss: 0.0036 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0036\n",
            "Epoch 49: val_loss did not improve from 0.00130\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 81ms/step - loss: 0.0036 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0036\n",
            "Epoch 50: val_loss did not improve from 0.00130\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 83ms/step - loss: 0.0036 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0036\n",
            "Epoch 51: val_loss did not improve from 0.00130\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - loss: 0.0036 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0036\n",
            "Epoch 52: val_loss improved from 0.00130 to 0.00129, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - loss: 0.0036 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0036\n",
            "Epoch 53: val_loss did not improve from 0.00129\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.0036 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0035\n",
            "Epoch 54: val_loss did not improve from 0.00129\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 82ms/step - loss: 0.0035 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0035\n",
            "Epoch 55: val_loss improved from 0.00129 to 0.00128, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 88ms/step - loss: 0.0035 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0035\n",
            "Epoch 56: val_loss did not improve from 0.00128\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 83ms/step - loss: 0.0035 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0035\n",
            "Epoch 57: val_loss did not improve from 0.00128\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 86ms/step - loss: 0.0035 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0035\n",
            "Epoch 58: val_loss improved from 0.00128 to 0.00127, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - loss: 0.0035 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0035\n",
            "Epoch 59: val_loss improved from 0.00127 to 0.00126, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - loss: 0.0035 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0034\n",
            "Epoch 60: val_loss did not improve from 0.00126\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 82ms/step - loss: 0.0034 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0034\n",
            "Epoch 61: val_loss did not improve from 0.00126\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 91ms/step - loss: 0.0034 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0034\n",
            "Epoch 62: val_loss did not improve from 0.00126\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 83ms/step - loss: 0.0034 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0034\n",
            "Epoch 63: val_loss did not improve from 0.00126\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 81ms/step - loss: 0.0034 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0033\n",
            "Epoch 64: val_loss improved from 0.00126 to 0.00126, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - loss: 0.0033 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0033\n",
            "Epoch 65: val_loss did not improve from 0.00126\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.0033 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0033\n",
            "Epoch 66: val_loss did not improve from 0.00126\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 86ms/step - loss: 0.0033 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0032\n",
            "Epoch 67: val_loss did not improve from 0.00126\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - loss: 0.0032 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0032\n",
            "Epoch 68: val_loss did not improve from 0.00126\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 90ms/step - loss: 0.0032 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0033\n",
            "Epoch 69: val_loss did not improve from 0.00126\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 82ms/step - loss: 0.0033 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0032\n",
            "Epoch 70: val_loss improved from 0.00126 to 0.00126, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 87ms/step - loss: 0.0032 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0032\n",
            "Epoch 71: val_loss did not improve from 0.00126\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 83ms/step - loss: 0.0032 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0031\n",
            "Epoch 72: val_loss improved from 0.00126 to 0.00125, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 86ms/step - loss: 0.0031 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0031\n",
            "Epoch 73: val_loss did not improve from 0.00125\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - loss: 0.0031 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0031\n",
            "Epoch 74: val_loss did not improve from 0.00125\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - loss: 0.0031 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0030\n",
            "Epoch 75: val_loss did not improve from 0.00125\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 84ms/step - loss: 0.0030 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0030\n",
            "Epoch 76: val_loss did not improve from 0.00125\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - loss: 0.0030 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0030\n",
            "Epoch 77: val_loss improved from 0.00125 to 0.00122, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 89ms/step - loss: 0.0030 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0030\n",
            "Epoch 78: val_loss did not improve from 0.00122\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 85ms/step - loss: 0.0030 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0030\n",
            "Epoch 79: val_loss did not improve from 0.00122\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - loss: 0.0030 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0030\n",
            "Epoch 80: val_loss did not improve from 0.00122\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - loss: 0.0030 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0030\n",
            "Epoch 81: val_loss improved from 0.00122 to 0.00119, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 83ms/step - loss: 0.0030 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0029\n",
            "Epoch 82: val_loss did not improve from 0.00119\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 82ms/step - loss: 0.0029 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0029\n",
            "Epoch 83: val_loss did not improve from 0.00119\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 84ms/step - loss: 0.0029 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0029\n",
            "Epoch 84: val_loss did not improve from 0.00119\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 82ms/step - loss: 0.0029 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0029\n",
            "Epoch 85: val_loss did not improve from 0.00119\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 87ms/step - loss: 0.0029 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0029\n",
            "Epoch 86: val_loss did not improve from 0.00119\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 93ms/step - loss: 0.0029 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0029\n",
            "Epoch 87: val_loss did not improve from 0.00119\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - loss: 0.0029 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0028\n",
            "Epoch 88: val_loss did not improve from 0.00119\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - loss: 0.0028 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0028\n",
            "Epoch 89: val_loss did not improve from 0.00119\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - loss: 0.0028 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0028\n",
            "Epoch 90: val_loss did not improve from 0.00119\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 0.0028 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0028\n",
            "Epoch 91: val_loss did not improve from 0.00119\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 83ms/step - loss: 0.0028 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0028\n",
            "Epoch 92: val_loss did not improve from 0.00119\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - loss: 0.0028 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0028\n",
            "Epoch 93: val_loss did not improve from 0.00119\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - loss: 0.0028 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0027\n",
            "Epoch 94: val_loss did not improve from 0.00119\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 83ms/step - loss: 0.0027 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0027\n",
            "Epoch 95: val_loss improved from 0.00119 to 0.00117, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - loss: 0.0027 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0028\n",
            "Epoch 96: val_loss did not improve from 0.00117\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - loss: 0.0028 - val_loss: 0.0015 - learning_rate: 1.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0027\n",
            "Epoch 97: val_loss did not improve from 0.00117\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.0027 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0027\n",
            "Epoch 98: val_loss did not improve from 0.00117\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - loss: 0.0027 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0026\n",
            "Epoch 99: val_loss did not improve from 0.00117\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 83ms/step - loss: 0.0026 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0027\n",
            "Epoch 100: val_loss did not improve from 0.00117\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 81ms/step - loss: 0.0027 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 95.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTMモデル (PCA適用なし)"
      ],
      "metadata": {
        "id": "cC4Z9Tk6Y8N-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTMモデルの構築 (PCA適用なしデータ)\n",
        "# n_features が X_train_seq_no_pca の特徴量数になる\n",
        "lstm_model_no_pca = build_lstm_model(seq_length, X_train_seq_no_pca.shape[2])\n",
        "print(\"\\n--- LSTMモデル (PCA適用なし) ---\")\n",
        "print(lstm_model_no_pca.summary())\n",
        "\n",
        "checkpoint_no_pca = ModelCheckpoint(\n",
        "    data_path + 'lstm_model_no_pca.h5', # ファイル名を変更して区別\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "# モデルの学習 (PCA適用なしデータ)\n",
        "print(\"\\n--- LSTMモデル学習開始 (PCA適用なし) ---\")\n",
        "lstm_history_no_pca = lstm_model_no_pca.fit(\n",
        "    X_train_seq_no_pca, y_train_seq_no_pca,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val_seq_no_pca, y_val_seq_no_pca),\n",
        "    callbacks=[early_stopping, checkpoint_no_pca, reduce_lr], # 同じコールバックを使用\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 学習履歴のプロット部分 (PCA適用なし)\n",
        "plt.figure(figsize=(7, 5))\n",
        "\n",
        "plt.plot(lstm_history_no_pca.history['loss'], label='Training Loss')\n",
        "plt.plot(lstm_history_no_pca.history['val_loss'], label='Validation Loss')\n",
        "plt.title('LSTM (No PCA) - Loss (MSE)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('lstm_training_history_loss_no_pca.png') # ファイル名を変更\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WR7zqgCrY_ZY",
        "outputId": "8c421e0b-4dca-4710-9e10-867611fb78d5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- LSTMモデル (PCA適用なし) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m24,320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m128,065\u001b[0m (500.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,065</span> (500.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m127,681\u001b[0m (498.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">127,681</span> (498.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\n",
            "--- LSTMモデル学習開始 (PCA適用なし) ---\n",
            "Epoch 1/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.3131\n",
            "Epoch 1: val_loss improved from inf to 0.01832, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 85ms/step - loss: 0.3121 - val_loss: 0.0183 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0362\n",
            "Epoch 2: val_loss improved from 0.01832 to 0.00871, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - loss: 0.0362 - val_loss: 0.0087 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0154\n",
            "Epoch 3: val_loss improved from 0.00871 to 0.00584, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - loss: 0.0153 - val_loss: 0.0058 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0104\n",
            "Epoch 4: val_loss improved from 0.00584 to 0.00384, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - loss: 0.0104 - val_loss: 0.0038 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0087\n",
            "Epoch 5: val_loss did not improve from 0.00384\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 84ms/step - loss: 0.0087 - val_loss: 0.0043 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0074\n",
            "Epoch 6: val_loss improved from 0.00384 to 0.00280, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - loss: 0.0074 - val_loss: 0.0028 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0067\n",
            "Epoch 7: val_loss did not improve from 0.00280\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.0067 - val_loss: 0.0029 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0063\n",
            "Epoch 8: val_loss improved from 0.00280 to 0.00244, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 85ms/step - loss: 0.0063 - val_loss: 0.0024 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0059\n",
            "Epoch 9: val_loss improved from 0.00244 to 0.00206, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 88ms/step - loss: 0.0059 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0053\n",
            "Epoch 10: val_loss improved from 0.00206 to 0.00188, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - loss: 0.0053 - val_loss: 0.0019 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0054\n",
            "Epoch 11: val_loss did not improve from 0.00188\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - loss: 0.0054 - val_loss: 0.0036 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0051\n",
            "Epoch 12: val_loss improved from 0.00188 to 0.00155, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 88ms/step - loss: 0.0051 - val_loss: 0.0016 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0050\n",
            "Epoch 13: val_loss improved from 0.00155 to 0.00142, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 83ms/step - loss: 0.0050 - val_loss: 0.0014 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0044\n",
            "Epoch 14: val_loss improved from 0.00142 to 0.00128, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.0044 - val_loss: 0.0013 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0041\n",
            "Epoch 15: val_loss did not improve from 0.00128\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - loss: 0.0041 - val_loss: 0.0030 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0041\n",
            "Epoch 16: val_loss did not improve from 0.00128\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 81ms/step - loss: 0.0041 - val_loss: 0.0020 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0035\n",
            "Epoch 17: val_loss did not improve from 0.00128\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 84ms/step - loss: 0.0035 - val_loss: 0.0015 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0032\n",
            "Epoch 18: val_loss improved from 0.00128 to 0.00124, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 88ms/step - loss: 0.0032 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0031\n",
            "Epoch 19: val_loss did not improve from 0.00124\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 91ms/step - loss: 0.0031 - val_loss: 0.0013 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0025\n",
            "Epoch 20: val_loss improved from 0.00124 to 0.00124, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 83ms/step - loss: 0.0025 - val_loss: 0.0012 - learning_rate: 2.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0024\n",
            "Epoch 21: val_loss improved from 0.00124 to 0.00116, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 86ms/step - loss: 0.0024 - val_loss: 0.0012 - learning_rate: 2.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0023\n",
            "Epoch 22: val_loss did not improve from 0.00116\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - loss: 0.0023 - val_loss: 0.0012 - learning_rate: 2.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0022\n",
            "Epoch 23: val_loss improved from 0.00116 to 0.00111, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - loss: 0.0022 - val_loss: 0.0011 - learning_rate: 2.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0023\n",
            "Epoch 24: val_loss did not improve from 0.00111\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 86ms/step - loss: 0.0023 - val_loss: 0.0011 - learning_rate: 2.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0023\n",
            "Epoch 25: val_loss improved from 0.00111 to 0.00105, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.0023 - val_loss: 0.0011 - learning_rate: 2.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0021\n",
            "Epoch 26: val_loss improved from 0.00105 to 0.00101, saving model to /content/drive/MyDrive/ML/Signate_1634/lstm_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - loss: 0.0021 - val_loss: 0.0010 - learning_rate: 2.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0021\n",
            "Epoch 27: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - loss: 0.0021 - val_loss: 0.0011 - learning_rate: 2.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0021\n",
            "Epoch 28: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - loss: 0.0021 - val_loss: 0.0012 - learning_rate: 2.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0020\n",
            "Epoch 29: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 83ms/step - loss: 0.0020 - val_loss: 0.0012 - learning_rate: 2.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0020\n",
            "Epoch 30: val_loss did not improve from 0.00101\n",
            "\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - loss: 0.0020 - val_loss: 0.0010 - learning_rate: 2.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0020\n",
            "Epoch 31: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 0.0020 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0019\n",
            "Epoch 32: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 84ms/step - loss: 0.0019 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0018\n",
            "Epoch 33: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 81ms/step - loss: 0.0018 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0019\n",
            "Epoch 34: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 82ms/step - loss: 0.0019 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0018\n",
            "Epoch 35: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 84ms/step - loss: 0.0018 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0018\n",
            "Epoch 36: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 86ms/step - loss: 0.0018 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0017\n",
            "Epoch 37: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 84ms/step - loss: 0.0017 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0017\n",
            "Epoch 38: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 84ms/step - loss: 0.0017 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0017\n",
            "Epoch 39: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 0.0017 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0017\n",
            "Epoch 40: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - loss: 0.0017 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0016\n",
            "Epoch 41: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 83ms/step - loss: 0.0016 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 41: early stopping\n",
            "Restoring model weights from the end of the best epoch: 26.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU モデル（PCA適用）"
      ],
      "metadata": {
        "id": "PHNk3HR6R9K4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_gru_model(seq_length, n_features):\n",
        "    model = Sequential([\n",
        "        GRU(64, return_sequences=True, input_shape=(seq_length, n_features)),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        GRU(128, return_sequences=False),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "    return model\n",
        "\n",
        "# GRUモデルの構築と学習 (PCA適用データ)\n",
        "gru_model_pca = build_gru_model(seq_length, X_train_seq_pca.shape[2])\n",
        "print(\"\\n--- GRUモデル (PCA適用) ---\")\n",
        "print(gru_model_pca.summary())\n",
        "\n",
        "checkpoint_gru_pca = ModelCheckpoint(\n",
        "    data_path + 'gru_model_pca.h5', # ファイル名を変更して区別\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "print(\"\\n--- GRUモデル学習開始 (PCA適用) ---\")\n",
        "gru_history_pca = gru_model_pca.fit(\n",
        "    X_train_seq_pca, y_train_seq_pca,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val_seq_pca, y_val_seq_pca),\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor='val_loss', patience=15, verbose=1, restore_best_weights=True),\n",
        "        checkpoint_gru_pca,\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001, verbose=1)\n",
        "    ],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# GRU 学習履歴のプロット部分 (PCA適用)\n",
        "plt.figure(figsize=(7, 5))\n",
        "\n",
        "plt.plot(gru_history_pca.history['loss'], label='Training Loss')\n",
        "plt.plot(gru_history_pca.history['val_loss'], label='Validation Loss')\n",
        "plt.title('GRU (PCA) - Loss (MSE)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('gru_training_history_loss_pca.png') # ファイル名を変更\n",
        "plt.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CahFKpwiR96t",
        "outputId": "55466360-c16a-406b-884a-2093ec53754d",
        "collapsed": true
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- GRUモデル (PCA適用) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m15,552\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m74,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,552</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m94,977\u001b[0m (371.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">94,977</span> (371.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m94,593\u001b[0m (369.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">94,593</span> (369.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\n",
            "--- GRUモデル学習開始 (PCA適用) ---\n",
            "Epoch 1/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.4686\n",
            "Epoch 1: val_loss improved from inf to 0.01087, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 86ms/step - loss: 0.4671 - val_loss: 0.0109 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0353\n",
            "Epoch 2: val_loss improved from 0.01087 to 0.00671, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.0352 - val_loss: 0.0067 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0158\n",
            "Epoch 3: val_loss improved from 0.00671 to 0.00652, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - loss: 0.0158 - val_loss: 0.0065 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0115\n",
            "Epoch 4: val_loss improved from 0.00652 to 0.00393, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - loss: 0.0115 - val_loss: 0.0039 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0094\n",
            "Epoch 5: val_loss improved from 0.00393 to 0.00378, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 94ms/step - loss: 0.0094 - val_loss: 0.0038 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0086\n",
            "Epoch 6: val_loss improved from 0.00378 to 0.00265, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 87ms/step - loss: 0.0086 - val_loss: 0.0027 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0077\n",
            "Epoch 7: val_loss improved from 0.00265 to 0.00235, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - loss: 0.0077 - val_loss: 0.0024 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0073\n",
            "Epoch 8: val_loss improved from 0.00235 to 0.00190, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - loss: 0.0073 - val_loss: 0.0019 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0069\n",
            "Epoch 9: val_loss improved from 0.00190 to 0.00176, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.0069 - val_loss: 0.0018 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0063\n",
            "Epoch 10: val_loss did not improve from 0.00176\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - loss: 0.0063 - val_loss: 0.0018 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0061\n",
            "Epoch 11: val_loss did not improve from 0.00176\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - loss: 0.0061 - val_loss: 0.0019 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0059\n",
            "Epoch 12: val_loss improved from 0.00176 to 0.00161, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - loss: 0.0059 - val_loss: 0.0016 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0065\n",
            "Epoch 13: val_loss improved from 0.00161 to 0.00131, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 89ms/step - loss: 0.0065 - val_loss: 0.0013 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0060\n",
            "Epoch 14: val_loss did not improve from 0.00131\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 84ms/step - loss: 0.0060 - val_loss: 0.0015 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0058\n",
            "Epoch 15: val_loss did not improve from 0.00131\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 88ms/step - loss: 0.0058 - val_loss: 0.0024 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0075\n",
            "Epoch 16: val_loss did not improve from 0.00131\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 84ms/step - loss: 0.0075 - val_loss: 0.0021 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0058\n",
            "Epoch 17: val_loss did not improve from 0.00131\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 83ms/step - loss: 0.0058 - val_loss: 0.0014 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0045\n",
            "Epoch 18: val_loss did not improve from 0.00131\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 86ms/step - loss: 0.0045 - val_loss: 0.0014 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0039\n",
            "Epoch 19: val_loss improved from 0.00131 to 0.00104, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - loss: 0.0039 - val_loss: 0.0010 - learning_rate: 2.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0037\n",
            "Epoch 20: val_loss did not improve from 0.00104\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 83ms/step - loss: 0.0037 - val_loss: 0.0011 - learning_rate: 2.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0038\n",
            "Epoch 21: val_loss did not improve from 0.00104\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 0.0038 - val_loss: 0.0011 - learning_rate: 2.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0037\n",
            "Epoch 22: val_loss did not improve from 0.00104\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 84ms/step - loss: 0.0037 - val_loss: 0.0011 - learning_rate: 2.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0036\n",
            "Epoch 23: val_loss did not improve from 0.00104\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 82ms/step - loss: 0.0036 - val_loss: 0.0011 - learning_rate: 2.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0036\n",
            "Epoch 24: val_loss improved from 0.00104 to 0.00104, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 88ms/step - loss: 0.0036 - val_loss: 0.0010 - learning_rate: 2.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0034\n",
            "Epoch 25: val_loss did not improve from 0.00104\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - loss: 0.0034 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0034\n",
            "Epoch 26: val_loss improved from 0.00104 to 0.00103, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 112ms/step - loss: 0.0034 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0033\n",
            "Epoch 27: val_loss improved from 0.00103 to 0.00101, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 87ms/step - loss: 0.0033 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0033\n",
            "Epoch 28: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - loss: 0.0033 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0033\n",
            "Epoch 29: val_loss improved from 0.00101 to 0.00101, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 86ms/step - loss: 0.0033 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0032\n",
            "Epoch 30: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 89ms/step - loss: 0.0032 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0032\n",
            "Epoch 31: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 83ms/step - loss: 0.0032 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0033\n",
            "Epoch 32: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 81ms/step - loss: 0.0033 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0033\n",
            "Epoch 33: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 85ms/step - loss: 0.0033 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0031\n",
            "Epoch 34: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 90ms/step - loss: 0.0031 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0032\n",
            "Epoch 35: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 82ms/step - loss: 0.0032 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0032\n",
            "Epoch 36: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 82ms/step - loss: 0.0032 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0032\n",
            "Epoch 37: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 86ms/step - loss: 0.0032 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0032\n",
            "Epoch 38: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 83ms/step - loss: 0.0032 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0032\n",
            "Epoch 39: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 0.0032 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0031\n",
            "Epoch 40: val_loss did not improve from 0.00101\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - loss: 0.0031 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0031\n",
            "Epoch 41: val_loss improved from 0.00101 to 0.00096, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 94ms/step - loss: 0.0031 - val_loss: 9.6252e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0030\n",
            "Epoch 42: val_loss did not improve from 0.00096\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.0030 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0031\n",
            "Epoch 43: val_loss did not improve from 0.00096\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 84ms/step - loss: 0.0031 - val_loss: 9.7059e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0030\n",
            "Epoch 44: val_loss did not improve from 0.00096\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 84ms/step - loss: 0.0030 - val_loss: 9.9110e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0029\n",
            "Epoch 45: val_loss did not improve from 0.00096\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 0.0029 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0030\n",
            "Epoch 46: val_loss did not improve from 0.00096\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 84ms/step - loss: 0.0030 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0029\n",
            "Epoch 47: val_loss did not improve from 0.00096\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 0.0029 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0029\n",
            "Epoch 48: val_loss did not improve from 0.00096\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 93ms/step - loss: 0.0029 - val_loss: 0.0011 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0029\n",
            "Epoch 49: val_loss improved from 0.00096 to 0.00094, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 87ms/step - loss: 0.0029 - val_loss: 9.3568e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0028\n",
            "Epoch 50: val_loss did not improve from 0.00094\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - loss: 0.0028 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0028\n",
            "Epoch 51: val_loss did not improve from 0.00094\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.0028 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0028\n",
            "Epoch 52: val_loss did not improve from 0.00094\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 84ms/step - loss: 0.0028 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0028\n",
            "Epoch 53: val_loss did not improve from 0.00094\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 88ms/step - loss: 0.0028 - val_loss: 9.7995e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0027\n",
            "Epoch 54: val_loss did not improve from 0.00094\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - loss: 0.0027 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0028\n",
            "Epoch 55: val_loss did not improve from 0.00094\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 89ms/step - loss: 0.0028 - val_loss: 9.4890e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0027\n",
            "Epoch 56: val_loss did not improve from 0.00094\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 83ms/step - loss: 0.0027 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0028\n",
            "Epoch 57: val_loss did not improve from 0.00094\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 82ms/step - loss: 0.0028 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0028\n",
            "Epoch 58: val_loss did not improve from 0.00094\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 82ms/step - loss: 0.0028 - val_loss: 9.3795e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0027\n",
            "Epoch 59: val_loss did not improve from 0.00094\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 87ms/step - loss: 0.0027 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0027\n",
            "Epoch 60: val_loss improved from 0.00094 to 0.00089, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - loss: 0.0027 - val_loss: 8.8717e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0027\n",
            "Epoch 61: val_loss did not improve from 0.00089\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 86ms/step - loss: 0.0027 - val_loss: 9.1730e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0027\n",
            "Epoch 62: val_loss did not improve from 0.00089\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 85ms/step - loss: 0.0027 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0027\n",
            "Epoch 63: val_loss did not improve from 0.00089\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 93ms/step - loss: 0.0027 - val_loss: 9.4188e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0027\n",
            "Epoch 64: val_loss did not improve from 0.00089\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 81ms/step - loss: 0.0027 - val_loss: 9.5686e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0027\n",
            "Epoch 65: val_loss did not improve from 0.00089\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 84ms/step - loss: 0.0027 - val_loss: 9.9519e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0027\n",
            "Epoch 66: val_loss did not improve from 0.00089\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 84ms/step - loss: 0.0027 - val_loss: 9.5646e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0027\n",
            "Epoch 67: val_loss did not improve from 0.00089\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 85ms/step - loss: 0.0027 - val_loss: 9.6787e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0026\n",
            "Epoch 68: val_loss did not improve from 0.00089\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 88ms/step - loss: 0.0026 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0026\n",
            "Epoch 69: val_loss did not improve from 0.00089\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 85ms/step - loss: 0.0026 - val_loss: 9.2881e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0026\n",
            "Epoch 70: val_loss did not improve from 0.00089\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 84ms/step - loss: 0.0026 - val_loss: 9.9592e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0026\n",
            "Epoch 71: val_loss did not improve from 0.00089\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 84ms/step - loss: 0.0026 - val_loss: 9.3430e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0026\n",
            "Epoch 72: val_loss did not improve from 0.00089\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 86ms/step - loss: 0.0026 - val_loss: 9.3526e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0026\n",
            "Epoch 73: val_loss did not improve from 0.00089\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 82ms/step - loss: 0.0026 - val_loss: 9.3490e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0025\n",
            "Epoch 74: val_loss did not improve from 0.00089\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 88ms/step - loss: 0.0025 - val_loss: 9.5483e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0025\n",
            "Epoch 75: val_loss did not improve from 0.00089\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 85ms/step - loss: 0.0025 - val_loss: 0.0010 - learning_rate: 1.0000e-04\n",
            "Epoch 75: early stopping\n",
            "Restoring model weights from the end of the best epoch: 60.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU モデル（PCA適用なし"
      ],
      "metadata": {
        "id": "bvC8ZZ8WZJua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRUモデルの構築と学習 (PCA適用なしデータ)\n",
        "gru_model_no_pca = build_gru_model(seq_length, X_train_seq_no_pca.shape[2])\n",
        "print(\"\\n--- GRUモデル (PCA適用なし) ---\")\n",
        "print(gru_model_no_pca.summary())\n",
        "\n",
        "checkpoint_gru_no_pca = ModelCheckpoint(\n",
        "    data_path + 'gru_model_no_pca.h5', # ファイル名を変更して区別\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\n--- GRUモデル学習開始 (PCA適用なし) ---\")\n",
        "gru_history_no_pca = gru_model_no_pca.fit(\n",
        "    X_train_seq_no_pca, y_train_seq_no_pca,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val_seq_no_pca, y_val_seq_no_pca),\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor='val_loss', patience=15, verbose=1, restore_best_weights=True),\n",
        "        checkpoint_gru_no_pca,\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001, verbose=1)\n",
        "    ],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# GRU 学習履歴のプロット部分 (PCA適用なし)\n",
        "plt.figure(figsize=(7, 5))\n",
        "\n",
        "plt.plot(gru_history_no_pca.history['loss'], label='Training Loss')\n",
        "plt.plot(gru_history_no_pca.history['val_loss'], label='Validation Loss')\n",
        "plt.title('GRU (No PCA) - Loss (MSE)')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('gru_training_history_loss_no_pca.png') # ファイル名を変更\n",
        "plt.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "bXJ5GbLdZLz8",
        "outputId": "1b96c312-49b0-4203-c921-ca78dad85f08"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- GRUモデル (PCA適用なし) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m18,432\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_5 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m74,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m97,857\u001b[0m (382.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,857</span> (382.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m97,473\u001b[0m (380.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,473</span> (380.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\n",
            "--- GRUモデル学習開始 (PCA適用なし) ---\n",
            "Epoch 1/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.4058\n",
            "Epoch 1: val_loss improved from inf to 0.02155, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 88ms/step - loss: 0.4045 - val_loss: 0.0215 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0445\n",
            "Epoch 2: val_loss improved from 0.02155 to 0.01172, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 96ms/step - loss: 0.0444 - val_loss: 0.0117 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0158\n",
            "Epoch 3: val_loss improved from 0.01172 to 0.00611, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 89ms/step - loss: 0.0158 - val_loss: 0.0061 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0110\n",
            "Epoch 4: val_loss improved from 0.00611 to 0.00349, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 89ms/step - loss: 0.0110 - val_loss: 0.0035 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0091\n",
            "Epoch 5: val_loss improved from 0.00349 to 0.00282, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 89ms/step - loss: 0.0091 - val_loss: 0.0028 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0076\n",
            "Epoch 6: val_loss improved from 0.00282 to 0.00240, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 89ms/step - loss: 0.0076 - val_loss: 0.0024 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0068\n",
            "Epoch 7: val_loss did not improve from 0.00240\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - loss: 0.0068 - val_loss: 0.0035 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0063\n",
            "Epoch 8: val_loss did not improve from 0.00240\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - loss: 0.0063 - val_loss: 0.0032 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0058\n",
            "Epoch 9: val_loss improved from 0.00240 to 0.00164, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 92ms/step - loss: 0.0058 - val_loss: 0.0016 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0053\n",
            "Epoch 10: val_loss did not improve from 0.00164\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 86ms/step - loss: 0.0053 - val_loss: 0.0027 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0051\n",
            "Epoch 11: val_loss improved from 0.00164 to 0.00136, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 89ms/step - loss: 0.0051 - val_loss: 0.0014 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0048\n",
            "Epoch 12: val_loss improved from 0.00136 to 0.00122, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 90ms/step - loss: 0.0048 - val_loss: 0.0012 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0044\n",
            "Epoch 13: val_loss did not improve from 0.00122\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 88ms/step - loss: 0.0044 - val_loss: 0.0017 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0042\n",
            "Epoch 14: val_loss improved from 0.00122 to 0.00088, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.0042 - val_loss: 8.8068e-04 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0043\n",
            "Epoch 15: val_loss did not improve from 0.00088\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - loss: 0.0043 - val_loss: 0.0018 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0037\n",
            "Epoch 16: val_loss did not improve from 0.00088\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 95ms/step - loss: 0.0037 - val_loss: 9.7364e-04 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0034\n",
            "Epoch 17: val_loss did not improve from 0.00088\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 87ms/step - loss: 0.0034 - val_loss: 0.0020 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0038\n",
            "Epoch 18: val_loss did not improve from 0.00088\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.0038 - val_loss: 0.0020 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0034\n",
            "Epoch 19: val_loss did not improve from 0.00088\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - loss: 0.0034 - val_loss: 0.0013 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0035\n",
            "Epoch 20: val_loss did not improve from 0.00088\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 89ms/step - loss: 0.0035 - val_loss: 9.9288e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0030\n",
            "Epoch 21: val_loss did not improve from 0.00088\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 87ms/step - loss: 0.0030 - val_loss: 9.1198e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0029\n",
            "Epoch 22: val_loss improved from 0.00088 to 0.00075, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - loss: 0.0029 - val_loss: 7.5210e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0028\n",
            "Epoch 23: val_loss did not improve from 0.00075\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 96ms/step - loss: 0.0028 - val_loss: 8.4906e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0027\n",
            "Epoch 24: val_loss did not improve from 0.00075\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 89ms/step - loss: 0.0027 - val_loss: 8.2673e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0027\n",
            "Epoch 25: val_loss improved from 0.00075 to 0.00073, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - loss: 0.0027 - val_loss: 7.3039e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0027\n",
            "Epoch 26: val_loss improved from 0.00073 to 0.00070, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - loss: 0.0027 - val_loss: 7.0219e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0026\n",
            "Epoch 27: val_loss improved from 0.00070 to 0.00066, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 91ms/step - loss: 0.0026 - val_loss: 6.6228e-04 - learning_rate: 2.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0025\n",
            "Epoch 28: val_loss improved from 0.00066 to 0.00066, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 90ms/step - loss: 0.0025 - val_loss: 6.5608e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0024\n",
            "Epoch 29: val_loss improved from 0.00066 to 0.00066, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 90ms/step - loss: 0.0024 - val_loss: 6.5533e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0024\n",
            "Epoch 30: val_loss did not improve from 0.00066\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 89ms/step - loss: 0.0024 - val_loss: 6.5681e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0023\n",
            "Epoch 31: val_loss did not improve from 0.00066\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 90ms/step - loss: 0.0023 - val_loss: 7.0889e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0023\n",
            "Epoch 32: val_loss did not improve from 0.00066\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 89ms/step - loss: 0.0023 - val_loss: 7.0839e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0023\n",
            "Epoch 33: val_loss did not improve from 0.00066\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 90ms/step - loss: 0.0023 - val_loss: 6.8801e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0023\n",
            "Epoch 34: val_loss did not improve from 0.00066\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 89ms/step - loss: 0.0023 - val_loss: 7.1070e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0023\n",
            "Epoch 35: val_loss did not improve from 0.00066\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 90ms/step - loss: 0.0023 - val_loss: 7.1222e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0023\n",
            "Epoch 36: val_loss did not improve from 0.00066\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 90ms/step - loss: 0.0023 - val_loss: 6.6407e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0023\n",
            "Epoch 37: val_loss improved from 0.00066 to 0.00065, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 88ms/step - loss: 0.0023 - val_loss: 6.4997e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0022\n",
            "Epoch 38: val_loss did not improve from 0.00065\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 86ms/step - loss: 0.0022 - val_loss: 7.1243e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0022\n",
            "Epoch 39: val_loss did not improve from 0.00065\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 89ms/step - loss: 0.0022 - val_loss: 7.2385e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0022\n",
            "Epoch 40: val_loss did not improve from 0.00065\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 90ms/step - loss: 0.0022 - val_loss: 6.7792e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0022\n",
            "Epoch 41: val_loss did not improve from 0.00065\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 87ms/step - loss: 0.0022 - val_loss: 6.6340e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0022\n",
            "Epoch 42: val_loss improved from 0.00065 to 0.00064, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - loss: 0.0022 - val_loss: 6.4328e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0022\n",
            "Epoch 43: val_loss improved from 0.00064 to 0.00064, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 92ms/step - loss: 0.0022 - val_loss: 6.4022e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0022\n",
            "Epoch 44: val_loss did not improve from 0.00064\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 88ms/step - loss: 0.0022 - val_loss: 6.7754e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0021\n",
            "Epoch 45: val_loss did not improve from 0.00064\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.0021 - val_loss: 6.6767e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0021\n",
            "Epoch 46: val_loss improved from 0.00064 to 0.00063, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 89ms/step - loss: 0.0021 - val_loss: 6.3308e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0022\n",
            "Epoch 47: val_loss did not improve from 0.00063\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 87ms/step - loss: 0.0022 - val_loss: 6.6008e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0022\n",
            "Epoch 48: val_loss did not improve from 0.00063\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.0022 - val_loss: 6.5842e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0022\n",
            "Epoch 49: val_loss did not improve from 0.00063\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.0022 - val_loss: 6.9490e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0021\n",
            "Epoch 50: val_loss did not improve from 0.00063\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 87ms/step - loss: 0.0021 - val_loss: 7.1722e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0021\n",
            "Epoch 51: val_loss did not improve from 0.00063\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 101ms/step - loss: 0.0021 - val_loss: 6.4556e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0021\n",
            "Epoch 52: val_loss did not improve from 0.00063\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 89ms/step - loss: 0.0021 - val_loss: 6.6207e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0022\n",
            "Epoch 53: val_loss did not improve from 0.00063\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 87ms/step - loss: 0.0022 - val_loss: 6.4328e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0021\n",
            "Epoch 54: val_loss improved from 0.00063 to 0.00063, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - loss: 0.0021 - val_loss: 6.2835e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0021\n",
            "Epoch 55: val_loss improved from 0.00063 to 0.00062, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 91ms/step - loss: 0.0021 - val_loss: 6.2383e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0021\n",
            "Epoch 56: val_loss improved from 0.00062 to 0.00062, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 91ms/step - loss: 0.0021 - val_loss: 6.1667e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0021\n",
            "Epoch 57: val_loss did not improve from 0.00062\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 88ms/step - loss: 0.0021 - val_loss: 6.2169e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0021\n",
            "Epoch 58: val_loss did not improve from 0.00062\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 95ms/step - loss: 0.0021 - val_loss: 6.5067e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0021\n",
            "Epoch 59: val_loss did not improve from 0.00062\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 88ms/step - loss: 0.0021 - val_loss: 6.3891e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0021\n",
            "Epoch 60: val_loss improved from 0.00062 to 0.00062, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - loss: 0.0021 - val_loss: 6.1661e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0021\n",
            "Epoch 61: val_loss did not improve from 0.00062\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - loss: 0.0021 - val_loss: 6.2766e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0021\n",
            "Epoch 62: val_loss did not improve from 0.00062\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - loss: 0.0021 - val_loss: 6.4259e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0021\n",
            "Epoch 63: val_loss did not improve from 0.00062\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 89ms/step - loss: 0.0021 - val_loss: 6.5343e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0021\n",
            "Epoch 64: val_loss did not improve from 0.00062\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - loss: 0.0021 - val_loss: 6.9628e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0020\n",
            "Epoch 65: val_loss did not improve from 0.00062\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 90ms/step - loss: 0.0020 - val_loss: 7.2466e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0020\n",
            "Epoch 66: val_loss did not improve from 0.00062\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 88ms/step - loss: 0.0020 - val_loss: 6.2857e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0020\n",
            "Epoch 67: val_loss improved from 0.00062 to 0.00062, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - loss: 0.0020 - val_loss: 6.1617e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0019\n",
            "Epoch 68: val_loss did not improve from 0.00062\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - loss: 0.0019 - val_loss: 6.3041e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0020\n",
            "Epoch 69: val_loss did not improve from 0.00062\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - loss: 0.0020 - val_loss: 6.2292e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0020\n",
            "Epoch 70: val_loss did not improve from 0.00062\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.0020 - val_loss: 6.3404e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0020\n",
            "Epoch 71: val_loss did not improve from 0.00062\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 89ms/step - loss: 0.0020 - val_loss: 6.2028e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0019\n",
            "Epoch 72: val_loss did not improve from 0.00062\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.0019 - val_loss: 6.2337e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0019\n",
            "Epoch 73: val_loss improved from 0.00062 to 0.00061, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 96ms/step - loss: 0.0019 - val_loss: 6.0676e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0019\n",
            "Epoch 74: val_loss did not improve from 0.00061\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 87ms/step - loss: 0.0019 - val_loss: 6.3210e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0020\n",
            "Epoch 75: val_loss improved from 0.00061 to 0.00060, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 90ms/step - loss: 0.0020 - val_loss: 6.0075e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0020\n",
            "Epoch 76: val_loss improved from 0.00060 to 0.00059, saving model to /content/drive/MyDrive/ML/Signate_1634/gru_model_no_pca.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 90ms/step - loss: 0.0020 - val_loss: 5.8528e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0019\n",
            "Epoch 77: val_loss did not improve from 0.00059\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - loss: 0.0019 - val_loss: 5.8846e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0019\n",
            "Epoch 78: val_loss did not improve from 0.00059\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 89ms/step - loss: 0.0019 - val_loss: 5.9003e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0019\n",
            "Epoch 79: val_loss did not improve from 0.00059\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.0019 - val_loss: 5.9407e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0019\n",
            "Epoch 80: val_loss did not improve from 0.00059\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - loss: 0.0019 - val_loss: 5.9854e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0019\n",
            "Epoch 81: val_loss did not improve from 0.00059\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 94ms/step - loss: 0.0019 - val_loss: 5.8807e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0019\n",
            "Epoch 82: val_loss did not improve from 0.00059\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 88ms/step - loss: 0.0019 - val_loss: 6.4749e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0020\n",
            "Epoch 83: val_loss did not improve from 0.00059\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - loss: 0.0020 - val_loss: 6.1052e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0019\n",
            "Epoch 84: val_loss did not improve from 0.00059\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 89ms/step - loss: 0.0019 - val_loss: 6.3156e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0019\n",
            "Epoch 85: val_loss did not improve from 0.00059\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 88ms/step - loss: 0.0019 - val_loss: 6.0398e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0019\n",
            "Epoch 86: val_loss did not improve from 0.00059\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 88ms/step - loss: 0.0019 - val_loss: 6.0694e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0019\n",
            "Epoch 87: val_loss did not improve from 0.00059\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 89ms/step - loss: 0.0019 - val_loss: 6.0345e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0019\n",
            "Epoch 88: val_loss did not improve from 0.00059\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 95ms/step - loss: 0.0019 - val_loss: 6.1443e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0019\n",
            "Epoch 89: val_loss did not improve from 0.00059\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.0019 - val_loss: 6.1772e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0019\n",
            "Epoch 90: val_loss did not improve from 0.00059\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 88ms/step - loss: 0.0019 - val_loss: 6.0683e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m328/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0019\n",
            "Epoch 91: val_loss did not improve from 0.00059\n",
            "\u001b[1m329/329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 90ms/step - loss: 0.0019 - val_loss: 6.0541e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 91: early stopping\n",
            "Restoring model weights from the end of the best epoch: 76.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデル評価と結果比較"
      ],
      "metadata": {
        "id": "coqyhCKXZW6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test_seq, y_test_seq_scaled, y_scaler, title): # y_test_scaledをy_test_seq_scaledに変更\n",
        "    \"\"\"\n",
        "    モデルを評価し、MAEとRMSEを計算、結果をプロットする\n",
        "    \"\"\"\n",
        "    # 予測\n",
        "    scaled_predictions = model.predict(X_test_seq)\n",
        "\n",
        "    # スケーリングを元に戻す\n",
        "    # MAE/RMSE計算とプロットのために、y_test_seq_scaledを使用する\n",
        "    y_test_orig = y_scaler.inverse_transform(y_test_seq_scaled.reshape(-1, 1)).flatten() # y_test_scaledをy_test_seq_scaledに変更\n",
        "    y_pred_orig = y_scaler.inverse_transform(scaled_predictions).flatten()\n",
        "\n",
        "    # 評価指標\n",
        "    mae = mean_absolute_error(y_test_orig, y_pred_orig)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_orig, y_pred_orig))\n",
        "\n",
        "    print(f\"\\n--- {title} 評価結果 ---\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "\n",
        "    # 予測結果と実測値の比較プロット\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    # プロットの実測値もy_test_seq_scaledから計算する\n",
        "    plt.plot(y_scaler.inverse_transform(y_test_seq_scaled.reshape(-1, 1)).flatten(), label='Actual Price') # y_test_scaledをy_test_seq_scaledに変更\n",
        "    plt.plot(y_pred_orig, label='Predicted Price')\n",
        "    plt.title(f'{title} - 実測値 vs 予測値')\n",
        "    plt.xlabel('Time Step')\n",
        "    plt.ylabel('Price')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'{title.replace(\" \", \"_\")}_prediction_vs_actual.png')\n",
        "    plt.close()\n",
        "\n",
        "    return mae, rmse\n",
        "\n",
        "# LSTM (PCA適用) の評価\n",
        "# y_test_scaled_pca を y_test_seq_pca に変更して evaluate_model を呼び出す\n",
        "lstm_pca_mae, lstm_pca_rmse = evaluate_model(lstm_model_pca, X_test_seq_pca, y_test_seq_pca, y_scaler, \"LSTM (PCA)\")\n",
        "\n",
        "# LSTM (PCA適用なし) の評価\n",
        "# y_test_scaled_no_pca を y_test_seq_no_pca に変更して evaluate_model を呼び出す\n",
        "lstm_no_pca_mae, lstm_no_pca_rmse = evaluate_model(lstm_model_no_pca, X_test_seq_no_pca, y_test_seq_no_pca, y_scaler, \"LSTM (No PCA)\")\n",
        "\n",
        "# GRU (PCA適用) の評価\n",
        "# y_test_scaled_pca を y_test_seq_pca に変更して evaluate_model を呼び出す\n",
        "gru_pca_mae, gru_pca_rmse = evaluate_model(gru_model_pca, X_test_seq_pca, y_test_seq_pca, y_scaler, \"GRU (PCA)\")\n",
        "\n",
        "# GRU (PCA適用なし) の評価\n",
        "# y_test_scaled_no_pca を y_test_seq_no_pca に変更して evaluate_model を呼び出す\n",
        "gru_no_pca_mae, gru_no_pca_rmse = evaluate_model(gru_model_no_pca, X_test_seq_no_pca, y_test_seq_no_pca, y_scaler, \"GRU (No PCA)\")\n",
        "\n",
        "# 結果の比較\n",
        "print(\"\\n--- モデル比較結果 ---\")\n",
        "print(f\"LSTM (PCA):     MAE={lstm_pca_mae:.4f}, RMSE={lstm_pca_rmse:.4f}\")\n",
        "print(f\"LSTM (No PCA):  MAE={lstm_no_pca_mae:.4f}, RMSE={lstm_no_pca_rmse:.4f}\")\n",
        "print(f\"GRU (PCA):      MAE={gru_pca_mae:.4f}, RMSE={gru_pca_rmse:.4f}\")\n",
        "print(f\"GRU (No PCA):   MAE={gru_no_pca_mae:.4f}, RMSE={gru_no_pca_rmse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99xd15M7ZXeo",
        "outputId": "a8ee5f86-799e-43ac-c75d-41f156fe601a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step\n",
            "\n",
            "--- LSTM (PCA) 評価結果 ---\n",
            "MAE: 4.4801\n",
            "RMSE: 6.2004\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step\n",
            "\n",
            "--- LSTM (No PCA) 評価結果 ---\n",
            "MAE: 3.9132\n",
            "RMSE: 5.3689\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step\n",
            "\n",
            "--- GRU (PCA) 評価結果 ---\n",
            "MAE: 3.7873\n",
            "RMSE: 5.1848\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step\n",
            "\n",
            "--- GRU (No PCA) 評価結果 ---\n",
            "MAE: 3.0780\n",
            "RMSE: 4.3365\n",
            "\n",
            "--- モデル比較結果 ---\n",
            "LSTM (PCA):     MAE=4.4801, RMSE=6.2004\n",
            "LSTM (No PCA):  MAE=3.9132, RMSE=5.3689\n",
            "GRU (PCA):      MAE=3.7873, RMSE=5.1848\n",
            "GRU (No PCA):   MAE=3.0780, RMSE=4.3365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 特徴量重要度の分析"
      ],
      "metadata": {
        "id": "Rh4RQNarSGbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴量重要度の可視化（SelectKBestの結果）\n",
        "def plot_feature_importance(X, y, top_n=20):\n",
        "    # 数値型以外のカラムを削除\n",
        "    X_numeric = X.select_dtypes(include=np.number)\n",
        "\n",
        "    selector = SelectKBest(score_func=f_regression, k='all')\n",
        "    # 数値型カラムのみを使ってfitを行う\n",
        "    selector.fit(X_numeric, y)\n",
        "\n",
        "    # 特徴量のスコアを取得\n",
        "    feature_scores = pd.DataFrame({\n",
        "        'Feature': X_numeric.columns, # X_numericのカラム名を使用\n",
        "        'Score': selector.scores_\n",
        "    })\n",
        "\n",
        "    # スコア順にソート\n",
        "    feature_scores = feature_scores.sort_values(by='Score', ascending=False)\n",
        "\n",
        "    # 上位n個の特徴量をプロット\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(x='Score', y='Feature', data=feature_scores.head(top_n))\n",
        "    plt.title(f'上位{top_n}個の重要な特徴量')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('feature_importance.png')\n",
        "    plt.close()\n",
        "\n",
        "    return feature_scores\n",
        "\n",
        "# 特徴量重要度のプロット\n",
        "# XがDataFrameであり、数値型以外のカラムを含んでいる可能性があるため、関数内で処理します\n",
        "importance = plot_feature_importance(X_featured, y_featured, top_n=20)\n",
        "print(\"\\n上位20の重要な特徴量:\")\n",
        "print(importance.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keF1FeENSIOG",
        "outputId": "b7859e83-335d-4e39-8ef7-4805fd447c1b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "上位20の重要な特徴量:\n",
            "                                        Feature          Score\n",
            "84                           price_actual_lag_1  362397.475584\n",
            "85                          price_actual_lag_24   55455.839343\n",
            "88                 price_actual_rolling_mean_24   51125.358795\n",
            "87                         price_actual_lag_168   46096.371945\n",
            "86                          price_actual_lag_48   29553.563560\n",
            "3                   generation_fossil_hard_coal    7410.283193\n",
            "1          generation_fossil_brown_coal/lignite    4315.279936\n",
            "14                            total_load_actual    4191.590208\n",
            "2                         generation_fossil_gas    4151.326152\n",
            "5   generation_hydro_pumped_storage_consumption    2642.416186\n",
            "6    generation_hydro_run_of_river_and_poundage    1905.413869\n",
            "79                                      quarter    1801.790531\n",
            "4                         generation_fossil_oil    1735.021199\n",
            "75                                         hour    1639.636595\n",
            "81                                   weekofyear    1558.000176\n",
            "77                                        month    1550.580653\n",
            "80                                    dayofyear    1547.614404\n",
            "83                                   is_weekend    1542.839203\n",
            "32                            madrid_wind_speed    1515.924859\n",
            "0                            generation_biomass    1159.447579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 時系列交差検証"
      ],
      "metadata": {
        "id": "qWKVR5klSKZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 時系列交差検証\n",
        "def time_series_cv_evaluation(X, y, seq_length=24, n_splits=5):\n",
        "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "    mae_scores = []\n",
        "    rmse_scores = []\n",
        "    fold = 1\n",
        "\n",
        "    for train_index, test_index in tscv.split(X):\n",
        "        print(f\"\\n評価 fold {fold}/{n_splits}\")\n",
        "\n",
        "        # データの分割\n",
        "        X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
        "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
        "\n",
        "        # スケーリング\n",
        "        y_scaler_fold = MinMaxScaler()\n",
        "        y_train_scaled = y_scaler_fold.fit_transform(y_train_fold.reshape(-1, 1))\n",
        "        y_test_scaled = y_scaler_fold.transform(y_test_fold.reshape(-1, 1))\n",
        "\n",
        "        # シーケンスデータの作成\n",
        "        X_train_seq_fold, y_train_seq_fold = create_sequences(X_train_fold, y_train_scaled, seq_length)\n",
        "        X_test_seq_fold, y_test_seq_fold = create_sequences(X_test_fold, y_test_scaled, seq_length)\n",
        "\n",
        "        if len(X_train_seq_fold) == 0 or len(X_test_seq_fold) == 0:\n",
        "            print(\"シーケンスデータが空です\")\n",
        "            continue\n",
        "\n",
        "        # モデル構築と学習\n",
        "        model = build_lstm_model(seq_length, X_train_seq_fold.shape[2])\n",
        "\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, restore_best_weights=True)\n",
        "\n",
        "        model.fit(\n",
        "            X_train_seq_fold, y_train_seq_fold,\n",
        "            epochs=50,\n",
        "            batch_size=64,\n",
        "            validation_split=0.2,\n",
        "            callbacks=[early_stopping],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # 評価\n",
        "        y_pred_fold = model.predict(X_test_seq_fold)\n",
        "\n",
        "        # スケーリングを元に戻す\n",
        "        y_test_orig_fold = y_scaler_fold.inverse_transform(y_test_seq_fold.reshape(-1, 1)).flatten()\n",
        "        y_pred_orig_fold = y_scaler_fold.inverse_transform(y_pred_fold).flatten()\n",
        "\n",
        "        # 評価指標の計算\n",
        "        mae = mean_absolute_error(y_test_orig_fold, y_pred_orig_fold)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test_orig_fold, y_pred_orig_fold))\n",
        "\n",
        "        mae_scores.append(mae)\n",
        "        rmse_scores.append(rmse)\n",
        "\n",
        "        print(f\"Fold {fold} - MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n",
        "        fold += 1\n",
        "\n",
        "    # 結果をまとめる\n",
        "    print(\"\\n時系列交差検証の結果:\")\n",
        "    print(f\"平均 MAE: {np.mean(mae_scores):.2f} (±{np.std(mae_scores):.2f})\")\n",
        "    print(f\"平均 RMSE: {np.mean(rmse_scores):.2f} (±{np.std(rmse_scores):.2f})\")\n",
        "\n",
        "    return mae_scores, rmse_scores\n",
        "\n",
        "# 時系列交差検証の実行\n",
        "mae_cv, rmse_cv = time_series_cv_evaluation(X_pca, y_scaled, seq_length=24, n_splits=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-aWTdEJSMJA",
        "outputId": "c23bee33-1657-4127-f02d-5c26da7d0995"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "評価 fold 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step\n",
            "Fold 1 - MAE: 0.09, RMSE: 0.12\n",
            "\n",
            "評価 fold 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step\n",
            "Fold 2 - MAE: 0.08, RMSE: 0.10\n",
            "\n",
            "評価 fold 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step\n",
            "Fold 3 - MAE: 0.04, RMSE: 0.06\n",
            "\n",
            "時系列交差検証の結果:\n",
            "平均 MAE: 0.07 (±0.02)\n",
            "平均 RMSE: 0.09 (±0.03)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## モデルとパイプラインの保存"
      ],
      "metadata": {
        "id": "ckd-tuS5SPPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# モデル保存のためのパイプラインを作成\n",
        "pipeline = {\n",
        "    'pca': pca,\n",
        "    'pca_scaler': pca_scaler,\n",
        "    'y_scaler': y_scaler,\n",
        "    'selected_features': X_selected.columns.tolist(),\n",
        "    'seq_length': seq_length\n",
        "}\n",
        "\n",
        "# パイプラインを保存\n",
        "pipeline_save_path = data_path + 'price_prediction_pipeline.pkl'\n",
        "with open(pipeline_save_path, 'wb') as f:\n",
        "    pickle.dump(pipeline, f)\n",
        "\n",
        "# 予測パイプラインの使用例\n",
        "def predict_price(model, new_data, pipeline):\n",
        "    \"\"\"\n",
        "    新しいデータで価格を予測する\n",
        "\n",
        "    Parameters:\n",
        "    - model: 訓練済みモデル\n",
        "    - new_data: 予測したいデータ（必要な特徴量を含むDataFrame）\n",
        "    - pipeline: 前処理パイプライン\n",
        "\n",
        "    Returns:\n",
        "    - predicted_price: 予測された価格\n",
        "    \"\"\"\n",
        "    # パイプラインから必要な要素を取得\n",
        "    pca = pipeline['pca']\n",
        "    pca_scaler = pipeline['pca_scaler']\n",
        "    y_scaler = pipeline['y_scaler']\n",
        "    selected_features = pipeline['selected_features']\n",
        "    seq_length = pipeline['seq_length']\n",
        "\n",
        "    # 必要な特徴量のみを選択\n",
        "    selected_data = new_data[selected_features]\n",
        "\n",
        "    # スケーリングとPCA変換\n",
        "    scaled_data = pca_scaler.transform(selected_data)\n",
        "    pca_data = pca.transform(scaled_data)\n",
        "\n",
        "    # シーケンスデータの作成（最新のseq_length分のデータを使用）\n",
        "    if len(pca_data) >= seq_length:\n",
        "        sequence = pca_data[-seq_length:].reshape(1, seq_length, -1)\n",
        "\n",
        "        # 予測\n",
        "        scaled_prediction = model.predict(sequence)\n",
        "\n",
        "        # スケーリングを元に戻す\n",
        "        prediction = y_scaler.inverse_transform(scaled_prediction)[0, 0]\n",
        "\n",
        "        return prediction\n",
        "    else:\n",
        "        raise ValueError(f\"入力データが短すぎます。少なくとも{seq_length}点必要です。\")\n",
        "\n",
        "print(\"\\nモデルと前処理パイプラインを保存しました。\")\n",
        "print(\"新しいデータに対する予測は 'predict_price' 関数を使用して行えます。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnQKYSgsSREZ",
        "outputId": "0b295e5d-9c1d-4735-b08a-45b750c59d1d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "モデルと前処理パイプラインを保存しました。\n",
            "新しいデータに対する予測は 'predict_price' 関数を使用して行えます。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 最適モデルの決定と最終予測"
      ],
      "metadata": {
        "id": "hsIhTuL1Q9is"
      }
    },
    {
      "source": [
        "\n",
        "# モデルの評価結果を格納\n",
        "evaluation_results = {\n",
        "    \"LSTM (PCA)\": {\"mae\": lstm_pca_mae, \"rmse\": lstm_pca_rmse, \"model\": lstm_model_pca, \"data_type\": \"pca\"},\n",
        "    \"LSTM (No PCA)\": {\"mae\": lstm_no_pca_mae, \"rmse\": lstm_no_pca_rmse, \"model\": lstm_model_no_pca, \"data_type\": \"no_pca\"},\n",
        "    \"GRU (PCA)\": {\"mae\": gru_pca_mae, \"rmse\": gru_pca_rmse, \"model\": gru_model_pca, \"data_type\": \"pca\"},\n",
        "    \"GRU (No PCA)\": {\"mae\": gru_no_pca_mae, \"rmse\": gru_no_pca_rmse, \"model\": gru_model_no_pca, \"data_type\": \"no_pca\"}\n",
        "}\n",
        "\n",
        "print(\"\\n--- モデル比較結果 ---\")\n",
        "for name, metrics in evaluation_results.items():\n",
        "    print(f\"{name}: MAE={metrics['mae']:.4f}, RMSE={metrics['rmse']:.4f}\")\n",
        "\n",
        "# 最適なモデルを選択（ここではMAEが最小のモデルとする）\n",
        "best_model_name = min(evaluation_results, key=lambda k: evaluation_results[k]['mae'])\n",
        "best_model_info = evaluation_results[best_model_name]\n",
        "best_model = best_model_info['model']\n",
        "best_data_type = best_model_info['data_type']\n",
        "\n",
        "print(f\"\\n最適なモデルは: {best_model_name} (MAE={best_model_info['mae']:.4f})\")\n",
        "\n",
        "# 最終予測に使用する前処理パイプラインを準備\n",
        "# 学習時に使用したスケーラーとPCAオブジェクトが必要\n",
        "# Assuming feature_scaler, pca, y_scaler are available from previous steps\n",
        "\n",
        "final_pca = None\n",
        "final_feature_scaler = feature_scaler # 特徴量選択前の標準化に使用したscaler\n",
        "final_y_scaler = y_scaler\n",
        "\n",
        "if best_data_type == 'pca':\n",
        "    final_pca = pca # 最適モデルがPCAを使用した場合のみPCAオブジェクトを使用\n",
        "    print(\"最終予測にPCAを使用します。\")\n",
        "else:\n",
        "    print(\"最終予測にPCAは使用しません。\")\n",
        "\n",
        "\n",
        "# test_dfに対する最終推論\n",
        "# test_IDが'spain_total'のデータのみを選択\n",
        "test_df_spain = test_df[test_df['item_ID'] == 'spain_total'].copy()\n",
        "\n",
        "# 欠損値処理 (trainと同じ処理を適用)\n",
        "test_df_spain = test_df_spain.ffill()\n",
        "test_df_spain = test_df_spain.bfill()\n",
        "\n",
        "# 'item_ID' 列を削除\n",
        "test_df_spain = test_df_spain.drop('item_ID', axis=1)\n",
        "\n",
        "# テストデータに特徴量エンジニアリングを適用（学習データを使ってラグを計算）\n",
        "# create_additional_features_combined 関数が train_df を必要とするため渡す\n",
        "if 'df' in locals() or 'df' in globals():\n",
        "    test_df_featured = create_additional_features_combined(\n",
        "        test_df_spain.copy(),\n",
        "        is_test=True,\n",
        "        train_df=df.copy() # 学習データを使用\n",
        "    )\n",
        "    print(f\"\\nテストデータの特徴量エンジニアリング完了。形状: {test_df_featured.shape}\")\n",
        "\n",
        "    # NaN値の最終確認と処理\n",
        "    final_nan_count_test = test_df_featured.isnull().sum().sum()\n",
        "    if final_nan_count_test > 0:\n",
        "        print(f\"警告: テストデータの特徴量エンジニアリング後にNaN値が {final_nan_count_test}個 あります。0で埋めます。\")\n",
        "        test_df_featured = test_df_featured.fillna(0)\n",
        "else:\n",
        "    print(\"エラー: 学習データ (df) が見つかりません。テストデータの特徴量エンジニアリングを実行できません。\")\n",
        "    test_df_featured = None\n",
        "\n",
        "\n",
        "if test_df_featured is not None:\n",
        "    try:\n",
        "        # 学習時に選択された特徴量のみを抽出\n",
        "        # loaded_selected_features は前回のパイプラインロード部分で取得\n",
        "        # ここでは feature_selector から再取得する\n",
        "        selected_features_for_inference = feature_selector.get_support(indices=True)\n",
        "        selected_feature_names = X_featured.select_dtypes(include=np.number).columns[selected_features_for_inference].tolist()\n",
        "\n",
        "        test_data_aligned = test_df_featured[selected_feature_names]\n",
        "        print(f\"テストデータ ({test_data_aligned.shape[1]}個の特徴量) のカラム順序を合わせました。\")\n",
        "\n",
        "        # テストデータに前処理を適用 (標準化)\n",
        "        test_data_scaled = final_feature_scaler.transform(test_data_aligned)\n",
        "        test_data_processed = test_data_scaled\n",
        "\n",
        "        # PCA適用が必要な場合のみPCAを適用\n",
        "        if final_pca is not None:\n",
        "            test_data_processed = final_pca.transform(test_data_scaled)\n",
        "            print(f\"テストデータにPCAを適用しました。形状: {test_data_processed.shape}\")\n",
        "        else:\n",
        "            print(f\"テストデータにPCAは適用しません。形状: {test_data_processed.shape}\")\n",
        "\n",
        "\n",
        "        # 推論用シーケンスの作成\n",
        "        # 学習データの最終部分 + テストデータ全体を使ってシーケンスを作成する必要がある\n",
        "        # 結合データが必要\n",
        "        if best_data_type == 'pca':\n",
        "             # 学習データのPCA適用済みデータ + テストデータのPCA適用済みデータ\n",
        "             if 'X_pca' in locals() or 'X_pca' in globals():\n",
        "                 combined_data_for_inference = np.concatenate([X_pca, test_data_processed])\n",
        "                 print(f\"推論用に学習(PCA済)とテスト(PCA済)データを結合。形状: {combined_data_for_inference.shape}\")\n",
        "             else:\n",
        "                 print(\"エラー: 学習データのPCA結果 (X_pca) が見つかりません。推論できません。\")\n",
        "                 combined_data_for_inference = None\n",
        "\n",
        "        else: # best_data_type == 'no_pca'\n",
        "             # 学習データのPCAなしデータ + テストデータのPCAなしデータ\n",
        "             if 'X_no_pca' in locals() or 'X_no_pca' in globals():\n",
        "                  # X_no_pca は既に scaled/selected 済み\n",
        "                  combined_data_for_inference = np.concatenate([X_no_pca, test_data_processed])\n",
        "                  print(f\"推論用に学習(PCAなし)とテスト(PCAなし)データを結合。形状: {combined_data_for_inference.shape}\")\n",
        "             else:\n",
        "                 print(\"エラー: 学習データのPCAなしデータ (X_no_pca) が見つかりません。推論できません。\")\n",
        "                 combined_data_for_inference = None\n",
        "\n",
        "\n",
        "        X_inference = []\n",
        "        # 推論はテストデータの最初から開始\n",
        "        # シーケンスの開始位置を考慮して、結合データからの開始インデックスを決定\n",
        "        start_index_combined = len(df) - loaded_seq_length # ラグ特徴量などを考慮した開始点\n",
        "        if best_data_type == 'pca':\n",
        "             start_index_combined = len(X_pca) - loaded_seq_length\n",
        "             # 学習データとテストデータを結合したデータセットに対してシーケンスを作成\n",
        "             # テストデータの最初のタイムステップに対応するシーケンスが必要\n",
        "             # combined_data_for_inference は (len(X_pca) + len(test_data_processed)) の長さ\n",
        "             # テストデータの最初のタイムステップはインデックス len(X_pca)\n",
        "             # その予測に必要なシーケンスは combined_data_for_inference[len(X_pca) - loaded_seq_length : len(X_pca)] から始まる\n",
        "             inference_start_idx_in_combined = len(X_pca) - loaded_seq_length\n",
        "        else: # best_data_type == 'no_pca'\n",
        "             start_index_combined = len(X_no_pca) - loaded_seq_length\n",
        "             inference_start_idx_in_combined = len(X_no_pca) - loaded_seq_length\n",
        "\n",
        "\n",
        "        if combined_data_for_inference is not None:\n",
        "             # テストデータの長さ分の予測が必要\n",
        "             num_test_timesteps = len(test_data_processed)\n",
        "\n",
        "             for i in range(num_test_timesteps):\n",
        "                 seq_start = inference_start_idx_in_combined + i\n",
        "                 seq_end = seq_start + loaded_seq_length\n",
        "\n",
        "                 if seq_start >= 0 and seq_end <= len(combined_data_for_inference):\n",
        "                      input_sequence = combined_data_for_inference[seq_start:seq_end]\n",
        "                      X_inference.append(input_sequence)\n",
        "                 else:\n",
        "                      # シーケンスが結合データの範囲外になる場合はスキップまたは適切な処理\n",
        "                      print(f\"警告: シーケンス範囲外のためスキップ (start={seq_start}, end={seq_end}, combined_len={len(combined_data_for_inference)})\")\n",
        "\n",
        "\n",
        "        if X_inference:\n",
        "            X_inference = np.array(X_inference)\n",
        "            print(f\"推論用シーケンスデータ形状: {X_inference.shape}\")\n",
        "\n",
        "            # 予測実行\n",
        "            scaled_predictions = best_model.predict(X_inference)\n",
        "            predictions = final_y_scaler.inverse_transform(scaled_predictions).flatten()\n",
        "\n",
        "            # 提出ファイル作成\n",
        "            # 予測されたのはテストデータの seq_length 以降の部分に対応する\n",
        "            # 推論用シーケンス作成時のループ回数と予測結果の長さを確認\n",
        "            if len(predictions) == len(test_df_spain) - loaded_seq_length:\n",
        "                # テストデータの対応するタイムスタンプを取得\n",
        "                # test_df_spain のインデックスで、シーケンス長だけずらす\n",
        "                valid_test_indices = test_df_spain.index[loaded_seq_length:]\n",
        "\n",
        "                submission_df = pd.DataFrame({\n",
        "                    'id': [ts.strftime('%Y-%m-%d %H:%M:%S') + '_spain_total' for ts in valid_test_indices],\n",
        "                    'price_actual': predictions\n",
        "                })\n",
        "\n",
        "                submission_path = data_path + 'submission.csv'\n",
        "                submission_df.to_csv(submission_path, header=False, index=False)\n",
        "\n",
        "                print(f\"\\n最終推論結果を '{submission_path}' に保存しました。\")\n",
        "                print(\"提出ファイルの先頭:\")\n",
        "                display(pd.read_csv(submission_path, header=None).head())\n",
        "\n",
        "            else:\n",
        "                print(f\"エラー: 予測結果の長さ ({len(predictions)}) がテストデータの予測対象期間の長さ ({len(test_df_spain) - loaded_seq_length}) と一致しません。\")\n",
        "                print(f\"テストデータの長さ: {len(test_df_spain)}\")\n",
        "                print(f\"シーケンス長: {loaded_seq_length}\")\n",
        "                print(f\"予測される長さ: {len(test_df_spain) - loaded_seq_length}\")\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(\"エラー: 最終予測のための入力シーケンスが作成できませんでした。\")\n",
        "\n",
        "    except KeyError as e:\n",
        "        print(f\"エラー: 特徴量選択で問題が発生しました。テストデータに必要な特徴量が見つかりません: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"最終予測の実行中にエラーが発生しました: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"テストデータの特徴量エンジニアリングが正常に完了しなかったため、推論を実行できません。\")\n",
        "# %%"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1vik4ZSQ0gZ",
        "outputId": "c9546e38-5e39-4970-81d4-1ee4bd78f357"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- モデル比較結果 ---\n",
            "LSTM (PCA): MAE=4.4801, RMSE=6.2004\n",
            "LSTM (No PCA): MAE=3.9132, RMSE=5.3689\n",
            "GRU (PCA): MAE=3.7873, RMSE=5.1848\n",
            "GRU (No PCA): MAE=3.0780, RMSE=4.3365\n",
            "\n",
            "最適なモデルは: GRU (No PCA) (MAE=3.0780)\n",
            "最終予測にPCAは使用しません。\n",
            "\n",
            "テストデータの特徴量エンジニアリング完了。形状: (8760, 105)\n",
            "テストデータ (30個の特徴量) のカラム順序を合わせました。\n",
            "最終予測の実行中にエラーが発生しました: The feature names should match those that were passed during fit.\n",
            "Feature names seen at fit time, yet now missing:\n",
            "- barcelona_clouds_all\n",
            "- barcelona_humidity\n",
            "- barcelona_pressure\n",
            "- barcelona_rain_1h\n",
            "- barcelona_rain_3h\n",
            "- ...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-ca4bec39412f>:72: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_features = df_features.ffill()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 最終提出データの作成"
      ],
      "metadata": {
        "id": "nFcXosEt0a62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "# test_dfに対する推論\n",
        "# test_IDが'spain_total'のデータのみを選択\n",
        "test_df_spain = test_df[test_df['item_ID'] == 'spain_total'].copy()\n",
        "\n",
        "# 欠損値処理 (trainと同じ処理を適用)\n",
        "test_df_spain = test_df_spain.ffill()\n",
        "test_df_spain = test_df_spain.bfill()\n",
        "\n",
        "# 'item_ID' 列を削除\n",
        "test_df_spain = test_df_spain.drop('item_ID', axis=1)\n",
        "\n",
        "def create_additional_features_combined(df, is_test=False, train_df=None):\n",
        "    \"\"\"\n",
        "    時間ベースの特徴量とラグ特徴量を作成。\n",
        "    テストデータの場合は学習データと結合してラグ特徴量を正しく計算する。\n",
        "    \"\"\"\n",
        "    df_features = df.copy()\n",
        "\n",
        "    # インデックスがDatetimeIndexであることを確認し、必要なら変換\n",
        "    if not isinstance(df_features.index, pd.DatetimeIndex) or df_features.index.tz is not None:\n",
        "        df_features.index = pd.to_datetime(df_features.index, utc=True)\n",
        "\n",
        "    # 時間ベースの特徴量\n",
        "    df_features['hour'] = df_features.index.hour\n",
        "    df_features['dayofweek'] = df_features.index.dayofweek\n",
        "    df_features['month'] = df_features.index.month\n",
        "    df_features['year'] = df_features.index.year\n",
        "    df_features['quarter'] = df_features.index.quarter\n",
        "    df_features['dayofyear'] = df_features.index.dayofyear\n",
        "    try:\n",
        "        df_features['weekofyear'] = df_features.index.isocalendar().week.astype(int)\n",
        "    except AttributeError:\n",
        "        df_features['weekofyear'] = df_features.index.weekofyear.astype(int)\n",
        "    df_features['dayofmonth'] = df_features.index.day\n",
        "    df_features['is_weekend'] = (df_features.index.dayofweek >= 5).astype(int)\n",
        "\n",
        "    # ラグ特徴量の処理\n",
        "    if is_test and train_df is not None:\n",
        "        # テストデータの場合、学習データと結合してラグ特徴量を計算\n",
        "        # 学習データの最後の部分とテストデータを結合\n",
        "        combined_df = pd.concat([train_df, df_features], axis=0)\n",
        "\n",
        "        # 結合データに対してラグ特徴量を計算\n",
        "        combined_df['price_actual_lag_1'] = combined_df['price_actual'].shift(1)\n",
        "        combined_df['price_actual_lag_24'] = combined_df['price_actual'].shift(24)\n",
        "        combined_df['price_actual_lag_48'] = combined_df['price_actual'].shift(48)\n",
        "        combined_df['price_actual_lag_168'] = combined_df['price_actual'].shift(168)\n",
        "        combined_df['price_actual_rolling_mean_24'] = combined_df['price_actual'].rolling(window=24).mean()\n",
        "\n",
        "        # テストデータ部分のみを抽出\n",
        "        df_features = combined_df.loc[df_features.index]\n",
        "\n",
        "        # price_actual列を削除（テストデータには存在しないため）\n",
        "        if 'price_actual' in df_features.columns:\n",
        "            df_features = df_features.drop('price_actual', axis=1)\n",
        "\n",
        "    elif not is_test and 'price_actual' in df_features.columns:\n",
        "        # 学習データの場合\n",
        "        df_features['price_actual_lag_1'] = df_features['price_actual'].shift(1)\n",
        "        df_features['price_actual_lag_24'] = df_features['price_actual'].shift(24)\n",
        "        df_features['price_actual_lag_48'] = df_features['price_actual'].shift(48)\n",
        "        df_features['price_actual_lag_168'] = df_features['price_actual'].shift(168)\n",
        "        df_features['price_actual_rolling_mean_24'] = df_features['price_actual'].rolling(window=24).mean()\n",
        "\n",
        "    # 欠損値処理\n",
        "    df_features = df_features.ffill()\n",
        "    df_features = df_features.bfill()\n",
        "\n",
        "    # まだNaNが残っている場合は0で埋める\n",
        "    df_features = df_features.fillna(0)\n",
        "\n",
        "    return df_features\n",
        "\n",
        "# 保存したパイプラインを読み込み\n",
        "pipeline_load_path = data_path + 'price_prediction_pipeline.pkl'\n",
        "loaded_pipeline = None\n",
        "loaded_selected_features = None\n",
        "\n",
        "if os.path.exists(pipeline_load_path):\n",
        "    try:\n",
        "        with open(pipeline_load_path, 'rb') as f:\n",
        "            loaded_pipeline = pickle.load(f)\n",
        "\n",
        "        loaded_pca = loaded_pipeline['pca']\n",
        "        loaded_pca_scaler = loaded_pipeline['pca_scaler']\n",
        "        loaded_y_scaler = loaded_pipeline['y_scaler']\n",
        "        loaded_selected_features = loaded_pipeline['selected_features']\n",
        "        loaded_seq_length = loaded_pipeline['seq_length']\n",
        "\n",
        "        print(f\"\\nパイプラインをロードしました。学習時に選択された特徴量 ({len(loaded_selected_features)}個): {loaded_selected_features}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"パイプラインのロードに失敗しました: {e}\")\n",
        "        loaded_pipeline = None\n",
        "else:\n",
        "    print(f\"エラー: パイプラインファイル '{pipeline_load_path}' が見つかりません。\")\n",
        "\n",
        "if loaded_pipeline is not None and loaded_selected_features is not None:\n",
        "    # 学習データの特徴量エンジニアリング済みデータが必要\n",
        "    # dfに対して同じ特徴量エンジニアリングを適用\n",
        "    if 'df' in locals() or 'df' in globals():\n",
        "        # 学習データに特徴量エンジニアリングを適用（price_actualラグを含む）\n",
        "        df_featured_train = create_additional_features_combined(df.copy(), is_test=False)\n",
        "\n",
        "        # テストデータに特徴量エンジニアリングを適用（学習データを使ってラグを計算）\n",
        "        test_df_featured = create_additional_features_combined(\n",
        "            test_df_spain.copy(),\n",
        "            is_test=True,\n",
        "            train_df=df.copy()\n",
        "        )\n",
        "\n",
        "        print(f\"テストデータの特徴量エンジニアリング完了。形状: {test_df_featured.shape}\")\n",
        "\n",
        "        # NaN値の確認\n",
        "        nan_count = test_df_featured.isnull().sum().sum()\n",
        "        print(f\"テストデータのNaN値の総数: {nan_count}\")\n",
        "\n",
        "        if nan_count > 0:\n",
        "            print(\"NaN値が残っているカラム:\")\n",
        "            nan_columns = test_df_featured.isnull().sum()\n",
        "            print(nan_columns[nan_columns > 0])\n",
        "\n",
        "            # 残りのNaN値を0で埋める\n",
        "            test_df_featured = test_df_featured.fillna(0)\n",
        "            print(\"残りのNaN値を0で埋めました。\")\n",
        "\n",
        "        try:\n",
        "            # 学習時に選択された特徴量のみを抽出\n",
        "            test_data_aligned = test_df_featured[loaded_selected_features]\n",
        "            print(f\"テストデータ ({test_data_aligned.shape[1]}個の特徴量) のカラム順序を合わせました。\")\n",
        "\n",
        "            # 最終的なNaN確認\n",
        "            final_nan_count = test_data_aligned.isnull().sum().sum()\n",
        "            print(f\"最終的なNaN値の総数: {final_nan_count}\")\n",
        "\n",
        "            if final_nan_count > 0:\n",
        "                print(\"警告: まだNaN値が残っています。さらに処理します。\")\n",
        "                test_data_aligned = test_data_aligned.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
        "\n",
        "        except KeyError as e:\n",
        "            print(f\"エラー: 学習時に選択された特徴量 '{e}' がテストデータに見つかりません。\")\n",
        "            test_data_aligned = None\n",
        "\n",
        "        if test_data_aligned is not None:\n",
        "            # モデルをロード\n",
        "            lstm_model_path = data_path + 'lstm_model.h5'\n",
        "            try:\n",
        "                loaded_model = tf.keras.models.load_model(\n",
        "                    lstm_model_path,\n",
        "                    custom_objects={'mse': tf.keras.losses.MeanSquaredError()}\n",
        "                )\n",
        "                print(\"モデルを正常にロードしました。\")\n",
        "\n",
        "                # テストデータに前処理を適用\n",
        "                test_data_scaled = loaded_pca_scaler.transform(test_data_aligned)\n",
        "                test_data_pca = loaded_pca.transform(test_data_scaled)\n",
        "                print(f\"テストデータにスケーリングとPCAを適用しました。形状: {test_data_pca.shape}\")\n",
        "\n",
        "                # 学習データのPCA結果と結合\n",
        "                if 'X_pca' in locals() or 'X_pca' in globals():\n",
        "                    combined_data_pca = np.concatenate([X_pca, test_data_pca])\n",
        "                    print(f\"データを結合しました。形状: {combined_data_pca.shape}\")\n",
        "\n",
        "                    # 推論用シーケンスの作成\n",
        "                    X_inference = []\n",
        "                    start_index_test = len(X_pca)\n",
        "\n",
        "                    for i in range(len(test_data_pca)):\n",
        "                        seq_start = start_index_test + i - loaded_seq_length\n",
        "                        seq_end = start_index_test + i\n",
        "\n",
        "                        if seq_start >= 0:\n",
        "                            input_sequence = combined_data_pca[seq_start:seq_end]\n",
        "                            X_inference.append(input_sequence)\n",
        "\n",
        "                    if X_inference:\n",
        "                        X_inference = np.array(X_inference)\n",
        "                        print(f\"推論用シーケンスデータ形状: {X_inference.shape}\")\n",
        "\n",
        "                        # 予測実行\n",
        "                        scaled_predictions = loaded_model.predict(X_inference)\n",
        "                        predictions = loaded_y_scaler.inverse_transform(scaled_predictions).flatten()\n",
        "\n",
        "                        # 提出ファイル作成\n",
        "                        valid_test_indices = test_df_spain.index[len(test_df_spain) - len(predictions):]\n",
        "                        submission_df = pd.DataFrame({\n",
        "                            'id': [ts.strftime('%Y-%m-%d %H:%M:%S') + '_spain_total' for ts in valid_test_indices],\n",
        "                            'price_actual': predictions\n",
        "                        })\n",
        "\n",
        "                        submission_path = data_path + 'submission.csv'\n",
        "                        submission_df.to_csv(submission_path, header=False, index=False)\n",
        "\n",
        "                        print(f\"\\n推論結果を '{submission_path}' に保存しました。\")\n",
        "                        print(\"提出ファイルの先頭:\")\n",
        "                        display(pd.read_csv(submission_path, header=None).head())\n",
        "\n",
        "                    else:\n",
        "                        print(\"エラー: 予測のための入力シーケンスが作成できませんでした。\")\n",
        "                else:\n",
        "                    print(\"エラー: 学習データのPCA結果 (X_pca) が見つかりません。\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"モデルのロードまたは推論に失敗しました: {e}\")\n",
        "    else:\n",
        "        print(\"エラー: 学習データ (df) が見つかりません。\")\n",
        "else:\n",
        "    print(\"パイプラインがロードされなかったため、推論を実行できません。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "dirpQrr1jDjC",
        "outputId": "0ca9c594-6a12-45af-b70d-9a20537286a8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "パイプラインをロードしました。学習時に選択された特徴量 (30個): ['generation_biomass', 'generation_fossil_brown_coal/lignite', 'generation_fossil_gas', 'generation_fossil_hard_coal', 'generation_fossil_oil', 'generation_hydro_pumped_storage_consumption', 'generation_hydro_run_of_river_and_poundage', 'generation_other', 'total_load_actual', 'valencia_wind_speed', 'madrid_wind_speed', 'bilbao_pressure', 'bilbao_wind_speed', 'bilbao_wind_deg', 'bilbao_clouds_all', 'barcelona_wind_speed', 'seville_pressure', 'seville_wind_deg', 'hour', 'dayofweek', 'month', 'quarter', 'dayofyear', 'weekofyear', 'is_weekend', 'price_actual_lag_1', 'price_actual_lag_24', 'price_actual_lag_48', 'price_actual_lag_168', 'price_actual_rolling_mean_24']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-ca4bec39412f>:72: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df_features = df_features.ffill()\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "テストデータの特徴量エンジニアリング完了。形状: (8760, 105)\n",
            "テストデータのNaN値の総数: 0\n",
            "テストデータ (30個の特徴量) のカラム順序を合わせました。\n",
            "最終的なNaN値の総数: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but PCA was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "モデルを正常にロードしました。\n",
            "テストデータにスケーリングとPCAを適用しました。形状: (8760, 15)\n",
            "データを結合しました。形状: (35040, 15)\n",
            "推論用シーケンスデータ形状: (8760, 24, 15)\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
            "\n",
            "推論結果を '/content/drive/MyDrive/ML/Signate_1634/submission.csv' に保存しました。\n",
            "提出ファイルの先頭:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                 0          1\n",
              "0  2018-01-01 00:00:00_spain_total  59.314354\n",
              "1  2018-01-01 01:00:00_spain_total  58.704500\n",
              "2  2018-01-01 02:00:00_spain_total  58.757313\n",
              "3  2018-01-01 03:00:00_spain_total  60.397420\n",
              "4  2018-01-01 04:00:00_spain_total  61.126390"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07318db8-8227-4d56-973b-57d960667840\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-01 00:00:00_spain_total</td>\n",
              "      <td>59.314354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-01 01:00:00_spain_total</td>\n",
              "      <td>58.704500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-01 02:00:00_spain_total</td>\n",
              "      <td>58.757313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-01 03:00:00_spain_total</td>\n",
              "      <td>60.397420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-01 04:00:00_spain_total</td>\n",
              "      <td>61.126390</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07318db8-8227-4d56-973b-57d960667840')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-07318db8-8227-4d56-973b-57d960667840 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-07318db8-8227-4d56-973b-57d960667840');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-20310781-0cef-4e2d-b089-4c756be4ffcb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20310781-0cef-4e2d-b089-4c756be4ffcb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-20310781-0cef-4e2d-b089-4c756be4ffcb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"\\u30d1\\u30a4\\u30d7\\u30e9\\u30a4\\u30f3\\u304c\\u30ed\\u30fc\\u30c9\\u3055\\u308c\\u306a\\u304b\\u3063\\u305f\\u305f\\u3081\\u3001\\u63a8\\u8ad6\\u3092\\u5b9f\\u884c\\u3067\\u304d\\u307e\\u305b\\u3093\\u3002\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2018-01-01 01:00:00_spain_total\",\n          \"2018-01-01 04:00:00_spain_total\",\n          \"2018-01-01 02:00:00_spain_total\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0655260573631207,\n        \"min\": 58.7045,\n        \"max\": 61.12639,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          58.7045,\n          61.12639,\n          58.757313\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 最終メモ\n",
        "この修正により、PCAによる次元削減がモデル性能にどのような影響を与えるかを定量的に比較できるようになります。\n",
        "\n",
        "次に進めるべきステップとしては、ハイパーパラメータ検索の導入や、時系列交差検証のロジック一本化・ログ強化が考えられます。どちらに進みますか？ または、今回のコードについてさらに詳細な説明や修正が必要な点があればお知らせください。"
      ],
      "metadata": {
        "id": "-oFzFqAAI1qd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bEiZWYl-I20O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}