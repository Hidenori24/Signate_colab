{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUAyyWQa3uJeJCJmb7NkHr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hidenori24/Signate_colab/blob/main/SMBC_2025_2ndVer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. ライブラリセットアップ\n"
      ],
      "metadata": {
        "id": "5idmRN9YE8EI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0ZWUiAp_EmOg"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# 0. ライブラリ & CFG 定義\n",
        "# ============================================\n",
        "!pip -q install lightgbm==4.3.0 polars==0.20.19 holidays==0.42\n",
        "\n",
        "import os, random, math, gc, pickle, warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import lightgbm as lgb\n",
        "import holidays\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ---------- CFG ----------\n",
        "class CFG:\n",
        "    seed         = 42\n",
        "    n_folds      = 5\n",
        "    early_stop   = 300\n",
        "    num_boost_round = 20_000\n",
        "    test_size_hr = 4380          # ≒6ヶ月\n",
        "    lags         = [1, 24]\n",
        "    rolls        = [24, 168]\n",
        "    data_path    = '/content/drive/MyDrive/ML/Signate_1634/'\n",
        "    use_polars   = False         # True にすると FE 後が高速\n",
        "    lgb_params = {\n",
        "        'objective'      : 'regression',\n",
        "        'metric'         : 'rmse',\n",
        "        'learning_rate'  : 0.05,\n",
        "        'num_leaves'     : 256,\n",
        "        'subsample'      : 0.8,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'seed'           : seed,\n",
        "        'verbose'        : -1,\n",
        "    }\n",
        "\n",
        "# set seed\n",
        "random.seed(CFG.seed)\n",
        "np.random.seed(CFG.seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Google Drive マウント\n"
      ],
      "metadata": {
        "id": "fMaGVka5FB7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 1. Google Drive マウント\n",
        "# ============================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jG6UMAE3Eqdv",
        "outputId": "f4abe306-8636-43b8-e360-28ce8936cd0a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. データ読み込み"
      ],
      "metadata": {
        "id": "guK8i2niFK0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 2. データ読み込み\n",
        "#    - index を DatetimeIndex（UTC）に\n",
        "# =========================================================\n",
        "def read_data(path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path)                 # まずは普通に読み込み\n",
        "    df['time'] = pd.to_datetime(df['time'], utc=True)   # ①文字列→datetime(UTC)\n",
        "    df['time'] = df['time'].dt.tz_convert(None)         # ②タイムゾーン情報を外す（naive へ）\n",
        "    df = df.set_index('time').sort_index()              # ③DatetimeIndex として設定\n",
        "    return df\n",
        "\n",
        "train_df = read_data(os.path.join(CFG.data_path, 'train.csv'))\n",
        "test_df  = read_data(os.path.join(CFG.data_path, 'test.csv'))\n",
        "\n",
        "print('train', train_df.shape, 'test', test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJKz_c6jEsq1",
        "outputId": "d2b81c84-c884-4495-b0ba-a5e21a1bf2b6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train (26280, 91) test (8760, 90)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 特徴量生成"
      ],
      "metadata": {
        "id": "dTc-JyB1FMV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 3. 特徴量エンジニアリング\n",
        "# ============================================\n",
        "es_holidays = holidays.country_holidays('ES', years=range(2015, 2019))\n",
        "holiday_set = set(es_holidays.keys())  # set で高速判定\n",
        "\n",
        "def add_calendar(df):\n",
        "    idx = df.index\n",
        "    df['hour']       = idx.hour\n",
        "    df['dow']        = idx.dayofweek\n",
        "    df['month']      = idx.month\n",
        "    df['is_weekend'] = (df['dow'] >= 5).astype(np.int8)\n",
        "    df['is_holiday'] = np.isin(idx.date, list(holiday_set)).astype(np.int8)\n",
        "\n",
        "    df['sin_hour'] = np.sin(2*np.pi*df['hour']/24)\n",
        "    df['cos_hour'] = np.cos(2*np.pi*df['hour']/24)\n",
        "    df['sin_dow']  = np.sin(2*np.pi*df['dow']/7)\n",
        "    df['cos_dow']  = np.cos(2*np.pi*df['dow']/7)\n",
        "    return df\n",
        "\n",
        "def add_supply_gap(df):\n",
        "    gen_cols = [c for c in df.columns if c.startswith('generation_')]\n",
        "    df['supply_total'] = df[gen_cols].sum(axis=1)\n",
        "    df['gap_supply_demand'] = df['supply_total'] - df['total_load_actual']\n",
        "\n",
        "    ren_cols = [c for c in gen_cols if any(k in c for k in ['solar','wind','hydro'])]\n",
        "    df['renewable_ratio'] = df[ren_cols].sum(axis=1) / df['supply_total']\n",
        "    return df\n",
        "\n",
        "def add_lag_roll(df, lags=CFG.lags, rolls=CFG.rolls):\n",
        "    for l in lags:\n",
        "        df[f'price_lag_{l}']  = df['price_actual'].shift(l)\n",
        "        df[f'demand_lag_{l}'] = df['total_load_actual'].shift(l)\n",
        "    for r in rolls:\n",
        "        df[f'price_rollmean_{r}'] = df['price_actual'].shift(1).rolling(r).mean()\n",
        "        df[f'gap_rollstd_{r}']    = df['gap_supply_demand'].shift(1).rolling(r).std()\n",
        "    return df\n",
        "\n",
        "def make_features(full):\n",
        "    full = add_calendar(full)\n",
        "    full = add_supply_gap(full)\n",
        "    full = add_lag_roll(full)\n",
        "    return full\n",
        "\n",
        "# train+test を縦結合して一括 FE\n",
        "full_df = pd.concat(\n",
        "    [train_df, test_df.assign(price_actual=np.nan)],\n",
        "    axis=0\n",
        ")\n",
        "full_df = make_features(full_df)\n",
        "\n",
        "# 欠損補完（時系列なので forward → 数値列平均）\n",
        "full_df = full_df.fillna(method='ffill')\n",
        "num_cols = full_df.select_dtypes(include=[np.number, 'bool']).columns\n",
        "full_df[num_cols] = full_df[num_cols].fillna(full_df[num_cols].mean())\n",
        "\n",
        "print('FE 完了:', full_df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNTw5dRGEuCe",
        "outputId": "fee81d77-9320-4f2b-fc1d-50eefcc6a901"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FE 完了: (35040, 111)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 数値列 & カテゴリー列を分離"
      ],
      "metadata": {
        "id": "PfqCv0ijFOM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 4. 数値列 & カテゴリー列を分離\n",
        "#    ─ LightGBM にカテゴリーを渡すオプション付き ─\n",
        "# ============================================\n",
        "TARGET = 'price_actual'\n",
        "\n",
        "cat_cols = [c for c in full_df.columns if c.endswith(('weather_main',\n",
        "                                                      'weather_description',\n",
        "                                                      'weather_icon'))]\n",
        "full_df[cat_cols] = full_df[cat_cols].astype('category')  # dtype=category に変換\n",
        "\n",
        "features = [c for c in full_df.columns if c != TARGET]    # すべて渡す\n",
        "\n",
        "train_fe = full_df.loc[train_df.index]\n",
        "test_fe  = full_df.loc[test_df.index]\n",
        "\n",
        "def to_lgb_matrix(df: pd.DataFrame, cat_cols: list) -> pd.DataFrame:\n",
        "    df_num = df.copy()\n",
        "    for col in cat_cols:\n",
        "        df_num[col] = df_num[col].cat.codes.astype('int32')\n",
        "    return df_num\n",
        "\n",
        "\n",
        "\n",
        "X_train, y_train = train_fe[features], train_fe[TARGET]"
      ],
      "metadata": {
        "id": "KIQ-glPpEweF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 時系列 CV & LightGBM 学習"
      ],
      "metadata": {
        "id": "Kgev0x-kFPg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 5. LightGBM 時系列 CV 学習  ★修正版\n",
        "# ============================================\n",
        "tscv = TimeSeriesSplit(n_splits=CFG.n_folds, test_size=CFG.test_size_hr)\n",
        "oof = np.zeros(len(X_train))\n",
        "pred= np.zeros(len(X_test))\n",
        "\n",
        "for fold, (tr_idx, val_idx) in enumerate(tscv.split(X_train)):\n",
        "    print(f'\\n---- Fold {fold} ----')\n",
        "    X_tr, y_tr = X_train.iloc[tr_idx], y_train.iloc[tr_idx]\n",
        "    X_val, y_val = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
        "\n",
        "    lgb_train = lgb.Dataset(X_tr, label=y_tr, categorical_feature=cat_cols, free_raw_data=False)\n",
        "    lgb_val   = lgb.Dataset(X_val, label=y_val, categorical_feature=cat_cols, free_raw_data=False)\n",
        "\n",
        "    model = lgb.train(\n",
        "        CFG.lgb_params,\n",
        "        lgb_train,\n",
        "        num_boost_round=CFG.num_boost_round,\n",
        "        valid_sets=[lgb_train, lgb_val],\n",
        "        valid_names=['train','valid'],\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(CFG.early_stop, verbose=True),\n",
        "            lgb.log_evaluation(500)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    oof[val_idx] = model.predict(\n",
        "        to_lgb_matrix(X_val, cat_cols),\n",
        "        num_iteration=model.best_iteration\n",
        "    )\n",
        "\n",
        "    pred += model.predict(\n",
        "        to_lgb_matrix(X_test, cat_cols),\n",
        "        num_iteration=model.best_iteration\n",
        "    ) / CFG.n_folds\n",
        "\n",
        "rmse = mean_squared_error(y_train, oof, squared=False)\n",
        "print(f'\\nOOF RMSE = {rmse:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "8rJWMv2JEx8O",
        "outputId": "9990a085-3943-44c9-f1a6-282476046019"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---- Fold 0 ----\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "Early stopping, best iteration is:\n",
            "[96]\ttrain's rmse: 1.12473\tvalid's rmse: 2.77683\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "train and valid dataset categorical_feature do not match.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-322322537>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     )\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     oof[val_idx] = model.predict(\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mto_lgb_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[0m\n\u001b[1;32m   4451\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4452\u001b[0m                 \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4453\u001b[0;31m         return predictor.predict(\n\u001b[0m\u001b[1;32m   4454\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4455\u001b[0m             \u001b[0mstart_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd_DataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             data = _data_from_pandas(\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train and valid dataset categorical_feature do not match.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas_categorical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: train and valid dataset categorical_feature do not match."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. 提出ファイル生成"
      ],
      "metadata": {
        "id": "qgQ4CfGfFQs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 6. 提出ファイル生成\n",
        "# =========================================================\n",
        "sub = pd.DataFrame({\n",
        "    'time': test_df.index.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'price_actual': pred\n",
        "})\n",
        "save_path = os.path.join(CFG.data_path, 'submission_lgbm_cfg.csv')\n",
        "sub.to_csv(save_path, index=False)\n",
        "print('saved to', save_path)\n"
      ],
      "metadata": {
        "id": "SQYxehpDEz2r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}